# GPSs:  1
# I am rank 0 of 1
Epoch - 0, step #000000/000234	Loss: 2.317320
Epoch - 0, step #000001/000234	Loss: 2.300910
Epoch - 0, step #000002/000234	Loss: 2.293287
Epoch - 0, step #000003/000234	Loss: 2.262537
Epoch - 0, step #000004/000234	Loss: 2.275126
Epoch - 0, step #000005/000234	Loss: 2.284384
Epoch - 0, step #000006/000234	Loss: 2.250126
Epoch - 0, step #000007/000234	Loss: 2.223477
Epoch - 0, step #000008/000234	Loss: 2.238486
Epoch - 0, step #000009/000234	Loss: 2.200092
Epoch - 0, step #000010/000234	Loss: 2.211484
Epoch - 0, step #000011/000234	Loss: 2.200383
Epoch - 0, step #000012/000234	Loss: 2.189105
Epoch - 0, step #000013/000234	Loss: 2.180099
Epoch - 0, step #000014/000234	Loss: 2.151802
Epoch - 0, step #000015/000234	Loss: 2.134150
Epoch - 0, step #000016/000234	Loss: 2.124331
Epoch - 0, step #000017/000234	Loss: 2.116809
Epoch - 0, step #000018/000234	Loss: 2.121315
Epoch - 0, step #000019/000234	Loss: 2.088115
Epoch - 0, step #000020/000234	Loss: 2.042140
Epoch - 0, step #000021/000234	Loss: 2.036212
Epoch - 0, step #000022/000234	Loss: 1.978118
Epoch - 0, step #000023/000234	Loss: 1.951708
Epoch - 0, step #000024/000234	Loss: 1.933125
Epoch - 0, step #000025/000234	Loss: 1.894298
Epoch - 0, step #000026/000234	Loss: 1.834035
Epoch - 0, step #000027/000234	Loss: 1.835396
Epoch - 0, step #000028/000234	Loss: 1.712146
Epoch - 0, step #000029/000234	Loss: 1.716021
Epoch - 0, step #000030/000234	Loss: 1.655309
Epoch - 0, step #000031/000234	Loss: 1.658462
Epoch - 0, step #000032/000234	Loss: 1.574728
Epoch - 0, step #000033/000234	Loss: 1.476867
Epoch - 0, step #000034/000234	Loss: 1.481200
Epoch - 0, step #000035/000234	Loss: 1.458297
Epoch - 0, step #000036/000234	Loss: 1.483725
Epoch - 0, step #000037/000234	Loss: 1.342844
Epoch - 0, step #000038/000234	Loss: 1.220324
Epoch - 0, step #000039/000234	Loss: 1.309995
Epoch - 0, step #000040/000234	Loss: 1.261407
Epoch - 0, step #000041/000234	Loss: 1.212279
Epoch - 0, step #000042/000234	Loss: 1.275244
Epoch - 0, step #000043/000234	Loss: 1.164441
Epoch - 0, step #000044/000234	Loss: 1.193482
Epoch - 0, step #000045/000234	Loss: 1.059238
Epoch - 0, step #000046/000234	Loss: 1.128417
Epoch - 0, step #000047/000234	Loss: 1.156268
Epoch - 0, step #000048/000234	Loss: 1.154503
Epoch - 0, step #000049/000234	Loss: 0.989980
Epoch - 0, step #000050/000234	Loss: 1.075330
Epoch - 0, step #000051/000234	Loss: 0.972670
Epoch - 0, step #000052/000234	Loss: 0.922546
Epoch - 0, step #000053/000234	Loss: 1.137517
Epoch - 0, step #000054/000234	Loss: 0.999288
Epoch - 0, step #000055/000234	Loss: 0.998015
Epoch - 0, step #000056/000234	Loss: 0.887936
Epoch - 0, step #000057/000234	Loss: 0.940986
Epoch - 0, step #000058/000234	Loss: 0.845977
Epoch - 0, step #000059/000234	Loss: 0.842332
Epoch - 0, step #000060/000234	Loss: 0.946815
Epoch - 0, step #000061/000234	Loss: 0.772654
Epoch - 0, step #000062/000234	Loss: 0.849957
Epoch - 0, step #000063/000234	Loss: 0.869408
Epoch - 0, step #000064/000234	Loss: 0.863970
Epoch - 0, step #000065/000234	Loss: 0.850570
Epoch - 0, step #000066/000234	Loss: 0.807479
Epoch - 0, step #000067/000234	Loss: 0.739268
Epoch - 0, step #000068/000234	Loss: 0.856500
Epoch - 0, step #000069/000234	Loss: 0.851072
Epoch - 0, step #000070/000234	Loss: 0.826541
Epoch - 0, step #000071/000234	Loss: 0.802194
Epoch - 0, step #000072/000234	Loss: 0.729893
Epoch - 0, step #000073/000234	Loss: 0.714798
Epoch - 0, step #000074/000234	Loss: 0.939628
Epoch - 0, step #000075/000234	Loss: 0.656297
Epoch - 0, step #000076/000234	Loss: 0.740167
Epoch - 0, step #000077/000234	Loss: 0.740463
Epoch - 0, step #000078/000234	Loss: 0.688065
Epoch - 0, step #000079/000234	Loss: 0.712252
Epoch - 0, step #000080/000234	Loss: 0.757793
Epoch - 0, step #000081/000234	Loss: 0.700871
Epoch - 0, step #000082/000234	Loss: 0.778062
Epoch - 0, step #000083/000234	Loss: 0.748705
Epoch - 0, step #000084/000234	Loss: 0.665769
Epoch - 0, step #000085/000234	Loss: 0.628042
Epoch - 0, step #000086/000234	Loss: 0.801873
Epoch - 0, step #000087/000234	Loss: 0.737997
Epoch - 0, step #000088/000234	Loss: 0.663561
Epoch - 0, step #000089/000234	Loss: 0.693868
Epoch - 0, step #000090/000234	Loss: 0.661100
Epoch - 0, step #000091/000234	Loss: 0.667315
Epoch - 0, step #000092/000234	Loss: 0.597646
Epoch - 0, step #000093/000234	Loss: 0.743888
Epoch - 0, step #000094/000234	Loss: 0.661577
Epoch - 0, step #000095/000234	Loss: 0.683077
Epoch - 0, step #000096/000234	Loss: 0.647572
Epoch - 0, step #000097/000234	Loss: 0.506038
Epoch - 0, step #000098/000234	Loss: 0.727430
Epoch - 0, step #000099/000234	Loss: 0.784896
Epoch - 0, step #000100/000234	Loss: 0.597430
Epoch - 0, step #000101/000234	Loss: 0.556558
Epoch - 0, step #000102/000234	Loss: 0.576811
Epoch - 0, step #000103/000234	Loss: 0.632284
Epoch - 0, step #000104/000234	Loss: 0.547989
Epoch - 0, step #000105/000234	Loss: 0.654986
Epoch - 0, step #000106/000234	Loss: 0.688338
Epoch - 0, step #000107/000234	Loss: 0.572814
Epoch - 0, step #000108/000234	Loss: 0.563667
Epoch - 0, step #000109/000234	Loss: 0.677321
Epoch - 0, step #000110/000234	Loss: 0.625152
Epoch - 0, step #000111/000234	Loss: 0.622643
Epoch - 0, step #000112/000234	Loss: 0.597154
Epoch - 0, step #000113/000234	Loss: 0.586923
Epoch - 0, step #000114/000234	Loss: 0.589928
Epoch - 0, step #000115/000234	Loss: 0.623674
Epoch - 0, step #000116/000234	Loss: 0.487921
Epoch - 0, step #000117/000234	Loss: 0.532484
Epoch - 0, step #000118/000234	Loss: 0.545136
Epoch - 0, step #000119/000234	Loss: 0.589044
Epoch - 0, step #000120/000234	Loss: 0.540045
Epoch - 0, step #000121/000234	Loss: 0.678635
Epoch - 0, step #000122/000234	Loss: 0.453748
Epoch - 0, step #000123/000234	Loss: 0.620432
Epoch - 0, step #000124/000234	Loss: 0.682070
Epoch - 0, step #000125/000234	Loss: 0.656120
Epoch - 0, step #000126/000234	Loss: 0.583760
Epoch - 0, step #000127/000234	Loss: 0.563725
Epoch - 0, step #000128/000234	Loss: 0.582565
Epoch - 0, step #000129/000234	Loss: 0.600830
Epoch - 0, step #000130/000234	Loss: 0.458171
Epoch - 0, step #000131/000234	Loss: 0.490310
Epoch - 0, step #000132/000234	Loss: 0.534310
Epoch - 0, step #000133/000234	Loss: 0.553033
Epoch - 0, step #000134/000234	Loss: 0.484909
Epoch - 0, step #000135/000234	Loss: 0.503031
Epoch - 0, step #000136/000234	Loss: 0.551449
Epoch - 0, step #000137/000234	Loss: 0.607126
Epoch - 0, step #000138/000234	Loss: 0.484389
Epoch - 0, step #000139/000234	Loss: 0.554773
Epoch - 0, step #000140/000234	Loss: 0.686841
Epoch - 0, step #000141/000234	Loss: 0.488966
Epoch - 0, step #000142/000234	Loss: 0.539794
Epoch - 0, step #000143/000234	Loss: 0.566076
Epoch - 0, step #000144/000234	Loss: 0.684625
Epoch - 0, step #000145/000234	Loss: 0.567686
Epoch - 0, step #000146/000234	Loss: 0.644264
Epoch - 0, step #000147/000234	Loss: 0.456341
Epoch - 0, step #000148/000234	Loss: 0.529021
Epoch - 0, step #000149/000234	Loss: 0.646508
Epoch - 0, step #000150/000234	Loss: 0.542793
Epoch - 0, step #000151/000234	Loss: 0.574695
Epoch - 0, step #000152/000234	Loss: 0.479799
Epoch - 0, step #000153/000234	Loss: 0.452862
Epoch - 0, step #000154/000234	Loss: 0.464777
Epoch - 0, step #000155/000234	Loss: 0.520235
Epoch - 0, step #000156/000234	Loss: 0.447072
Epoch - 0, step #000157/000234	Loss: 0.547966
Epoch - 0, step #000158/000234	Loss: 0.605644
Epoch - 0, step #000159/000234	Loss: 0.548137
Epoch - 0, step #000160/000234	Loss: 0.580981
Epoch - 0, step #000161/000234	Loss: 0.512233
Epoch - 0, step #000162/000234	Loss: 0.533341
Epoch - 0, step #000163/000234	Loss: 0.429588
Epoch - 0, step #000164/000234	Loss: 0.539598
Epoch - 0, step #000165/000234	Loss: 0.658665
Epoch - 0, step #000166/000234	Loss: 0.463920
Epoch - 0, step #000167/000234	Loss: 0.530908
Epoch - 0, step #000168/000234	Loss: 0.619158
Epoch - 0, step #000169/000234	Loss: 0.470504
Epoch - 0, step #000170/000234	Loss: 0.598066
Epoch - 0, step #000171/000234	Loss: 0.570205
Epoch - 0, step #000172/000234	Loss: 0.432257
Epoch - 0, step #000173/000234	Loss: 0.468888
Epoch - 0, step #000174/000234	Loss: 0.560975
Epoch - 0, step #000175/000234	Loss: 0.578388
Epoch - 0, step #000176/000234	Loss: 0.495477
Epoch - 0, step #000177/000234	Loss: 0.546938
Epoch - 0, step #000178/000234	Loss: 0.566224
Epoch - 0, step #000179/000234	Loss: 0.547767
Epoch - 0, step #000180/000234	Loss: 0.547891
Epoch - 0, step #000181/000234	Loss: 0.501181
Epoch - 0, step #000182/000234	Loss: 0.412450
Epoch - 0, step #000183/000234	Loss: 0.435733
Epoch - 0, step #000184/000234	Loss: 0.457639
Epoch - 0, step #000185/000234	Loss: 0.534526
Epoch - 0, step #000186/000234	Loss: 0.509076
Epoch - 0, step #000187/000234	Loss: 0.486326
Epoch - 0, step #000188/000234	Loss: 0.506668
Epoch - 0, step #000189/000234	Loss: 0.420938
Epoch - 0, step #000190/000234	Loss: 0.518123
Epoch - 0, step #000191/000234	Loss: 0.624111
Epoch - 0, step #000192/000234	Loss: 0.415681
Epoch - 0, step #000193/000234	Loss: 0.355032
Epoch - 0, step #000194/000234	Loss: 0.479272
Epoch - 0, step #000195/000234	Loss: 0.478232
Epoch - 0, step #000196/000234	Loss: 0.463642
Epoch - 0, step #000197/000234	Loss: 0.365514
Epoch - 0, step #000198/000234	Loss: 0.457632
Epoch - 0, step #000199/000234	Loss: 0.488452
Epoch - 0, step #000200/000234	Loss: 0.464987
Epoch - 0, step #000201/000234	Loss: 0.432441
Epoch - 0, step #000202/000234	Loss: 0.393445
Epoch - 0, step #000203/000234	Loss: 0.456239
Epoch - 0, step #000204/000234	Loss: 0.424250
Epoch - 0, step #000205/000234	Loss: 0.514627
Epoch - 0, step #000206/000234	Loss: 0.501355
Epoch - 0, step #000207/000234	Loss: 0.377231
Epoch - 0, step #000208/000234	Loss: 0.476826
Epoch - 0, step #000209/000234	Loss: 0.477245
Epoch - 0, step #000210/000234	Loss: 0.428532
Epoch - 0, step #000211/000234	Loss: 0.478535
Epoch - 0, step #000212/000234	Loss: 0.480047
Epoch - 0, step #000213/000234	Loss: 0.353804
Epoch - 0, step #000214/000234	Loss: 0.441356
Epoch - 0, step #000215/000234	Loss: 0.359218
Epoch - 0, step #000216/000234	Loss: 0.477465
Epoch - 0, step #000217/000234	Loss: 0.464676
Epoch - 0, step #000218/000234	Loss: 0.448512
Epoch - 0, step #000219/000234	Loss: 0.291969
Epoch - 0, step #000220/000234	Loss: 0.521968
Epoch - 0, step #000221/000234	Loss: 0.436064
Epoch - 0, step #000222/000234	Loss: 0.455657
Epoch - 0, step #000223/000234	Loss: 0.481347
Epoch - 0, step #000224/000234	Loss: 0.374248
Epoch - 0, step #000225/000234	Loss: 0.451865
Epoch - 0, step #000226/000234	Loss: 0.372077
Epoch - 0, step #000227/000234	Loss: 0.409476
Epoch - 0, step #000228/000234	Loss: 0.384562
Epoch - 0, step #000229/000234	Loss: 0.361293
Epoch - 0, step #000230/000234	Loss: 0.405751
Epoch - 0, step #000231/000234	Loss: 0.476324
Epoch - 0, step #000232/000234	Loss: 0.466942
Epoch - 0, step #000233/000234	Loss: 0.527433
E[0], train Loss: 0.845585, training Acc: 0.733, val loss: 0.282, val Acc: 0.920	 Time: 21.248 seconds
Epoch - 1, step #000000/000234	Loss: 0.452929
Epoch - 1, step #000001/000234	Loss: 0.534688
Epoch - 1, step #000002/000234	Loss: 0.361937
Epoch - 1, step #000003/000234	Loss: 0.401707
Epoch - 1, step #000004/000234	Loss: 0.399507
Epoch - 1, step #000005/000234	Loss: 0.408110
Epoch - 1, step #000006/000234	Loss: 0.426295
Epoch - 1, step #000007/000234	Loss: 0.405462
Epoch - 1, step #000008/000234	Loss: 0.437428
Epoch - 1, step #000009/000234	Loss: 0.386309
Epoch - 1, step #000010/000234	Loss: 0.400817
Epoch - 1, step #000011/000234	Loss: 0.453795
Epoch - 1, step #000012/000234	Loss: 0.394669
Epoch - 1, step #000013/000234	Loss: 0.456368
Epoch - 1, step #000014/000234	Loss: 0.430439
Epoch - 1, step #000015/000234	Loss: 0.423497
Epoch - 1, step #000016/000234	Loss: 0.456536
Epoch - 1, step #000017/000234	Loss: 0.428399
Epoch - 1, step #000018/000234	Loss: 0.312788
Epoch - 1, step #000019/000234	Loss: 0.476243
Epoch - 1, step #000020/000234	Loss: 0.389564
Epoch - 1, step #000021/000234	Loss: 0.523480
Epoch - 1, step #000022/000234	Loss: 0.395721
Epoch - 1, step #000023/000234	Loss: 0.383839
Epoch - 1, step #000024/000234	Loss: 0.424863
Epoch - 1, step #000025/000234	Loss: 0.481519
Epoch - 1, step #000026/000234	Loss: 0.335017
Epoch - 1, step #000027/000234	Loss: 0.470948
Epoch - 1, step #000028/000234	Loss: 0.455461
Epoch - 1, step #000029/000234	Loss: 0.476809
Epoch - 1, step #000030/000234	Loss: 0.467062
Epoch - 1, step #000031/000234	Loss: 0.412128
Epoch - 1, step #000032/000234	Loss: 0.401299
Epoch - 1, step #000033/000234	Loss: 0.519456
Epoch - 1, step #000034/000234	Loss: 0.379849
Epoch - 1, step #000035/000234	Loss: 0.496240
Epoch - 1, step #000036/000234	Loss: 0.479525
Epoch - 1, step #000037/000234	Loss: 0.444468
Epoch - 1, step #000038/000234	Loss: 0.402213
Epoch - 1, step #000039/000234	Loss: 0.437066
Epoch - 1, step #000040/000234	Loss: 0.400139
Epoch - 1, step #000041/000234	Loss: 0.373516
Epoch - 1, step #000042/000234	Loss: 0.401728
Epoch - 1, step #000043/000234	Loss: 0.436632
Epoch - 1, step #000044/000234	Loss: 0.429366
Epoch - 1, step #000045/000234	Loss: 0.438448
Epoch - 1, step #000046/000234	Loss: 0.405365
Epoch - 1, step #000047/000234	Loss: 0.508943
Epoch - 1, step #000048/000234	Loss: 0.444889
Epoch - 1, step #000049/000234	Loss: 0.407205
Epoch - 1, step #000050/000234	Loss: 0.435461
Epoch - 1, step #000051/000234	Loss: 0.362668
Epoch - 1, step #000052/000234	Loss: 0.366754
Epoch - 1, step #000053/000234	Loss: 0.483009
Epoch - 1, step #000054/000234	Loss: 0.370144
Epoch - 1, step #000055/000234	Loss: 0.470285
Epoch - 1, step #000056/000234	Loss: 0.473215
Epoch - 1, step #000057/000234	Loss: 0.361863
Epoch - 1, step #000058/000234	Loss: 0.459245
Epoch - 1, step #000059/000234	Loss: 0.394309
Epoch - 1, step #000060/000234	Loss: 0.432698
Epoch - 1, step #000061/000234	Loss: 0.437039
Epoch - 1, step #000062/000234	Loss: 0.356772
Epoch - 1, step #000063/000234	Loss: 0.493009
Epoch - 1, step #000064/000234	Loss: 0.379605
Epoch - 1, step #000065/000234	Loss: 0.409077
Epoch - 1, step #000066/000234	Loss: 0.342774
Epoch - 1, step #000067/000234	Loss: 0.340199
Epoch - 1, step #000068/000234	Loss: 0.394875
Epoch - 1, step #000069/000234	Loss: 0.410567
Epoch - 1, step #000070/000234	Loss: 0.460738
Epoch - 1, step #000071/000234	Loss: 0.470189
Epoch - 1, step #000072/000234	Loss: 0.329059
Epoch - 1, step #000073/000234	Loss: 0.387188
Epoch - 1, step #000074/000234	Loss: 0.394863
Epoch - 1, step #000075/000234	Loss: 0.379710
Epoch - 1, step #000076/000234	Loss: 0.400347
Epoch - 1, step #000077/000234	Loss: 0.313290
Epoch - 1, step #000078/000234	Loss: 0.373740
Epoch - 1, step #000079/000234	Loss: 0.248257
Epoch - 1, step #000080/000234	Loss: 0.394206
Epoch - 1, step #000081/000234	Loss: 0.333023
Epoch - 1, step #000082/000234	Loss: 0.441487
Epoch - 1, step #000083/000234	Loss: 0.424632
Epoch - 1, step #000084/000234	Loss: 0.465922
Epoch - 1, step #000085/000234	Loss: 0.448566
Epoch - 1, step #000086/000234	Loss: 0.423549
Epoch - 1, step #000087/000234	Loss: 0.367482
Epoch - 1, step #000088/000234	Loss: 0.440583
Epoch - 1, step #000089/000234	Loss: 0.365025
Epoch - 1, step #000090/000234	Loss: 0.366920
Epoch - 1, step #000091/000234	Loss: 0.344296
Epoch - 1, step #000092/000234	Loss: 0.359997
Epoch - 1, step #000093/000234	Loss: 0.452779
Epoch - 1, step #000094/000234	Loss: 0.379771
Epoch - 1, step #000095/000234	Loss: 0.443354
Epoch - 1, step #000096/000234	Loss: 0.351076
Epoch - 1, step #000097/000234	Loss: 0.349130
Epoch - 1, step #000098/000234	Loss: 0.363026
Epoch - 1, step #000099/000234	Loss: 0.309903
Epoch - 1, step #000100/000234	Loss: 0.354184
Epoch - 1, step #000101/000234	Loss: 0.329105
Epoch - 1, step #000102/000234	Loss: 0.302071
Epoch - 1, step #000103/000234	Loss: 0.413625
Epoch - 1, step #000104/000234	Loss: 0.461389
Epoch - 1, step #000105/000234	Loss: 0.415507
Epoch - 1, step #000106/000234	Loss: 0.442900
Epoch - 1, step #000107/000234	Loss: 0.439382
Epoch - 1, step #000108/000234	Loss: 0.448857
Epoch - 1, step #000109/000234	Loss: 0.444121
Epoch - 1, step #000110/000234	Loss: 0.364208
Epoch - 1, step #000111/000234	Loss: 0.369723
Epoch - 1, step #000112/000234	Loss: 0.426876
Epoch - 1, step #000113/000234	Loss: 0.320625
Epoch - 1, step #000114/000234	Loss: 0.352281
Epoch - 1, step #000115/000234	Loss: 0.361007
Epoch - 1, step #000116/000234	Loss: 0.313460
Epoch - 1, step #000117/000234	Loss: 0.404361
Epoch - 1, step #000118/000234	Loss: 0.369584
Epoch - 1, step #000119/000234	Loss: 0.384020
Epoch - 1, step #000120/000234	Loss: 0.529330
Epoch - 1, step #000121/000234	Loss: 0.399891
Epoch - 1, step #000122/000234	Loss: 0.542816
Epoch - 1, step #000123/000234	Loss: 0.382531
Epoch - 1, step #000124/000234	Loss: 0.379210
Epoch - 1, step #000125/000234	Loss: 0.502843
Epoch - 1, step #000126/000234	Loss: 0.412759
Epoch - 1, step #000127/000234	Loss: 0.458487
Epoch - 1, step #000128/000234	Loss: 0.383493
Epoch - 1, step #000129/000234	Loss: 0.331806
Epoch - 1, step #000130/000234	Loss: 0.448924
Epoch - 1, step #000131/000234	Loss: 0.377879
Epoch - 1, step #000132/000234	Loss: 0.438343
Epoch - 1, step #000133/000234	Loss: 0.405045
Epoch - 1, step #000134/000234	Loss: 0.345007
Epoch - 1, step #000135/000234	Loss: 0.387211
Epoch - 1, step #000136/000234	Loss: 0.489541
Epoch - 1, step #000137/000234	Loss: 0.372747
Epoch - 1, step #000138/000234	Loss: 0.408597
Epoch - 1, step #000139/000234	Loss: 0.316823
Epoch - 1, step #000140/000234	Loss: 0.312072
Epoch - 1, step #000141/000234	Loss: 0.394194
Epoch - 1, step #000142/000234	Loss: 0.393288
Epoch - 1, step #000143/000234	Loss: 0.334428
Epoch - 1, step #000144/000234	Loss: 0.477070
Epoch - 1, step #000145/000234	Loss: 0.333996
Epoch - 1, step #000146/000234	Loss: 0.333148
Epoch - 1, step #000147/000234	Loss: 0.459502
Epoch - 1, step #000148/000234	Loss: 0.319901
Epoch - 1, step #000149/000234	Loss: 0.444971
Epoch - 1, step #000150/000234	Loss: 0.415237
Epoch - 1, step #000151/000234	Loss: 0.417070
Epoch - 1, step #000152/000234	Loss: 0.346906
Epoch - 1, step #000153/000234	Loss: 0.339847
Epoch - 1, step #000154/000234	Loss: 0.308665
Epoch - 1, step #000155/000234	Loss: 0.422692
Epoch - 1, step #000156/000234	Loss: 0.418805
Epoch - 1, step #000157/000234	Loss: 0.566149
Epoch - 1, step #000158/000234	Loss: 0.392057
Epoch - 1, step #000159/000234	Loss: 0.489344
Epoch - 1, step #000160/000234	Loss: 0.501706
Epoch - 1, step #000161/000234	Loss: 0.540052
Epoch - 1, step #000162/000234	Loss: 0.511025
Epoch - 1, step #000163/000234	Loss: 0.401872
Epoch - 1, step #000164/000234	Loss: 0.531358
Epoch - 1, step #000165/000234	Loss: 0.327655
Epoch - 1, step #000166/000234	Loss: 0.378571
Epoch - 1, step #000167/000234	Loss: 0.352960
Epoch - 1, step #000168/000234	Loss: 0.345489
Epoch - 1, step #000169/000234	Loss: 0.445508
Epoch - 1, step #000170/000234	Loss: 0.302524
Epoch - 1, step #000171/000234	Loss: 0.361563
Epoch - 1, step #000172/000234	Loss: 0.398720
Epoch - 1, step #000173/000234	Loss: 0.400631
Epoch - 1, step #000174/000234	Loss: 0.386463
Epoch - 1, step #000175/000234	Loss: 0.321914
Epoch - 1, step #000176/000234	Loss: 0.308249
Epoch - 1, step #000177/000234	Loss: 0.386532
Epoch - 1, step #000178/000234	Loss: 0.309615
Epoch - 1, step #000179/000234	Loss: 0.427173
Epoch - 1, step #000180/000234	Loss: 0.397046
Epoch - 1, step #000181/000234	Loss: 0.443105
Epoch - 1, step #000182/000234	Loss: 0.355222
Epoch - 1, step #000183/000234	Loss: 0.399840
Epoch - 1, step #000184/000234	Loss: 0.349120
Epoch - 1, step #000185/000234	Loss: 0.287710
Epoch - 1, step #000186/000234	Loss: 0.334252
Epoch - 1, step #000187/000234	Loss: 0.432195
Epoch - 1, step #000188/000234	Loss: 0.271484
Epoch - 1, step #000189/000234	Loss: 0.292244
Epoch - 1, step #000190/000234	Loss: 0.338929
Epoch - 1, step #000191/000234	Loss: 0.337600
Epoch - 1, step #000192/000234	Loss: 0.404089
Epoch - 1, step #000193/000234	Loss: 0.287129
Epoch - 1, step #000194/000234	Loss: 0.372100
Epoch - 1, step #000195/000234	Loss: 0.323606
Epoch - 1, step #000196/000234	Loss: 0.358494
Epoch - 1, step #000197/000234	Loss: 0.411009
Epoch - 1, step #000198/000234	Loss: 0.344266
Epoch - 1, step #000199/000234	Loss: 0.294289
Epoch - 1, step #000200/000234	Loss: 0.337767
Epoch - 1, step #000201/000234	Loss: 0.322991
Epoch - 1, step #000202/000234	Loss: 0.304250
Epoch - 1, step #000203/000234	Loss: 0.352383
Epoch - 1, step #000204/000234	Loss: 0.434680
Epoch - 1, step #000205/000234	Loss: 0.476488
Epoch - 1, step #000206/000234	Loss: 0.259294
Epoch - 1, step #000207/000234	Loss: 0.291777
Epoch - 1, step #000208/000234	Loss: 0.373166
Epoch - 1, step #000209/000234	Loss: 0.364339
Epoch - 1, step #000210/000234	Loss: 0.347829
Epoch - 1, step #000211/000234	Loss: 0.359909
Epoch - 1, step #000212/000234	Loss: 0.321173
Epoch - 1, step #000213/000234	Loss: 0.374384
Epoch - 1, step #000214/000234	Loss: 0.297528
Epoch - 1, step #000215/000234	Loss: 0.341495
Epoch - 1, step #000216/000234	Loss: 0.323722
Epoch - 1, step #000217/000234	Loss: 0.373209
Epoch - 1, step #000218/000234	Loss: 0.293722
Epoch - 1, step #000219/000234	Loss: 0.415708
Epoch - 1, step #000220/000234	Loss: 0.268911
Epoch - 1, step #000221/000234	Loss: 0.341201
Epoch - 1, step #000222/000234	Loss: 0.288760
Epoch - 1, step #000223/000234	Loss: 0.364522
Epoch - 1, step #000224/000234	Loss: 0.381064
Epoch - 1, step #000225/000234	Loss: 0.319025
Epoch - 1, step #000226/000234	Loss: 0.324300
Epoch - 1, step #000227/000234	Loss: 0.325886
Epoch - 1, step #000228/000234	Loss: 0.347328
Epoch - 1, step #000229/000234	Loss: 0.450171
Epoch - 1, step #000230/000234	Loss: 0.348358
Epoch - 1, step #000231/000234	Loss: 0.350611
Epoch - 1, step #000232/000234	Loss: 0.451790
Epoch - 1, step #000233/000234	Loss: 0.333349
E[1], train Loss: 0.393208, training Acc: 0.879, val loss: 0.212, val Acc: 0.940	 Time: 10.272 seconds
Epoch - 2, step #000000/000234	Loss: 0.246729
Epoch - 2, step #000001/000234	Loss: 0.381711
Epoch - 2, step #000002/000234	Loss: 0.293622
Epoch - 2, step #000003/000234	Loss: 0.387360
Epoch - 2, step #000004/000234	Loss: 0.302286
Epoch - 2, step #000005/000234	Loss: 0.312856
Epoch - 2, step #000006/000234	Loss: 0.396387
Epoch - 2, step #000007/000234	Loss: 0.343785
Epoch - 2, step #000008/000234	Loss: 0.302340
Epoch - 2, step #000009/000234	Loss: 0.314179
Epoch - 2, step #000010/000234	Loss: 0.372843
Epoch - 2, step #000011/000234	Loss: 0.306949
Epoch - 2, step #000012/000234	Loss: 0.432583
Epoch - 2, step #000013/000234	Loss: 0.337261
Epoch - 2, step #000014/000234	Loss: 0.318841
Epoch - 2, step #000015/000234	Loss: 0.283442
Epoch - 2, step #000016/000234	Loss: 0.433952
Epoch - 2, step #000017/000234	Loss: 0.304726
Epoch - 2, step #000018/000234	Loss: 0.310940
Epoch - 2, step #000019/000234	Loss: 0.386990
Epoch - 2, step #000020/000234	Loss: 0.439683
Epoch - 2, step #000021/000234	Loss: 0.326100
Epoch - 2, step #000022/000234	Loss: 0.407604
Epoch - 2, step #000023/000234	Loss: 0.407290
Epoch - 2, step #000024/000234	Loss: 0.383609
Epoch - 2, step #000025/000234	Loss: 0.394255
Epoch - 2, step #000026/000234	Loss: 0.330457
Epoch - 2, step #000027/000234	Loss: 0.472133
Epoch - 2, step #000028/000234	Loss: 0.414387
Epoch - 2, step #000029/000234	Loss: 0.360845
Epoch - 2, step #000030/000234	Loss: 0.320703
Epoch - 2, step #000031/000234	Loss: 0.351859
Epoch - 2, step #000032/000234	Loss: 0.261540
Epoch - 2, step #000033/000234	Loss: 0.249296
Epoch - 2, step #000034/000234	Loss: 0.372686
Epoch - 2, step #000035/000234	Loss: 0.310325
Epoch - 2, step #000036/000234	Loss: 0.217947
Epoch - 2, step #000037/000234	Loss: 0.394295
Epoch - 2, step #000038/000234	Loss: 0.355012
Epoch - 2, step #000039/000234	Loss: 0.305617
Epoch - 2, step #000040/000234	Loss: 0.277904
Epoch - 2, step #000041/000234	Loss: 0.241248
Epoch - 2, step #000042/000234	Loss: 0.476042
Epoch - 2, step #000043/000234	Loss: 0.472480
Epoch - 2, step #000044/000234	Loss: 0.389022
Epoch - 2, step #000045/000234	Loss: 0.426731
Epoch - 2, step #000046/000234	Loss: 0.401328
Epoch - 2, step #000047/000234	Loss: 0.276082
Epoch - 2, step #000048/000234	Loss: 0.360424
Epoch - 2, step #000049/000234	Loss: 0.391789
Epoch - 2, step #000050/000234	Loss: 0.335149
Epoch - 2, step #000051/000234	Loss: 0.388047
Epoch - 2, step #000052/000234	Loss: 0.249600
Epoch - 2, step #000053/000234	Loss: 0.286510
Epoch - 2, step #000054/000234	Loss: 0.401870
Epoch - 2, step #000055/000234	Loss: 0.310224
Epoch - 2, step #000056/000234	Loss: 0.381850
Epoch - 2, step #000057/000234	Loss: 0.332410
Epoch - 2, step #000058/000234	Loss: 0.274529
Epoch - 2, step #000059/000234	Loss: 0.304753
Epoch - 2, step #000060/000234	Loss: 0.336431
Epoch - 2, step #000061/000234	Loss: 0.476892
Epoch - 2, step #000062/000234	Loss: 0.302993
Epoch - 2, step #000063/000234	Loss: 0.331049
Epoch - 2, step #000064/000234	Loss: 0.293721
Epoch - 2, step #000065/000234	Loss: 0.346928
Epoch - 2, step #000066/000234	Loss: 0.350068
Epoch - 2, step #000067/000234	Loss: 0.411891
Epoch - 2, step #000068/000234	Loss: 0.332612
Epoch - 2, step #000069/000234	Loss: 0.259611
Epoch - 2, step #000070/000234	Loss: 0.275909
Epoch - 2, step #000071/000234	Loss: 0.247875
Epoch - 2, step #000072/000234	Loss: 0.411801
Epoch - 2, step #000073/000234	Loss: 0.434335
Epoch - 2, step #000074/000234	Loss: 0.354486
Epoch - 2, step #000075/000234	Loss: 0.324481
Epoch - 2, step #000076/000234	Loss: 0.445020
Epoch - 2, step #000077/000234	Loss: 0.289695
Epoch - 2, step #000078/000234	Loss: 0.481104
Epoch - 2, step #000079/000234	Loss: 0.323189
Epoch - 2, step #000080/000234	Loss: 0.358992
Epoch - 2, step #000081/000234	Loss: 0.311808
Epoch - 2, step #000082/000234	Loss: 0.376281
Epoch - 2, step #000083/000234	Loss: 0.328194
Epoch - 2, step #000084/000234	Loss: 0.322813
Epoch - 2, step #000085/000234	Loss: 0.287610
Epoch - 2, step #000086/000234	Loss: 0.380713
Epoch - 2, step #000087/000234	Loss: 0.376919
Epoch - 2, step #000088/000234	Loss: 0.336590
Epoch - 2, step #000089/000234	Loss: 0.291553
Epoch - 2, step #000090/000234	Loss: 0.357327
Epoch - 2, step #000091/000234	Loss: 0.421340
Epoch - 2, step #000092/000234	Loss: 0.502475
Epoch - 2, step #000093/000234	Loss: 0.371372
Epoch - 2, step #000094/000234	Loss: 0.343039
Epoch - 2, step #000095/000234	Loss: 0.283146
Epoch - 2, step #000096/000234	Loss: 0.256970
Epoch - 2, step #000097/000234	Loss: 0.300990
Epoch - 2, step #000098/000234	Loss: 0.427577
Epoch - 2, step #000099/000234	Loss: 0.347194
Epoch - 2, step #000100/000234	Loss: 0.346335
Epoch - 2, step #000101/000234	Loss: 0.363050
Epoch - 2, step #000102/000234	Loss: 0.374352
Epoch - 2, step #000103/000234	Loss: 0.313374
Epoch - 2, step #000104/000234	Loss: 0.293666
Epoch - 2, step #000105/000234	Loss: 0.366648
Epoch - 2, step #000106/000234	Loss: 0.339294
Epoch - 2, step #000107/000234	Loss: 0.296515
Epoch - 2, step #000108/000234	Loss: 0.287053
Epoch - 2, step #000109/000234	Loss: 0.335869
Epoch - 2, step #000110/000234	Loss: 0.369492
Epoch - 2, step #000111/000234	Loss: 0.360391
Epoch - 2, step #000112/000234	Loss: 0.285536
Epoch - 2, step #000113/000234	Loss: 0.429596
Epoch - 2, step #000114/000234	Loss: 0.382359
Epoch - 2, step #000115/000234	Loss: 0.506195
Epoch - 2, step #000116/000234	Loss: 0.554802
Epoch - 2, step #000117/000234	Loss: 0.260035
Epoch - 2, step #000118/000234	Loss: 0.392606
Epoch - 2, step #000119/000234	Loss: 0.317652
Epoch - 2, step #000120/000234	Loss: 0.288497
Epoch - 2, step #000121/000234	Loss: 0.264030
Epoch - 2, step #000122/000234	Loss: 0.296113
Epoch - 2, step #000123/000234	Loss: 0.315391
Epoch - 2, step #000124/000234	Loss: 0.344062
Epoch - 2, step #000125/000234	Loss: 0.358305
Epoch - 2, step #000126/000234	Loss: 0.380079
Epoch - 2, step #000127/000234	Loss: 0.363900
Epoch - 2, step #000128/000234	Loss: 0.365147
Epoch - 2, step #000129/000234	Loss: 0.333408
Epoch - 2, step #000130/000234	Loss: 0.360092
Epoch - 2, step #000131/000234	Loss: 0.250741
Epoch - 2, step #000132/000234	Loss: 0.310720
Epoch - 2, step #000133/000234	Loss: 0.364042
Epoch - 2, step #000134/000234	Loss: 0.379650
Epoch - 2, step #000135/000234	Loss: 0.380952
Epoch - 2, step #000136/000234	Loss: 0.305663
Epoch - 2, step #000137/000234	Loss: 0.325442
Epoch - 2, step #000138/000234	Loss: 0.294972
Epoch - 2, step #000139/000234	Loss: 0.363629
Epoch - 2, step #000140/000234	Loss: 0.401658
Epoch - 2, step #000141/000234	Loss: 0.339719
Epoch - 2, step #000142/000234	Loss: 0.414838
Epoch - 2, step #000143/000234	Loss: 0.289997
Epoch - 2, step #000144/000234	Loss: 0.398883
Epoch - 2, step #000145/000234	Loss: 0.337252
Epoch - 2, step #000146/000234	Loss: 0.279083
Epoch - 2, step #000147/000234	Loss: 0.399721
Epoch - 2, step #000148/000234	Loss: 0.326136
Epoch - 2, step #000149/000234	Loss: 0.372225
Epoch - 2, step #000150/000234	Loss: 0.317056
Epoch - 2, step #000151/000234	Loss: 0.228819
Epoch - 2, step #000152/000234	Loss: 0.327332
Epoch - 2, step #000153/000234	Loss: 0.323751
Epoch - 2, step #000154/000234	Loss: 0.331293
Epoch - 2, step #000155/000234	Loss: 0.329044
Epoch - 2, step #000156/000234	Loss: 0.186801
Epoch - 2, step #000157/000234	Loss: 0.312223
Epoch - 2, step #000158/000234	Loss: 0.346996
Epoch - 2, step #000159/000234	Loss: 0.337161
Epoch - 2, step #000160/000234	Loss: 0.433382
Epoch - 2, step #000161/000234	Loss: 0.307382
Epoch - 2, step #000162/000234	Loss: 0.443558
Epoch - 2, step #000163/000234	Loss: 0.277055
Epoch - 2, step #000164/000234	Loss: 0.339278
Epoch - 2, step #000165/000234	Loss: 0.287941
Epoch - 2, step #000166/000234	Loss: 0.392667
Epoch - 2, step #000167/000234	Loss: 0.388863
Epoch - 2, step #000168/000234	Loss: 0.340293
Epoch - 2, step #000169/000234	Loss: 0.312495
Epoch - 2, step #000170/000234	Loss: 0.276493
Epoch - 2, step #000171/000234	Loss: 0.262282
Epoch - 2, step #000172/000234	Loss: 0.461549
Epoch - 2, step #000173/000234	Loss: 0.377590
Epoch - 2, step #000174/000234	Loss: 0.427300
Epoch - 2, step #000175/000234	Loss: 0.304071
Epoch - 2, step #000176/000234	Loss: 0.229836
Epoch - 2, step #000177/000234	Loss: 0.392758
Epoch - 2, step #000178/000234	Loss: 0.342039
Epoch - 2, step #000179/000234	Loss: 0.365537
Epoch - 2, step #000180/000234	Loss: 0.285373
Epoch - 2, step #000181/000234	Loss: 0.246426
Epoch - 2, step #000182/000234	Loss: 0.472640
Epoch - 2, step #000183/000234	Loss: 0.380448
Epoch - 2, step #000184/000234	Loss: 0.338902
Epoch - 2, step #000185/000234	Loss: 0.320431
Epoch - 2, step #000186/000234	Loss: 0.311840
Epoch - 2, step #000187/000234	Loss: 0.419505
Epoch - 2, step #000188/000234	Loss: 0.265537
Epoch - 2, step #000189/000234	Loss: 0.253079
Epoch - 2, step #000190/000234	Loss: 0.362816
Epoch - 2, step #000191/000234	Loss: 0.265350
Epoch - 2, step #000192/000234	Loss: 0.378418
Epoch - 2, step #000193/000234	Loss: 0.247411
Epoch - 2, step #000194/000234	Loss: 0.265270
Epoch - 2, step #000195/000234	Loss: 0.411718
Epoch - 2, step #000196/000234	Loss: 0.314905
Epoch - 2, step #000197/000234	Loss: 0.265255
Epoch - 2, step #000198/000234	Loss: 0.259420
Epoch - 2, step #000199/000234	Loss: 0.338519
Epoch - 2, step #000200/000234	Loss: 0.302795
Epoch - 2, step #000201/000234	Loss: 0.301716
Epoch - 2, step #000202/000234	Loss: 0.243210
Epoch - 2, step #000203/000234	Loss: 0.219313
Epoch - 2, step #000204/000234	Loss: 0.204542
Epoch - 2, step #000205/000234	Loss: 0.303495
Epoch - 2, step #000206/000234	Loss: 0.303429
Epoch - 2, step #000207/000234	Loss: 0.304068
Epoch - 2, step #000208/000234	Loss: 0.336670
Epoch - 2, step #000209/000234	Loss: 0.369056
Epoch - 2, step #000210/000234	Loss: 0.294584
Epoch - 2, step #000211/000234	Loss: 0.292992
Epoch - 2, step #000212/000234	Loss: 0.257395
Epoch - 2, step #000213/000234	Loss: 0.183173
Epoch - 2, step #000214/000234	Loss: 0.299762
Epoch - 2, step #000215/000234	Loss: 0.382833
Epoch - 2, step #000216/000234	Loss: 0.371231
Epoch - 2, step #000217/000234	Loss: 0.337712
Epoch - 2, step #000218/000234	Loss: 0.358163
Epoch - 2, step #000219/000234	Loss: 0.407646
Epoch - 2, step #000220/000234	Loss: 0.245659
Epoch - 2, step #000221/000234	Loss: 0.335892
Epoch - 2, step #000222/000234	Loss: 0.204483
Epoch - 2, step #000223/000234	Loss: 0.345870
Epoch - 2, step #000224/000234	Loss: 0.219319
Epoch - 2, step #000225/000234	Loss: 0.226230
Epoch - 2, step #000226/000234	Loss: 0.279717
Epoch - 2, step #000227/000234	Loss: 0.327725
Epoch - 2, step #000228/000234	Loss: 0.305811
Epoch - 2, step #000229/000234	Loss: 0.369488
Epoch - 2, step #000230/000234	Loss: 0.254725
Epoch - 2, step #000231/000234	Loss: 0.400333
Epoch - 2, step #000232/000234	Loss: 0.311057
Epoch - 2, step #000233/000234	Loss: 0.237669
E[2], train Loss: 0.336579, training Acc: 0.898, val loss: 0.177, val Acc: 0.949	 Time: 10.002 seconds
Epoch - 3, step #000000/000234	Loss: 0.344457
Epoch - 3, step #000001/000234	Loss: 0.284622
Epoch - 3, step #000002/000234	Loss: 0.266459
Epoch - 3, step #000003/000234	Loss: 0.260718
Epoch - 3, step #000004/000234	Loss: 0.286924
Epoch - 3, step #000005/000234	Loss: 0.238154
Epoch - 3, step #000006/000234	Loss: 0.302833
Epoch - 3, step #000007/000234	Loss: 0.323961
Epoch - 3, step #000008/000234	Loss: 0.245684
Epoch - 3, step #000009/000234	Loss: 0.273417
Epoch - 3, step #000010/000234	Loss: 0.242731
Epoch - 3, step #000011/000234	Loss: 0.365709
Epoch - 3, step #000012/000234	Loss: 0.288479
Epoch - 3, step #000013/000234	Loss: 0.245750
Epoch - 3, step #000014/000234	Loss: 0.391836
Epoch - 3, step #000015/000234	Loss: 0.304929
Epoch - 3, step #000016/000234	Loss: 0.251225
Epoch - 3, step #000017/000234	Loss: 0.321089
Epoch - 3, step #000018/000234	Loss: 0.378474
Epoch - 3, step #000019/000234	Loss: 0.218506
Epoch - 3, step #000020/000234	Loss: 0.248154
Epoch - 3, step #000021/000234	Loss: 0.207783
Epoch - 3, step #000022/000234	Loss: 0.271373
Epoch - 3, step #000023/000234	Loss: 0.283559
Epoch - 3, step #000024/000234	Loss: 0.327533
Epoch - 3, step #000025/000234	Loss: 0.298910
Epoch - 3, step #000026/000234	Loss: 0.364909
Epoch - 3, step #000027/000234	Loss: 0.239358
Epoch - 3, step #000028/000234	Loss: 0.244198
Epoch - 3, step #000029/000234	Loss: 0.320027
Epoch - 3, step #000030/000234	Loss: 0.314455
Epoch - 3, step #000031/000234	Loss: 0.375233
Epoch - 3, step #000032/000234	Loss: 0.261657
Epoch - 3, step #000033/000234	Loss: 0.310155
Epoch - 3, step #000034/000234	Loss: 0.221233
Epoch - 3, step #000035/000234	Loss: 0.337741
Epoch - 3, step #000036/000234	Loss: 0.258245
Epoch - 3, step #000037/000234	Loss: 0.275676
Epoch - 3, step #000038/000234	Loss: 0.403982
Epoch - 3, step #000039/000234	Loss: 0.364464
Epoch - 3, step #000040/000234	Loss: 0.380787
Epoch - 3, step #000041/000234	Loss: 0.329701
Epoch - 3, step #000042/000234	Loss: 0.266577
Epoch - 3, step #000043/000234	Loss: 0.317727
Epoch - 3, step #000044/000234	Loss: 0.273121
Epoch - 3, step #000045/000234	Loss: 0.303728
Epoch - 3, step #000046/000234	Loss: 0.330938
Epoch - 3, step #000047/000234	Loss: 0.385650
Epoch - 3, step #000048/000234	Loss: 0.245577
Epoch - 3, step #000049/000234	Loss: 0.328919
Epoch - 3, step #000050/000234	Loss: 0.354933
Epoch - 3, step #000051/000234	Loss: 0.391287
Epoch - 3, step #000052/000234	Loss: 0.362440
Epoch - 3, step #000053/000234	Loss: 0.334005
Epoch - 3, step #000054/000234	Loss: 0.340520
Epoch - 3, step #000055/000234	Loss: 0.315987
Epoch - 3, step #000056/000234	Loss: 0.374973
Epoch - 3, step #000057/000234	Loss: 0.294498
Epoch - 3, step #000058/000234	Loss: 0.272153
Epoch - 3, step #000059/000234	Loss: 0.303677
Epoch - 3, step #000060/000234	Loss: 0.296129
Epoch - 3, step #000061/000234	Loss: 0.266123
Epoch - 3, step #000062/000234	Loss: 0.300593
Epoch - 3, step #000063/000234	Loss: 0.276185
Epoch - 3, step #000064/000234	Loss: 0.365769
Epoch - 3, step #000065/000234	Loss: 0.350852
Epoch - 3, step #000066/000234	Loss: 0.249284
Epoch - 3, step #000067/000234	Loss: 0.356024
Epoch - 3, step #000068/000234	Loss: 0.364129
Epoch - 3, step #000069/000234	Loss: 0.234540
Epoch - 3, step #000070/000234	Loss: 0.273418
Epoch - 3, step #000071/000234	Loss: 0.306555
Epoch - 3, step #000072/000234	Loss: 0.222477
Epoch - 3, step #000073/000234	Loss: 0.325896
Epoch - 3, step #000074/000234	Loss: 0.347285
Epoch - 3, step #000075/000234	Loss: 0.365352
Epoch - 3, step #000076/000234	Loss: 0.397724
Epoch - 3, step #000077/000234	Loss: 0.251061
Epoch - 3, step #000078/000234	Loss: 0.349513
Epoch - 3, step #000079/000234	Loss: 0.428474
Epoch - 3, step #000080/000234	Loss: 0.262353
Epoch - 3, step #000081/000234	Loss: 0.296769
Epoch - 3, step #000082/000234	Loss: 0.339902
Epoch - 3, step #000083/000234	Loss: 0.266899
Epoch - 3, step #000084/000234	Loss: 0.306466
Epoch - 3, step #000085/000234	Loss: 0.272286
Epoch - 3, step #000086/000234	Loss: 0.313855
Epoch - 3, step #000087/000234	Loss: 0.334512
Epoch - 3, step #000088/000234	Loss: 0.319366
Epoch - 3, step #000089/000234	Loss: 0.315908
Epoch - 3, step #000090/000234	Loss: 0.342890
Epoch - 3, step #000091/000234	Loss: 0.297037
Epoch - 3, step #000092/000234	Loss: 0.246190
Epoch - 3, step #000093/000234	Loss: 0.336389
Epoch - 3, step #000094/000234	Loss: 0.327859
Epoch - 3, step #000095/000234	Loss: 0.276332
Epoch - 3, step #000096/000234	Loss: 0.269582
Epoch - 3, step #000097/000234	Loss: 0.400442
Epoch - 3, step #000098/000234	Loss: 0.256432
Epoch - 3, step #000099/000234	Loss: 0.385189
Epoch - 3, step #000100/000234	Loss: 0.325947
Epoch - 3, step #000101/000234	Loss: 0.314488
Epoch - 3, step #000102/000234	Loss: 0.283347
Epoch - 3, step #000103/000234	Loss: 0.308521
Epoch - 3, step #000104/000234	Loss: 0.296188
Epoch - 3, step #000105/000234	Loss: 0.246162
Epoch - 3, step #000106/000234	Loss: 0.293574
Epoch - 3, step #000107/000234	Loss: 0.311266
Epoch - 3, step #000108/000234	Loss: 0.381364
Epoch - 3, step #000109/000234	Loss: 0.359843
Epoch - 3, step #000110/000234	Loss: 0.235322
Epoch - 3, step #000111/000234	Loss: 0.328795
Epoch - 3, step #000112/000234	Loss: 0.275698
Epoch - 3, step #000113/000234	Loss: 0.302943
Epoch - 3, step #000114/000234	Loss: 0.293719
Epoch - 3, step #000115/000234	Loss: 0.296961
Epoch - 3, step #000116/000234	Loss: 0.329535
Epoch - 3, step #000117/000234	Loss: 0.394701
Epoch - 3, step #000118/000234	Loss: 0.245056
Epoch - 3, step #000119/000234	Loss: 0.351971
Epoch - 3, step #000120/000234	Loss: 0.377213
Epoch - 3, step #000121/000234	Loss: 0.300619
Epoch - 3, step #000122/000234	Loss: 0.266585
Epoch - 3, step #000123/000234	Loss: 0.234103
Epoch - 3, step #000124/000234	Loss: 0.388879
Epoch - 3, step #000125/000234	Loss: 0.245865
Epoch - 3, step #000126/000234	Loss: 0.277861
Epoch - 3, step #000127/000234	Loss: 0.295793
Epoch - 3, step #000128/000234	Loss: 0.306064
Epoch - 3, step #000129/000234	Loss: 0.462935
Epoch - 3, step #000130/000234	Loss: 0.304676
Epoch - 3, step #000131/000234	Loss: 0.394425
Epoch - 3, step #000132/000234	Loss: 0.233247
Epoch - 3, step #000133/000234	Loss: 0.249453
Epoch - 3, step #000134/000234	Loss: 0.252860
Epoch - 3, step #000135/000234	Loss: 0.214673
Epoch - 3, step #000136/000234	Loss: 0.424267
Epoch - 3, step #000137/000234	Loss: 0.250490
Epoch - 3, step #000138/000234	Loss: 0.197905
Epoch - 3, step #000139/000234	Loss: 0.258866
Epoch - 3, step #000140/000234	Loss: 0.292358
Epoch - 3, step #000141/000234	Loss: 0.278888
Epoch - 3, step #000142/000234	Loss: 0.282037
Epoch - 3, step #000143/000234	Loss: 0.337443
Epoch - 3, step #000144/000234	Loss: 0.329334
Epoch - 3, step #000145/000234	Loss: 0.276812
Epoch - 3, step #000146/000234	Loss: 0.318482
Epoch - 3, step #000147/000234	Loss: 0.300333
Epoch - 3, step #000148/000234	Loss: 0.316143
Epoch - 3, step #000149/000234	Loss: 0.378291
Epoch - 3, step #000150/000234	Loss: 0.309425
Epoch - 3, step #000151/000234	Loss: 0.287198
Epoch - 3, step #000152/000234	Loss: 0.346973
Epoch - 3, step #000153/000234	Loss: 0.283768
Epoch - 3, step #000154/000234	Loss: 0.304699
Epoch - 3, step #000155/000234	Loss: 0.191725
Epoch - 3, step #000156/000234	Loss: 0.292502
Epoch - 3, step #000157/000234	Loss: 0.356706
Epoch - 3, step #000158/000234	Loss: 0.351450
Epoch - 3, step #000159/000234	Loss: 0.296320
Epoch - 3, step #000160/000234	Loss: 0.236055
Epoch - 3, step #000161/000234	Loss: 0.303662
Epoch - 3, step #000162/000234	Loss: 0.307903
Epoch - 3, step #000163/000234	Loss: 0.378169
Epoch - 3, step #000164/000234	Loss: 0.294069
Epoch - 3, step #000165/000234	Loss: 0.278522
Epoch - 3, step #000166/000234	Loss: 0.256593
Epoch - 3, step #000167/000234	Loss: 0.249047
Epoch - 3, step #000168/000234	Loss: 0.319795
Epoch - 3, step #000169/000234	Loss: 0.353155
Epoch - 3, step #000170/000234	Loss: 0.249528
Epoch - 3, step #000171/000234	Loss: 0.319483
Epoch - 3, step #000172/000234	Loss: 0.304893
Epoch - 3, step #000173/000234	Loss: 0.310855
Epoch - 3, step #000174/000234	Loss: 0.360864
Epoch - 3, step #000175/000234	Loss: 0.242021
Epoch - 3, step #000176/000234	Loss: 0.322528
Epoch - 3, step #000177/000234	Loss: 0.278371
Epoch - 3, step #000178/000234	Loss: 0.242929
Epoch - 3, step #000179/000234	Loss: 0.304478
Epoch - 3, step #000180/000234	Loss: 0.312945
Epoch - 3, step #000181/000234	Loss: 0.285207
Epoch - 3, step #000182/000234	Loss: 0.339608
Epoch - 3, step #000183/000234	Loss: 0.340934
Epoch - 3, step #000184/000234	Loss: 0.248001
Epoch - 3, step #000185/000234	Loss: 0.205940
Epoch - 3, step #000186/000234	Loss: 0.292057
Epoch - 3, step #000187/000234	Loss: 0.332300
Epoch - 3, step #000188/000234	Loss: 0.279190
Epoch - 3, step #000189/000234	Loss: 0.262463
Epoch - 3, step #000190/000234	Loss: 0.228843
Epoch - 3, step #000191/000234	Loss: 0.300476
Epoch - 3, step #000192/000234	Loss: 0.268386
Epoch - 3, step #000193/000234	Loss: 0.311059
Epoch - 3, step #000194/000234	Loss: 0.204326
Epoch - 3, step #000195/000234	Loss: 0.296091
Epoch - 3, step #000196/000234	Loss: 0.227758
Epoch - 3, step #000197/000234	Loss: 0.248341
Epoch - 3, step #000198/000234	Loss: 0.211017
Epoch - 3, step #000199/000234	Loss: 0.216748
Epoch - 3, step #000200/000234	Loss: 0.269457
Epoch - 3, step #000201/000234	Loss: 0.341407
Epoch - 3, step #000202/000234	Loss: 0.255384
Epoch - 3, step #000203/000234	Loss: 0.318910
Epoch - 3, step #000204/000234	Loss: 0.203998
Epoch - 3, step #000205/000234	Loss: 0.202316
Epoch - 3, step #000206/000234	Loss: 0.188184
Epoch - 3, step #000207/000234	Loss: 0.275436
Epoch - 3, step #000208/000234	Loss: 0.383619
Epoch - 3, step #000209/000234	Loss: 0.306147
Epoch - 3, step #000210/000234	Loss: 0.237010
Epoch - 3, step #000211/000234	Loss: 0.252820
Epoch - 3, step #000212/000234	Loss: 0.252335
Epoch - 3, step #000213/000234	Loss: 0.247242
Epoch - 3, step #000214/000234	Loss: 0.202441
Epoch - 3, step #000215/000234	Loss: 0.285146
Epoch - 3, step #000216/000234	Loss: 0.220506
Epoch - 3, step #000217/000234	Loss: 0.183336
Epoch - 3, step #000218/000234	Loss: 0.340102
Epoch - 3, step #000219/000234	Loss: 0.222877
Epoch - 3, step #000220/000234	Loss: 0.265474
Epoch - 3, step #000221/000234	Loss: 0.248130
Epoch - 3, step #000222/000234	Loss: 0.198551
Epoch - 3, step #000223/000234	Loss: 0.221041
Epoch - 3, step #000224/000234	Loss: 0.298158
Epoch - 3, step #000225/000234	Loss: 0.226959
Epoch - 3, step #000226/000234	Loss: 0.230446
Epoch - 3, step #000227/000234	Loss: 0.335591
Epoch - 3, step #000228/000234	Loss: 0.288291
Epoch - 3, step #000229/000234	Loss: 0.335491
Epoch - 3, step #000230/000234	Loss: 0.244451
Epoch - 3, step #000231/000234	Loss: 0.349130
Epoch - 3, step #000232/000234	Loss: 0.215349
Epoch - 3, step #000233/000234	Loss: 0.385697
E[3], train Loss: 0.296431, training Acc: 0.911, val loss: 0.156, val Acc: 0.955	 Time: 10.162 seconds
Epoch - 4, step #000000/000234	Loss: 0.361248
Epoch - 4, step #000001/000234	Loss: 0.250881
Epoch - 4, step #000002/000234	Loss: 0.243579
Epoch - 4, step #000003/000234	Loss: 0.207256
Epoch - 4, step #000004/000234	Loss: 0.175726
Epoch - 4, step #000005/000234	Loss: 0.351709
Epoch - 4, step #000006/000234	Loss: 0.241892
Epoch - 4, step #000007/000234	Loss: 0.350084
Epoch - 4, step #000008/000234	Loss: 0.262968
Epoch - 4, step #000009/000234	Loss: 0.205676
Epoch - 4, step #000010/000234	Loss: 0.371528
Epoch - 4, step #000011/000234	Loss: 0.230594
Epoch - 4, step #000012/000234	Loss: 0.269110
Epoch - 4, step #000013/000234	Loss: 0.274897
Epoch - 4, step #000014/000234	Loss: 0.272394
Epoch - 4, step #000015/000234	Loss: 0.242323
Epoch - 4, step #000016/000234	Loss: 0.225487
Epoch - 4, step #000017/000234	Loss: 0.274114
Epoch - 4, step #000018/000234	Loss: 0.244460
Epoch - 4, step #000019/000234	Loss: 0.313947
Epoch - 4, step #000020/000234	Loss: 0.209441
Epoch - 4, step #000021/000234	Loss: 0.347316
Epoch - 4, step #000022/000234	Loss: 0.391565
Epoch - 4, step #000023/000234	Loss: 0.268910
Epoch - 4, step #000024/000234	Loss: 0.295370
Epoch - 4, step #000025/000234	Loss: 0.281674
Epoch - 4, step #000026/000234	Loss: 0.269362
Epoch - 4, step #000027/000234	Loss: 0.350875
Epoch - 4, step #000028/000234	Loss: 0.472246
Epoch - 4, step #000029/000234	Loss: 0.254246
Epoch - 4, step #000030/000234	Loss: 0.330154
Epoch - 4, step #000031/000234	Loss: 0.270138
Epoch - 4, step #000032/000234	Loss: 0.279432
Epoch - 4, step #000033/000234	Loss: 0.290047
Epoch - 4, step #000034/000234	Loss: 0.277654
Epoch - 4, step #000035/000234	Loss: 0.301642
Epoch - 4, step #000036/000234	Loss: 0.386039
Epoch - 4, step #000037/000234	Loss: 0.229933
Epoch - 4, step #000038/000234	Loss: 0.263022
Epoch - 4, step #000039/000234	Loss: 0.240297
Epoch - 4, step #000040/000234	Loss: 0.241772
Epoch - 4, step #000041/000234	Loss: 0.241432
Epoch - 4, step #000042/000234	Loss: 0.209256
Epoch - 4, step #000043/000234	Loss: 0.218718
Epoch - 4, step #000044/000234	Loss: 0.304316
Epoch - 4, step #000045/000234	Loss: 0.307831
Epoch - 4, step #000046/000234	Loss: 0.300391
Epoch - 4, step #000047/000234	Loss: 0.255627
Epoch - 4, step #000048/000234	Loss: 0.223127
Epoch - 4, step #000049/000234	Loss: 0.280199
Epoch - 4, step #000050/000234	Loss: 0.274438
Epoch - 4, step #000051/000234	Loss: 0.332180
Epoch - 4, step #000052/000234	Loss: 0.250255
Epoch - 4, step #000053/000234	Loss: 0.232883
Epoch - 4, step #000054/000234	Loss: 0.231728
Epoch - 4, step #000055/000234	Loss: 0.223107
Epoch - 4, step #000056/000234	Loss: 0.211562
Epoch - 4, step #000057/000234	Loss: 0.322263
Epoch - 4, step #000058/000234	Loss: 0.263763
Epoch - 4, step #000059/000234	Loss: 0.279099
Epoch - 4, step #000060/000234	Loss: 0.282661
Epoch - 4, step #000061/000234	Loss: 0.293736
Epoch - 4, step #000062/000234	Loss: 0.241821
Epoch - 4, step #000063/000234	Loss: 0.261307
Epoch - 4, step #000064/000234	Loss: 0.292454
Epoch - 4, step #000065/000234	Loss: 0.304214
Epoch - 4, step #000066/000234	Loss: 0.226195
Epoch - 4, step #000067/000234	Loss: 0.338056
Epoch - 4, step #000068/000234	Loss: 0.234094
Epoch - 4, step #000069/000234	Loss: 0.271637
Epoch - 4, step #000070/000234	Loss: 0.277256
Epoch - 4, step #000071/000234	Loss: 0.262479
Epoch - 4, step #000072/000234	Loss: 0.206776
Epoch - 4, step #000073/000234	Loss: 0.391226
Epoch - 4, step #000074/000234	Loss: 0.330924
Epoch - 4, step #000075/000234	Loss: 0.255513
Epoch - 4, step #000076/000234	Loss: 0.282209
Epoch - 4, step #000077/000234	Loss: 0.236226
Epoch - 4, step #000078/000234	Loss: 0.262849
Epoch - 4, step #000079/000234	Loss: 0.233278
Epoch - 4, step #000080/000234	Loss: 0.272652
Epoch - 4, step #000081/000234	Loss: 0.263157
Epoch - 4, step #000082/000234	Loss: 0.272776
Epoch - 4, step #000083/000234	Loss: 0.318596
Epoch - 4, step #000084/000234	Loss: 0.234927
Epoch - 4, step #000085/000234	Loss: 0.337330
Epoch - 4, step #000086/000234	Loss: 0.303686
Epoch - 4, step #000087/000234	Loss: 0.266593
Epoch - 4, step #000088/000234	Loss: 0.336027
Epoch - 4, step #000089/000234	Loss: 0.270684
Epoch - 4, step #000090/000234	Loss: 0.273434
Epoch - 4, step #000091/000234	Loss: 0.268413
Epoch - 4, step #000092/000234	Loss: 0.277940
Epoch - 4, step #000093/000234	Loss: 0.258126
Epoch - 4, step #000094/000234	Loss: 0.211788
Epoch - 4, step #000095/000234	Loss: 0.302482
Epoch - 4, step #000096/000234	Loss: 0.294769
Epoch - 4, step #000097/000234	Loss: 0.204858
Epoch - 4, step #000098/000234	Loss: 0.212948
Epoch - 4, step #000099/000234	Loss: 0.299766
Epoch - 4, step #000100/000234	Loss: 0.298232
Epoch - 4, step #000101/000234	Loss: 0.276425
Epoch - 4, step #000102/000234	Loss: 0.251893
Epoch - 4, step #000103/000234	Loss: 0.263547
Epoch - 4, step #000104/000234	Loss: 0.231904
Epoch - 4, step #000105/000234	Loss: 0.224280
Epoch - 4, step #000106/000234	Loss: 0.244805
Epoch - 4, step #000107/000234	Loss: 0.327101
Epoch - 4, step #000108/000234	Loss: 0.183706
Epoch - 4, step #000109/000234	Loss: 0.271986
Epoch - 4, step #000110/000234	Loss: 0.225547
Epoch - 4, step #000111/000234	Loss: 0.273950
Epoch - 4, step #000112/000234	Loss: 0.175935
Epoch - 4, step #000113/000234	Loss: 0.205125
Epoch - 4, step #000114/000234	Loss: 0.281213
Epoch - 4, step #000115/000234	Loss: 0.314728
Epoch - 4, step #000116/000234	Loss: 0.328834
Epoch - 4, step #000117/000234	Loss: 0.309154
Epoch - 4, step #000118/000234	Loss: 0.276386
Epoch - 4, step #000119/000234	Loss: 0.357551
Epoch - 4, step #000120/000234	Loss: 0.248152
Epoch - 4, step #000121/000234	Loss: 0.313213
Epoch - 4, step #000122/000234	Loss: 0.269248
Epoch - 4, step #000123/000234	Loss: 0.258470
Epoch - 4, step #000124/000234	Loss: 0.217759
Epoch - 4, step #000125/000234	Loss: 0.305011
Epoch - 4, step #000126/000234	Loss: 0.240074
Epoch - 4, step #000127/000234	Loss: 0.462252
Epoch - 4, step #000128/000234	Loss: 0.232540
Epoch - 4, step #000129/000234	Loss: 0.250974
Epoch - 4, step #000130/000234	Loss: 0.244968
Epoch - 4, step #000131/000234	Loss: 0.203867
Epoch - 4, step #000132/000234	Loss: 0.289662
Epoch - 4, step #000133/000234	Loss: 0.267361
Epoch - 4, step #000134/000234	Loss: 0.320370
Epoch - 4, step #000135/000234	Loss: 0.315144
Epoch - 4, step #000136/000234	Loss: 0.283703
Epoch - 4, step #000137/000234	Loss: 0.281065
Epoch - 4, step #000138/000234	Loss: 0.232347
Epoch - 4, step #000139/000234	Loss: 0.208814
Epoch - 4, step #000140/000234	Loss: 0.303803
Epoch - 4, step #000141/000234	Loss: 0.222459
Epoch - 4, step #000142/000234	Loss: 0.266906
Epoch - 4, step #000143/000234	Loss: 0.339066
Epoch - 4, step #000144/000234	Loss: 0.321076
Epoch - 4, step #000145/000234	Loss: 0.228344
Epoch - 4, step #000146/000234	Loss: 0.301100
Epoch - 4, step #000147/000234	Loss: 0.281130
Epoch - 4, step #000148/000234	Loss: 0.268025
Epoch - 4, step #000149/000234	Loss: 0.259102
Epoch - 4, step #000150/000234	Loss: 0.313239
Epoch - 4, step #000151/000234	Loss: 0.288364
Epoch - 4, step #000152/000234	Loss: 0.248997
Epoch - 4, step #000153/000234	Loss: 0.224816
Epoch - 4, step #000154/000234	Loss: 0.293863
Epoch - 4, step #000155/000234	Loss: 0.266662
Epoch - 4, step #000156/000234	Loss: 0.264747
Epoch - 4, step #000157/000234	Loss: 0.263908
Epoch - 4, step #000158/000234	Loss: 0.260145
Epoch - 4, step #000159/000234	Loss: 0.216786
Epoch - 4, step #000160/000234	Loss: 0.266574
Epoch - 4, step #000161/000234	Loss: 0.242471
Epoch - 4, step #000162/000234	Loss: 0.227026
Epoch - 4, step #000163/000234	Loss: 0.297070
Epoch - 4, step #000164/000234	Loss: 0.307239
Epoch - 4, step #000165/000234	Loss: 0.297758
Epoch - 4, step #000166/000234	Loss: 0.245570
Epoch - 4, step #000167/000234	Loss: 0.247944
Epoch - 4, step #000168/000234	Loss: 0.284263
Epoch - 4, step #000169/000234	Loss: 0.325636
Epoch - 4, step #000170/000234	Loss: 0.204420
Epoch - 4, step #000171/000234	Loss: 0.197673
Epoch - 4, step #000172/000234	Loss: 0.210529
Epoch - 4, step #000173/000234	Loss: 0.363814
Epoch - 4, step #000174/000234	Loss: 0.247726
Epoch - 4, step #000175/000234	Loss: 0.286689
Epoch - 4, step #000176/000234	Loss: 0.229736
Epoch - 4, step #000177/000234	Loss: 0.472762
Epoch - 4, step #000178/000234	Loss: 0.288321
Epoch - 4, step #000179/000234	Loss: 0.270194
Epoch - 4, step #000180/000234	Loss: 0.292367
Epoch - 4, step #000181/000234	Loss: 0.258272
Epoch - 4, step #000182/000234	Loss: 0.228113
Epoch - 4, step #000183/000234	Loss: 0.240482
Epoch - 4, step #000184/000234	Loss: 0.215403
Epoch - 4, step #000185/000234	Loss: 0.264648
Epoch - 4, step #000186/000234	Loss: 0.253365
Epoch - 4, step #000187/000234	Loss: 0.222434
Epoch - 4, step #000188/000234	Loss: 0.381449
Epoch - 4, step #000189/000234	Loss: 0.285705
Epoch - 4, step #000190/000234	Loss: 0.313495
Epoch - 4, step #000191/000234	Loss: 0.286036
Epoch - 4, step #000192/000234	Loss: 0.300510
Epoch - 4, step #000193/000234	Loss: 0.294580
Epoch - 4, step #000194/000234	Loss: 0.224180
Epoch - 4, step #000195/000234	Loss: 0.201984
Epoch - 4, step #000196/000234	Loss: 0.190709
Epoch - 4, step #000197/000234	Loss: 0.271499
Epoch - 4, step #000198/000234	Loss: 0.325751
Epoch - 4, step #000199/000234	Loss: 0.249848
Epoch - 4, step #000200/000234	Loss: 0.197280
Epoch - 4, step #000201/000234	Loss: 0.283679
Epoch - 4, step #000202/000234	Loss: 0.255815
Epoch - 4, step #000203/000234	Loss: 0.348600
Epoch - 4, step #000204/000234	Loss: 0.242709
Epoch - 4, step #000205/000234	Loss: 0.257762
Epoch - 4, step #000206/000234	Loss: 0.238369
Epoch - 4, step #000207/000234	Loss: 0.261031
Epoch - 4, step #000208/000234	Loss: 0.155830
Epoch - 4, step #000209/000234	Loss: 0.236005
Epoch - 4, step #000210/000234	Loss: 0.206352
Epoch - 4, step #000211/000234	Loss: 0.235875
Epoch - 4, step #000212/000234	Loss: 0.219302
Epoch - 4, step #000213/000234	Loss: 0.237750
Epoch - 4, step #000214/000234	Loss: 0.298498
Epoch - 4, step #000215/000234	Loss: 0.205602
Epoch - 4, step #000216/000234	Loss: 0.258628
Epoch - 4, step #000217/000234	Loss: 0.254034
Epoch - 4, step #000218/000234	Loss: 0.205799
Epoch - 4, step #000219/000234	Loss: 0.248474
Epoch - 4, step #000220/000234	Loss: 0.266249
Epoch - 4, step #000221/000234	Loss: 0.209844
Epoch - 4, step #000222/000234	Loss: 0.184136
Epoch - 4, step #000223/000234	Loss: 0.266294
Epoch - 4, step #000224/000234	Loss: 0.198832
Epoch - 4, step #000225/000234	Loss: 0.266268
Epoch - 4, step #000226/000234	Loss: 0.307900
Epoch - 4, step #000227/000234	Loss: 0.312091
Epoch - 4, step #000228/000234	Loss: 0.335895
Epoch - 4, step #000229/000234	Loss: 0.259160
Epoch - 4, step #000230/000234	Loss: 0.247816
Epoch - 4, step #000231/000234	Loss: 0.242720
Epoch - 4, step #000232/000234	Loss: 0.177060
Epoch - 4, step #000233/000234	Loss: 0.303512
E[4], train Loss: 0.269181, training Acc: 0.921, val loss: 0.145, val Acc: 0.959	 Time: 9.990 seconds
Epoch - 5, step #000000/000234	Loss: 0.309730
Epoch - 5, step #000001/000234	Loss: 0.300246
Epoch - 5, step #000002/000234	Loss: 0.258016
Epoch - 5, step #000003/000234	Loss: 0.274135
Epoch - 5, step #000004/000234	Loss: 0.298427
Epoch - 5, step #000005/000234	Loss: 0.188581
Epoch - 5, step #000006/000234	Loss: 0.142160
Epoch - 5, step #000007/000234	Loss: 0.274564
Epoch - 5, step #000008/000234	Loss: 0.241165
Epoch - 5, step #000009/000234	Loss: 0.187490
Epoch - 5, step #000010/000234	Loss: 0.262374
Epoch - 5, step #000011/000234	Loss: 0.220111
Epoch - 5, step #000012/000234	Loss: 0.204139
Epoch - 5, step #000013/000234	Loss: 0.273073
Epoch - 5, step #000014/000234	Loss: 0.242089
Epoch - 5, step #000015/000234	Loss: 0.253087
Epoch - 5, step #000016/000234	Loss: 0.203359
Epoch - 5, step #000017/000234	Loss: 0.224852
Epoch - 5, step #000018/000234	Loss: 0.252837
Epoch - 5, step #000019/000234	Loss: 0.265267
Epoch - 5, step #000020/000234	Loss: 0.236261
Epoch - 5, step #000021/000234	Loss: 0.192205
Epoch - 5, step #000022/000234	Loss: 0.253474
Epoch - 5, step #000023/000234	Loss: 0.284168
Epoch - 5, step #000024/000234	Loss: 0.227425
Epoch - 5, step #000025/000234	Loss: 0.239891
Epoch - 5, step #000026/000234	Loss: 0.195389
Epoch - 5, step #000027/000234	Loss: 0.361096
Epoch - 5, step #000028/000234	Loss: 0.182609
Epoch - 5, step #000029/000234	Loss: 0.292978
Epoch - 5, step #000030/000234	Loss: 0.388565
Epoch - 5, step #000031/000234	Loss: 0.245457
Epoch - 5, step #000032/000234	Loss: 0.338597
Epoch - 5, step #000033/000234	Loss: 0.352427
Epoch - 5, step #000034/000234	Loss: 0.168047
Epoch - 5, step #000035/000234	Loss: 0.263727
Epoch - 5, step #000036/000234	Loss: 0.194671
Epoch - 5, step #000037/000234	Loss: 0.313079
Epoch - 5, step #000038/000234	Loss: 0.293572
Epoch - 5, step #000039/000234	Loss: 0.322877
Epoch - 5, step #000040/000234	Loss: 0.276201
Epoch - 5, step #000041/000234	Loss: 0.276721
Epoch - 5, step #000042/000234	Loss: 0.232403
Epoch - 5, step #000043/000234	Loss: 0.340223
Epoch - 5, step #000044/000234	Loss: 0.258482
Epoch - 5, step #000045/000234	Loss: 0.382979
Epoch - 5, step #000046/000234	Loss: 0.232461
Epoch - 5, step #000047/000234	Loss: 0.336252
Epoch - 5, step #000048/000234	Loss: 0.275165
Epoch - 5, step #000049/000234	Loss: 0.222835
Epoch - 5, step #000050/000234	Loss: 0.213519
Epoch - 5, step #000051/000234	Loss: 0.228629
Epoch - 5, step #000052/000234	Loss: 0.289694
Epoch - 5, step #000053/000234	Loss: 0.254507
Epoch - 5, step #000054/000234	Loss: 0.231097
Epoch - 5, step #000055/000234	Loss: 0.296640
Epoch - 5, step #000056/000234	Loss: 0.196804
Epoch - 5, step #000057/000234	Loss: 0.234748
Epoch - 5, step #000058/000234	Loss: 0.194245
Epoch - 5, step #000059/000234	Loss: 0.310390
Epoch - 5, step #000060/000234	Loss: 0.249560
Epoch - 5, step #000061/000234	Loss: 0.176189
Epoch - 5, step #000062/000234	Loss: 0.300722
Epoch - 5, step #000063/000234	Loss: 0.275649
Epoch - 5, step #000064/000234	Loss: 0.204331
Epoch - 5, step #000065/000234	Loss: 0.234266
Epoch - 5, step #000066/000234	Loss: 0.239829
Epoch - 5, step #000067/000234	Loss: 0.196218
Epoch - 5, step #000068/000234	Loss: 0.284610
Epoch - 5, step #000069/000234	Loss: 0.240833
Epoch - 5, step #000070/000234	Loss: 0.245573
Epoch - 5, step #000071/000234	Loss: 0.234072
Epoch - 5, step #000072/000234	Loss: 0.229271
Epoch - 5, step #000073/000234	Loss: 0.310493
Epoch - 5, step #000074/000234	Loss: 0.216633
Epoch - 5, step #000075/000234	Loss: 0.322748
Epoch - 5, step #000076/000234	Loss: 0.345539
Epoch - 5, step #000077/000234	Loss: 0.304162
Epoch - 5, step #000078/000234	Loss: 0.226396
Epoch - 5, step #000079/000234	Loss: 0.162189
Epoch - 5, step #000080/000234	Loss: 0.268845
Epoch - 5, step #000081/000234	Loss: 0.267884
Epoch - 5, step #000082/000234	Loss: 0.199598
Epoch - 5, step #000083/000234	Loss: 0.186713
Epoch - 5, step #000084/000234	Loss: 0.238189
Epoch - 5, step #000085/000234	Loss: 0.197189
Epoch - 5, step #000086/000234	Loss: 0.199789
Epoch - 5, step #000087/000234	Loss: 0.323696
Epoch - 5, step #000088/000234	Loss: 0.229180
Epoch - 5, step #000089/000234	Loss: 0.230109
Epoch - 5, step #000090/000234	Loss: 0.244971
Epoch - 5, step #000091/000234	Loss: 0.225817
Epoch - 5, step #000092/000234	Loss: 0.202766
Epoch - 5, step #000093/000234	Loss: 0.280168
Epoch - 5, step #000094/000234	Loss: 0.320156
Epoch - 5, step #000095/000234	Loss: 0.276703
Epoch - 5, step #000096/000234	Loss: 0.218140
Epoch - 5, step #000097/000234	Loss: 0.308595
Epoch - 5, step #000098/000234	Loss: 0.245052
Epoch - 5, step #000099/000234	Loss: 0.284594
Epoch - 5, step #000100/000234	Loss: 0.221904
Epoch - 5, step #000101/000234	Loss: 0.300658
Epoch - 5, step #000102/000234	Loss: 0.269770
Epoch - 5, step #000103/000234	Loss: 0.188691
Epoch - 5, step #000104/000234	Loss: 0.232149
Epoch - 5, step #000105/000234	Loss: 0.202524
Epoch - 5, step #000106/000234	Loss: 0.235017
Epoch - 5, step #000107/000234	Loss: 0.282572
Epoch - 5, step #000108/000234	Loss: 0.289093
Epoch - 5, step #000109/000234	Loss: 0.330205
Epoch - 5, step #000110/000234	Loss: 0.364343
Epoch - 5, step #000111/000234	Loss: 0.296997
Epoch - 5, step #000112/000234	Loss: 0.226989
Epoch - 5, step #000113/000234	Loss: 0.285531
Epoch - 5, step #000114/000234	Loss: 0.244110
Epoch - 5, step #000115/000234	Loss: 0.206314
Epoch - 5, step #000116/000234	Loss: 0.217376
Epoch - 5, step #000117/000234	Loss: 0.237606
Epoch - 5, step #000118/000234	Loss: 0.244132
Epoch - 5, step #000119/000234	Loss: 0.164098
Epoch - 5, step #000120/000234	Loss: 0.254715
Epoch - 5, step #000121/000234	Loss: 0.354887
Epoch - 5, step #000122/000234	Loss: 0.252013
Epoch - 5, step #000123/000234	Loss: 0.293296
Epoch - 5, step #000124/000234	Loss: 0.375530
Epoch - 5, step #000125/000234	Loss: 0.210974
Epoch - 5, step #000126/000234	Loss: 0.147858
Epoch - 5, step #000127/000234	Loss: 0.219903
Epoch - 5, step #000128/000234	Loss: 0.258991
Epoch - 5, step #000129/000234	Loss: 0.205125
Epoch - 5, step #000130/000234	Loss: 0.211480
Epoch - 5, step #000131/000234	Loss: 0.250276
Epoch - 5, step #000132/000234	Loss: 0.220443
Epoch - 5, step #000133/000234	Loss: 0.189269
Epoch - 5, step #000134/000234	Loss: 0.246770
Epoch - 5, step #000135/000234	Loss: 0.292778
Epoch - 5, step #000136/000234	Loss: 0.239363
Epoch - 5, step #000137/000234	Loss: 0.253107
Epoch - 5, step #000138/000234	Loss: 0.268960
Epoch - 5, step #000139/000234	Loss: 0.285615
Epoch - 5, step #000140/000234	Loss: 0.186714
Epoch - 5, step #000141/000234	Loss: 0.235492
Epoch - 5, step #000142/000234	Loss: 0.277142
Epoch - 5, step #000143/000234	Loss: 0.241363
Epoch - 5, step #000144/000234	Loss: 0.207802
Epoch - 5, step #000145/000234	Loss: 0.242811
Epoch - 5, step #000146/000234	Loss: 0.205942
Epoch - 5, step #000147/000234	Loss: 0.220174
Epoch - 5, step #000148/000234	Loss: 0.298286
Epoch - 5, step #000149/000234	Loss: 0.269461
Epoch - 5, step #000150/000234	Loss: 0.320554
Epoch - 5, step #000151/000234	Loss: 0.230335
Epoch - 5, step #000152/000234	Loss: 0.257783
Epoch - 5, step #000153/000234	Loss: 0.283562
Epoch - 5, step #000154/000234	Loss: 0.304004
Epoch - 5, step #000155/000234	Loss: 0.220563
Epoch - 5, step #000156/000234	Loss: 0.195056
Epoch - 5, step #000157/000234	Loss: 0.308845
Epoch - 5, step #000158/000234	Loss: 0.333822
Epoch - 5, step #000159/000234	Loss: 0.230214
Epoch - 5, step #000160/000234	Loss: 0.288999
Epoch - 5, step #000161/000234	Loss: 0.256887
Epoch - 5, step #000162/000234	Loss: 0.315037
Epoch - 5, step #000163/000234	Loss: 0.223946
Epoch - 5, step #000164/000234	Loss: 0.231281
Epoch - 5, step #000165/000234	Loss: 0.340726
Epoch - 5, step #000166/000234	Loss: 0.166289
Epoch - 5, step #000167/000234	Loss: 0.320753
Epoch - 5, step #000168/000234	Loss: 0.266977
Epoch - 5, step #000169/000234	Loss: 0.226057
Epoch - 5, step #000170/000234	Loss: 0.214574
Epoch - 5, step #000171/000234	Loss: 0.259938
Epoch - 5, step #000172/000234	Loss: 0.217735
Epoch - 5, step #000173/000234	Loss: 0.201715
Epoch - 5, step #000174/000234	Loss: 0.284951
Epoch - 5, step #000175/000234	Loss: 0.227549
Epoch - 5, step #000176/000234	Loss: 0.319042
Epoch - 5, step #000177/000234	Loss: 0.266291
Epoch - 5, step #000178/000234	Loss: 0.259807
Epoch - 5, step #000179/000234	Loss: 0.243114
Epoch - 5, step #000180/000234	Loss: 0.176290
Epoch - 5, step #000181/000234	Loss: 0.266080
Epoch - 5, step #000182/000234	Loss: 0.271684
Epoch - 5, step #000183/000234	Loss: 0.259920
Epoch - 5, step #000184/000234	Loss: 0.163065
Epoch - 5, step #000185/000234	Loss: 0.196124
Epoch - 5, step #000186/000234	Loss: 0.245798
Epoch - 5, step #000187/000234	Loss: 0.277874
Epoch - 5, step #000188/000234	Loss: 0.136162
Epoch - 5, step #000189/000234	Loss: 0.211608
Epoch - 5, step #000190/000234	Loss: 0.284330
Epoch - 5, step #000191/000234	Loss: 0.331000
Epoch - 5, step #000192/000234	Loss: 0.197991
Epoch - 5, step #000193/000234	Loss: 0.172127
Epoch - 5, step #000194/000234	Loss: 0.221074
Epoch - 5, step #000195/000234	Loss: 0.208436
Epoch - 5, step #000196/000234	Loss: 0.140753
Epoch - 5, step #000197/000234	Loss: 0.223801
Epoch - 5, step #000198/000234	Loss: 0.151456
Epoch - 5, step #000199/000234	Loss: 0.234121
Epoch - 5, step #000200/000234	Loss: 0.256287
Epoch - 5, step #000201/000234	Loss: 0.277542
Epoch - 5, step #000202/000234	Loss: 0.265223
Epoch - 5, step #000203/000234	Loss: 0.322043
Epoch - 5, step #000204/000234	Loss: 0.189583
Epoch - 5, step #000205/000234	Loss: 0.224462
Epoch - 5, step #000206/000234	Loss: 0.287630
Epoch - 5, step #000207/000234	Loss: 0.202512
Epoch - 5, step #000208/000234	Loss: 0.234519
Epoch - 5, step #000209/000234	Loss: 0.237372
Epoch - 5, step #000210/000234	Loss: 0.215981
Epoch - 5, step #000211/000234	Loss: 0.242166
Epoch - 5, step #000212/000234	Loss: 0.255906
Epoch - 5, step #000213/000234	Loss: 0.202845
Epoch - 5, step #000214/000234	Loss: 0.193477
Epoch - 5, step #000215/000234	Loss: 0.362770
Epoch - 5, step #000216/000234	Loss: 0.231068
Epoch - 5, step #000217/000234	Loss: 0.280539
Epoch - 5, step #000218/000234	Loss: 0.210874
Epoch - 5, step #000219/000234	Loss: 0.219529
Epoch - 5, step #000220/000234	Loss: 0.312627
Epoch - 5, step #000221/000234	Loss: 0.215136
Epoch - 5, step #000222/000234	Loss: 0.169565
Epoch - 5, step #000223/000234	Loss: 0.163276
Epoch - 5, step #000224/000234	Loss: 0.276092
Epoch - 5, step #000225/000234	Loss: 0.254284
Epoch - 5, step #000226/000234	Loss: 0.216324
Epoch - 5, step #000227/000234	Loss: 0.358324
Epoch - 5, step #000228/000234	Loss: 0.302697
Epoch - 5, step #000229/000234	Loss: 0.227434
Epoch - 5, step #000230/000234	Loss: 0.233474
Epoch - 5, step #000231/000234	Loss: 0.298933
Epoch - 5, step #000232/000234	Loss: 0.254904
Epoch - 5, step #000233/000234	Loss: 0.247375
E[5], train Loss: 0.250167, training Acc: 0.925, val loss: 0.134, val Acc: 0.961	 Time: 10.079 seconds
Epoch - 6, step #000000/000234	Loss: 0.176105
Epoch - 6, step #000001/000234	Loss: 0.244663
Epoch - 6, step #000002/000234	Loss: 0.184646
Epoch - 6, step #000003/000234	Loss: 0.225824
Epoch - 6, step #000004/000234	Loss: 0.147679
Epoch - 6, step #000005/000234	Loss: 0.195517
Epoch - 6, step #000006/000234	Loss: 0.154586
Epoch - 6, step #000007/000234	Loss: 0.170853
Epoch - 6, step #000008/000234	Loss: 0.235986
Epoch - 6, step #000009/000234	Loss: 0.245264
Epoch - 6, step #000010/000234	Loss: 0.236252
Epoch - 6, step #000011/000234	Loss: 0.189912
Epoch - 6, step #000012/000234	Loss: 0.177184
Epoch - 6, step #000013/000234	Loss: 0.204448
Epoch - 6, step #000014/000234	Loss: 0.174561
Epoch - 6, step #000015/000234	Loss: 0.220103
Epoch - 6, step #000016/000234	Loss: 0.270295
Epoch - 6, step #000017/000234	Loss: 0.218936
Epoch - 6, step #000018/000234	Loss: 0.219924
Epoch - 6, step #000019/000234	Loss: 0.348160
Epoch - 6, step #000020/000234	Loss: 0.242370
Epoch - 6, step #000021/000234	Loss: 0.166659
Epoch - 6, step #000022/000234	Loss: 0.226263
Epoch - 6, step #000023/000234	Loss: 0.228263
Epoch - 6, step #000024/000234	Loss: 0.245628
Epoch - 6, step #000025/000234	Loss: 0.218583
Epoch - 6, step #000026/000234	Loss: 0.209934
Epoch - 6, step #000027/000234	Loss: 0.376004
Epoch - 6, step #000028/000234	Loss: 0.291478
Epoch - 6, step #000029/000234	Loss: 0.249080
Epoch - 6, step #000030/000234	Loss: 0.223779
Epoch - 6, step #000031/000234	Loss: 0.243295
Epoch - 6, step #000032/000234	Loss: 0.310688
Epoch - 6, step #000033/000234	Loss: 0.216828
Epoch - 6, step #000034/000234	Loss: 0.245805
Epoch - 6, step #000035/000234	Loss: 0.219863
Epoch - 6, step #000036/000234	Loss: 0.228457
Epoch - 6, step #000037/000234	Loss: 0.250497
Epoch - 6, step #000038/000234	Loss: 0.232704
Epoch - 6, step #000039/000234	Loss: 0.209468
Epoch - 6, step #000040/000234	Loss: 0.172002
Epoch - 6, step #000041/000234	Loss: 0.242412
Epoch - 6, step #000042/000234	Loss: 0.210457
Epoch - 6, step #000043/000234	Loss: 0.218976
Epoch - 6, step #000044/000234	Loss: 0.305742
Epoch - 6, step #000045/000234	Loss: 0.219446
Epoch - 6, step #000046/000234	Loss: 0.335732
Epoch - 6, step #000047/000234	Loss: 0.233156
Epoch - 6, step #000048/000234	Loss: 0.190214
Epoch - 6, step #000049/000234	Loss: 0.329963
Epoch - 6, step #000050/000234	Loss: 0.352143
Epoch - 6, step #000051/000234	Loss: 0.346742
Epoch - 6, step #000052/000234	Loss: 0.169612
Epoch - 6, step #000053/000234	Loss: 0.283135
Epoch - 6, step #000054/000234	Loss: 0.217639
Epoch - 6, step #000055/000234	Loss: 0.161042
Epoch - 6, step #000056/000234	Loss: 0.234673
Epoch - 6, step #000057/000234	Loss: 0.310662
Epoch - 6, step #000058/000234	Loss: 0.222161
Epoch - 6, step #000059/000234	Loss: 0.283219
Epoch - 6, step #000060/000234	Loss: 0.228564
Epoch - 6, step #000061/000234	Loss: 0.301883
Epoch - 6, step #000062/000234	Loss: 0.121407
Epoch - 6, step #000063/000234	Loss: 0.244374
Epoch - 6, step #000064/000234	Loss: 0.230834
Epoch - 6, step #000065/000234	Loss: 0.250698
Epoch - 6, step #000066/000234	Loss: 0.207590
Epoch - 6, step #000067/000234	Loss: 0.170467
Epoch - 6, step #000068/000234	Loss: 0.181731
Epoch - 6, step #000069/000234	Loss: 0.214503
Epoch - 6, step #000070/000234	Loss: 0.225497
Epoch - 6, step #000071/000234	Loss: 0.227351
Epoch - 6, step #000072/000234	Loss: 0.208412
Epoch - 6, step #000073/000234	Loss: 0.169788
Epoch - 6, step #000074/000234	Loss: 0.159983
Epoch - 6, step #000075/000234	Loss: 0.206370
Epoch - 6, step #000076/000234	Loss: 0.234994
Epoch - 6, step #000077/000234	Loss: 0.257044
Epoch - 6, step #000078/000234	Loss: 0.168257
Epoch - 6, step #000079/000234	Loss: 0.288440
Epoch - 6, step #000080/000234	Loss: 0.295068
Epoch - 6, step #000081/000234	Loss: 0.229252
Epoch - 6, step #000082/000234	Loss: 0.200748
Epoch - 6, step #000083/000234	Loss: 0.236526
Epoch - 6, step #000084/000234	Loss: 0.277197
Epoch - 6, step #000085/000234	Loss: 0.233713
Epoch - 6, step #000086/000234	Loss: 0.181875
Epoch - 6, step #000087/000234	Loss: 0.372131
Epoch - 6, step #000088/000234	Loss: 0.176293
Epoch - 6, step #000089/000234	Loss: 0.222879
Epoch - 6, step #000090/000234	Loss: 0.233582
Epoch - 6, step #000091/000234	Loss: 0.172779
Epoch - 6, step #000092/000234	Loss: 0.308607
Epoch - 6, step #000093/000234	Loss: 0.238936
Epoch - 6, step #000094/000234	Loss: 0.326997
Epoch - 6, step #000095/000234	Loss: 0.291758
Epoch - 6, step #000096/000234	Loss: 0.215849
Epoch - 6, step #000097/000234	Loss: 0.284473
Epoch - 6, step #000098/000234	Loss: 0.222889
Epoch - 6, step #000099/000234	Loss: 0.328344
Epoch - 6, step #000100/000234	Loss: 0.204587
Epoch - 6, step #000101/000234	Loss: 0.194510
Epoch - 6, step #000102/000234	Loss: 0.302769
Epoch - 6, step #000103/000234	Loss: 0.262039
Epoch - 6, step #000104/000234	Loss: 0.197077
Epoch - 6, step #000105/000234	Loss: 0.231334
Epoch - 6, step #000106/000234	Loss: 0.233173
Epoch - 6, step #000107/000234	Loss: 0.259054
Epoch - 6, step #000108/000234	Loss: 0.219449
Epoch - 6, step #000109/000234	Loss: 0.246893
Epoch - 6, step #000110/000234	Loss: 0.212879
Epoch - 6, step #000111/000234	Loss: 0.145007
Epoch - 6, step #000112/000234	Loss: 0.333945
Epoch - 6, step #000113/000234	Loss: 0.292178
Epoch - 6, step #000114/000234	Loss: 0.257270
Epoch - 6, step #000115/000234	Loss: 0.254693
Epoch - 6, step #000116/000234	Loss: 0.230115
Epoch - 6, step #000117/000234	Loss: 0.218925
Epoch - 6, step #000118/000234	Loss: 0.203565
Epoch - 6, step #000119/000234	Loss: 0.261345
Epoch - 6, step #000120/000234	Loss: 0.218499
Epoch - 6, step #000121/000234	Loss: 0.297465
Epoch - 6, step #000122/000234	Loss: 0.275969
Epoch - 6, step #000123/000234	Loss: 0.251176
Epoch - 6, step #000124/000234	Loss: 0.244610
Epoch - 6, step #000125/000234	Loss: 0.200392
Epoch - 6, step #000126/000234	Loss: 0.261879
Epoch - 6, step #000127/000234	Loss: 0.214383
Epoch - 6, step #000128/000234	Loss: 0.221979
Epoch - 6, step #000129/000234	Loss: 0.223000
Epoch - 6, step #000130/000234	Loss: 0.279362
Epoch - 6, step #000131/000234	Loss: 0.203017
Epoch - 6, step #000132/000234	Loss: 0.224107
Epoch - 6, step #000133/000234	Loss: 0.204232
Epoch - 6, step #000134/000234	Loss: 0.203108
Epoch - 6, step #000135/000234	Loss: 0.341227
Epoch - 6, step #000136/000234	Loss: 0.268823
Epoch - 6, step #000137/000234	Loss: 0.175468
Epoch - 6, step #000138/000234	Loss: 0.294452
Epoch - 6, step #000139/000234	Loss: 0.178486
Epoch - 6, step #000140/000234	Loss: 0.248366
Epoch - 6, step #000141/000234	Loss: 0.255921
Epoch - 6, step #000142/000234	Loss: 0.186260
Epoch - 6, step #000143/000234	Loss: 0.271266
Epoch - 6, step #000144/000234	Loss: 0.205641
Epoch - 6, step #000145/000234	Loss: 0.255693
Epoch - 6, step #000146/000234	Loss: 0.147069
Epoch - 6, step #000147/000234	Loss: 0.240602
Epoch - 6, step #000148/000234	Loss: 0.278239
Epoch - 6, step #000149/000234	Loss: 0.212331
Epoch - 6, step #000150/000234	Loss: 0.256505
Epoch - 6, step #000151/000234	Loss: 0.190117
Epoch - 6, step #000152/000234	Loss: 0.209287
Epoch - 6, step #000153/000234	Loss: 0.287986
Epoch - 6, step #000154/000234	Loss: 0.226059
Epoch - 6, step #000155/000234	Loss: 0.225573
Epoch - 6, step #000156/000234	Loss: 0.178085
Epoch - 6, step #000157/000234	Loss: 0.256918
Epoch - 6, step #000158/000234	Loss: 0.205232
Epoch - 6, step #000159/000234	Loss: 0.239472
Epoch - 6, step #000160/000234	Loss: 0.357403
Epoch - 6, step #000161/000234	Loss: 0.253892
Epoch - 6, step #000162/000234	Loss: 0.218146
Epoch - 6, step #000163/000234	Loss: 0.220376
Epoch - 6, step #000164/000234	Loss: 0.316661
Epoch - 6, step #000165/000234	Loss: 0.298342
Epoch - 6, step #000166/000234	Loss: 0.269058
Epoch - 6, step #000167/000234	Loss: 0.247897
Epoch - 6, step #000168/000234	Loss: 0.270294
Epoch - 6, step #000169/000234	Loss: 0.259081
Epoch - 6, step #000170/000234	Loss: 0.334758
Epoch - 6, step #000171/000234	Loss: 0.356316
Epoch - 6, step #000172/000234	Loss: 0.188250
Epoch - 6, step #000173/000234	Loss: 0.234081
Epoch - 6, step #000174/000234	Loss: 0.319867
Epoch - 6, step #000175/000234	Loss: 0.302949
Epoch - 6, step #000176/000234	Loss: 0.238835
Epoch - 6, step #000177/000234	Loss: 0.182057
Epoch - 6, step #000178/000234	Loss: 0.316382
Epoch - 6, step #000179/000234	Loss: 0.300315
Epoch - 6, step #000180/000234	Loss: 0.252262
Epoch - 6, step #000181/000234	Loss: 0.264168
Epoch - 6, step #000182/000234	Loss: 0.275319
Epoch - 6, step #000183/000234	Loss: 0.280181
Epoch - 6, step #000184/000234	Loss: 0.263408
Epoch - 6, step #000185/000234	Loss: 0.241326
Epoch - 6, step #000186/000234	Loss: 0.224532
Epoch - 6, step #000187/000234	Loss: 0.165932
Epoch - 6, step #000188/000234	Loss: 0.200866
Epoch - 6, step #000189/000234	Loss: 0.210773
Epoch - 6, step #000190/000234	Loss: 0.277125
Epoch - 6, step #000191/000234	Loss: 0.137323
Epoch - 6, step #000192/000234	Loss: 0.289037
Epoch - 6, step #000193/000234	Loss: 0.199060
Epoch - 6, step #000194/000234	Loss: 0.205215
Epoch - 6, step #000195/000234	Loss: 0.255675
Epoch - 6, step #000196/000234	Loss: 0.259217
Epoch - 6, step #000197/000234	Loss: 0.231597
Epoch - 6, step #000198/000234	Loss: 0.207477
Epoch - 6, step #000199/000234	Loss: 0.201489
Epoch - 6, step #000200/000234	Loss: 0.276300
Epoch - 6, step #000201/000234	Loss: 0.271072
Epoch - 6, step #000202/000234	Loss: 0.199499
Epoch - 6, step #000203/000234	Loss: 0.143089
Epoch - 6, step #000204/000234	Loss: 0.278836
Epoch - 6, step #000205/000234	Loss: 0.187024
Epoch - 6, step #000206/000234	Loss: 0.251516
Epoch - 6, step #000207/000234	Loss: 0.238062
Epoch - 6, step #000208/000234	Loss: 0.206372
Epoch - 6, step #000209/000234	Loss: 0.206074
Epoch - 6, step #000210/000234	Loss: 0.165723
Epoch - 6, step #000211/000234	Loss: 0.216403
Epoch - 6, step #000212/000234	Loss: 0.281883
Epoch - 6, step #000213/000234	Loss: 0.293287
Epoch - 6, step #000214/000234	Loss: 0.215504
Epoch - 6, step #000215/000234	Loss: 0.211176
Epoch - 6, step #000216/000234	Loss: 0.179249
Epoch - 6, step #000217/000234	Loss: 0.191084
Epoch - 6, step #000218/000234	Loss: 0.174171
Epoch - 6, step #000219/000234	Loss: 0.236930
Epoch - 6, step #000220/000234	Loss: 0.229451
Epoch - 6, step #000221/000234	Loss: 0.239778
Epoch - 6, step #000222/000234	Loss: 0.227003
Epoch - 6, step #000223/000234	Loss: 0.203862
Epoch - 6, step #000224/000234	Loss: 0.202909
Epoch - 6, step #000225/000234	Loss: 0.206565
Epoch - 6, step #000226/000234	Loss: 0.167499
Epoch - 6, step #000227/000234	Loss: 0.255509
Epoch - 6, step #000228/000234	Loss: 0.252283
Epoch - 6, step #000229/000234	Loss: 0.190700
Epoch - 6, step #000230/000234	Loss: 0.208628
Epoch - 6, step #000231/000234	Loss: 0.165341
Epoch - 6, step #000232/000234	Loss: 0.325995
Epoch - 6, step #000233/000234	Loss: 0.239910
E[6], train Loss: 0.236105, training Acc: 0.930, val loss: 0.126, val Acc: 0.962	 Time: 10.218 seconds
Epoch - 7, step #000000/000234	Loss: 0.220825
Epoch - 7, step #000001/000234	Loss: 0.175368
Epoch - 7, step #000002/000234	Loss: 0.208614
Epoch - 7, step #000003/000234	Loss: 0.156887
Epoch - 7, step #000004/000234	Loss: 0.206311
Epoch - 7, step #000005/000234	Loss: 0.211572
Epoch - 7, step #000006/000234	Loss: 0.223645
Epoch - 7, step #000007/000234	Loss: 0.265954
Epoch - 7, step #000008/000234	Loss: 0.201257
Epoch - 7, step #000009/000234	Loss: 0.200359
Epoch - 7, step #000010/000234	Loss: 0.233248
Epoch - 7, step #000011/000234	Loss: 0.187326
Epoch - 7, step #000012/000234	Loss: 0.205811
Epoch - 7, step #000013/000234	Loss: 0.214122
Epoch - 7, step #000014/000234	Loss: 0.219336
Epoch - 7, step #000015/000234	Loss: 0.227294
Epoch - 7, step #000016/000234	Loss: 0.231387
Epoch - 7, step #000017/000234	Loss: 0.209082
Epoch - 7, step #000018/000234	Loss: 0.238322
Epoch - 7, step #000019/000234	Loss: 0.289917
Epoch - 7, step #000020/000234	Loss: 0.271597
Epoch - 7, step #000021/000234	Loss: 0.205931
Epoch - 7, step #000022/000234	Loss: 0.248964
Epoch - 7, step #000023/000234	Loss: 0.174906
Epoch - 7, step #000024/000234	Loss: 0.179681
Epoch - 7, step #000025/000234	Loss: 0.263919
Epoch - 7, step #000026/000234	Loss: 0.219714
Epoch - 7, step #000027/000234	Loss: 0.233849
Epoch - 7, step #000028/000234	Loss: 0.254839
Epoch - 7, step #000029/000234	Loss: 0.255449
Epoch - 7, step #000030/000234	Loss: 0.239517
Epoch - 7, step #000031/000234	Loss: 0.202736
Epoch - 7, step #000032/000234	Loss: 0.252946
Epoch - 7, step #000033/000234	Loss: 0.201436
Epoch - 7, step #000034/000234	Loss: 0.272126
Epoch - 7, step #000035/000234	Loss: 0.203840
Epoch - 7, step #000036/000234	Loss: 0.197552
Epoch - 7, step #000037/000234	Loss: 0.190967
Epoch - 7, step #000038/000234	Loss: 0.214242
Epoch - 7, step #000039/000234	Loss: 0.279316
Epoch - 7, step #000040/000234	Loss: 0.232857
Epoch - 7, step #000041/000234	Loss: 0.235192
Epoch - 7, step #000042/000234	Loss: 0.248105
Epoch - 7, step #000043/000234	Loss: 0.212295
Epoch - 7, step #000044/000234	Loss: 0.194446
Epoch - 7, step #000045/000234	Loss: 0.286977
Epoch - 7, step #000046/000234	Loss: 0.179412
Epoch - 7, step #000047/000234	Loss: 0.164411
Epoch - 7, step #000048/000234	Loss: 0.282583
Epoch - 7, step #000049/000234	Loss: 0.179787
Epoch - 7, step #000050/000234	Loss: 0.261472
Epoch - 7, step #000051/000234	Loss: 0.181886
Epoch - 7, step #000052/000234	Loss: 0.189928
Epoch - 7, step #000053/000234	Loss: 0.256484
Epoch - 7, step #000054/000234	Loss: 0.233215
Epoch - 7, step #000055/000234	Loss: 0.215302
Epoch - 7, step #000056/000234	Loss: 0.183351
Epoch - 7, step #000057/000234	Loss: 0.282977
Epoch - 7, step #000058/000234	Loss: 0.187251
Epoch - 7, step #000059/000234	Loss: 0.309666
Epoch - 7, step #000060/000234	Loss: 0.168008
Epoch - 7, step #000061/000234	Loss: 0.182305
Epoch - 7, step #000062/000234	Loss: 0.304790
Epoch - 7, step #000063/000234	Loss: 0.222806
Epoch - 7, step #000064/000234	Loss: 0.262663
Epoch - 7, step #000065/000234	Loss: 0.189692
Epoch - 7, step #000066/000234	Loss: 0.326530
Epoch - 7, step #000067/000234	Loss: 0.188463
Epoch - 7, step #000068/000234	Loss: 0.286162
Epoch - 7, step #000069/000234	Loss: 0.249208
Epoch - 7, step #000070/000234	Loss: 0.288010
Epoch - 7, step #000071/000234	Loss: 0.204099
Epoch - 7, step #000072/000234	Loss: 0.268397
Epoch - 7, step #000073/000234	Loss: 0.196793
Epoch - 7, step #000074/000234	Loss: 0.212008
Epoch - 7, step #000075/000234	Loss: 0.273054
Epoch - 7, step #000076/000234	Loss: 0.248491
Epoch - 7, step #000077/000234	Loss: 0.217164
Epoch - 7, step #000078/000234	Loss: 0.220148
Epoch - 7, step #000079/000234	Loss: 0.239562
Epoch - 7, step #000080/000234	Loss: 0.214736
Epoch - 7, step #000081/000234	Loss: 0.260806
Epoch - 7, step #000082/000234	Loss: 0.231819
Epoch - 7, step #000083/000234	Loss: 0.198465
Epoch - 7, step #000084/000234	Loss: 0.307507
Epoch - 7, step #000085/000234	Loss: 0.176959
Epoch - 7, step #000086/000234	Loss: 0.219817
Epoch - 7, step #000087/000234	Loss: 0.235297
Epoch - 7, step #000088/000234	Loss: 0.197913
Epoch - 7, step #000089/000234	Loss: 0.227759
Epoch - 7, step #000090/000234	Loss: 0.193868
Epoch - 7, step #000091/000234	Loss: 0.243305
Epoch - 7, step #000092/000234	Loss: 0.248036
Epoch - 7, step #000093/000234	Loss: 0.186336
Epoch - 7, step #000094/000234	Loss: 0.195881
Epoch - 7, step #000095/000234	Loss: 0.227128
Epoch - 7, step #000096/000234	Loss: 0.259474
Epoch - 7, step #000097/000234	Loss: 0.211371
Epoch - 7, step #000098/000234	Loss: 0.165503
Epoch - 7, step #000099/000234	Loss: 0.192035
Epoch - 7, step #000100/000234	Loss: 0.240649
Epoch - 7, step #000101/000234	Loss: 0.292322
Epoch - 7, step #000102/000234	Loss: 0.174783
Epoch - 7, step #000103/000234	Loss: 0.249716
Epoch - 7, step #000104/000234	Loss: 0.143354
Epoch - 7, step #000105/000234	Loss: 0.186896
Epoch - 7, step #000106/000234	Loss: 0.213549
Epoch - 7, step #000107/000234	Loss: 0.183295
Epoch - 7, step #000108/000234	Loss: 0.249576
Epoch - 7, step #000109/000234	Loss: 0.160864
Epoch - 7, step #000110/000234	Loss: 0.237982
Epoch - 7, step #000111/000234	Loss: 0.247047
Epoch - 7, step #000112/000234	Loss: 0.181075
Epoch - 7, step #000113/000234	Loss: 0.135554
Epoch - 7, step #000114/000234	Loss: 0.209442
Epoch - 7, step #000115/000234	Loss: 0.346676
Epoch - 7, step #000116/000234	Loss: 0.324962
Epoch - 7, step #000117/000234	Loss: 0.183340
Epoch - 7, step #000118/000234	Loss: 0.278812
Epoch - 7, step #000119/000234	Loss: 0.257842
Epoch - 7, step #000120/000234	Loss: 0.223238
Epoch - 7, step #000121/000234	Loss: 0.196450
Epoch - 7, step #000122/000234	Loss: 0.274040
Epoch - 7, step #000123/000234	Loss: 0.184066
Epoch - 7, step #000124/000234	Loss: 0.325939
Epoch - 7, step #000125/000234	Loss: 0.304376
Epoch - 7, step #000126/000234	Loss: 0.212433
Epoch - 7, step #000127/000234	Loss: 0.260536
Epoch - 7, step #000128/000234	Loss: 0.294660
Epoch - 7, step #000129/000234	Loss: 0.228367
Epoch - 7, step #000130/000234	Loss: 0.235178
Epoch - 7, step #000131/000234	Loss: 0.232790
Epoch - 7, step #000132/000234	Loss: 0.212479
Epoch - 7, step #000133/000234	Loss: 0.262462
Epoch - 7, step #000134/000234	Loss: 0.201999
Epoch - 7, step #000135/000234	Loss: 0.174789
Epoch - 7, step #000136/000234	Loss: 0.130941
Epoch - 7, step #000137/000234	Loss: 0.200825
Epoch - 7, step #000138/000234	Loss: 0.303159
Epoch - 7, step #000139/000234	Loss: 0.220504
Epoch - 7, step #000140/000234	Loss: 0.274002
Epoch - 7, step #000141/000234	Loss: 0.287679
Epoch - 7, step #000142/000234	Loss: 0.278786
Epoch - 7, step #000143/000234	Loss: 0.341166
Epoch - 7, step #000144/000234	Loss: 0.209053
Epoch - 7, step #000145/000234	Loss: 0.329089
Epoch - 7, step #000146/000234	Loss: 0.268275
Epoch - 7, step #000147/000234	Loss: 0.198925
Epoch - 7, step #000148/000234	Loss: 0.230537
Epoch - 7, step #000149/000234	Loss: 0.193712
Epoch - 7, step #000150/000234	Loss: 0.250420
Epoch - 7, step #000151/000234	Loss: 0.204715
Epoch - 7, step #000152/000234	Loss: 0.207508
Epoch - 7, step #000153/000234	Loss: 0.268709
Epoch - 7, step #000154/000234	Loss: 0.146005
Epoch - 7, step #000155/000234	Loss: 0.295010
Epoch - 7, step #000156/000234	Loss: 0.225077
Epoch - 7, step #000157/000234	Loss: 0.220944
Epoch - 7, step #000158/000234	Loss: 0.222321
Epoch - 7, step #000159/000234	Loss: 0.222271
Epoch - 7, step #000160/000234	Loss: 0.197954
Epoch - 7, step #000161/000234	Loss: 0.153225
Epoch - 7, step #000162/000234	Loss: 0.202805
Epoch - 7, step #000163/000234	Loss: 0.208362
Epoch - 7, step #000164/000234	Loss: 0.248026
Epoch - 7, step #000165/000234	Loss: 0.176682
Epoch - 7, step #000166/000234	Loss: 0.320039
Epoch - 7, step #000167/000234	Loss: 0.223734
Epoch - 7, step #000168/000234	Loss: 0.285458
Epoch - 7, step #000169/000234	Loss: 0.143892
Epoch - 7, step #000170/000234	Loss: 0.175011
Epoch - 7, step #000171/000234	Loss: 0.274654
Epoch - 7, step #000172/000234	Loss: 0.218923
Epoch - 7, step #000173/000234	Loss: 0.384809
Epoch - 7, step #000174/000234	Loss: 0.203263
Epoch - 7, step #000175/000234	Loss: 0.320006
Epoch - 7, step #000176/000234	Loss: 0.196720
Epoch - 7, step #000177/000234	Loss: 0.245467
Epoch - 7, step #000178/000234	Loss: 0.239102
Epoch - 7, step #000179/000234	Loss: 0.178041
Epoch - 7, step #000180/000234	Loss: 0.179625
Epoch - 7, step #000181/000234	Loss: 0.198990
Epoch - 7, step #000182/000234	Loss: 0.175447
Epoch - 7, step #000183/000234	Loss: 0.252812
Epoch - 7, step #000184/000234	Loss: 0.275745
Epoch - 7, step #000185/000234	Loss: 0.134678
Epoch - 7, step #000186/000234	Loss: 0.199957
Epoch - 7, step #000187/000234	Loss: 0.279188
Epoch - 7, step #000188/000234	Loss: 0.188969
Epoch - 7, step #000189/000234	Loss: 0.176726
Epoch - 7, step #000190/000234	Loss: 0.278658
Epoch - 7, step #000191/000234	Loss: 0.206801
Epoch - 7, step #000192/000234	Loss: 0.146564
Epoch - 7, step #000193/000234	Loss: 0.211810
Epoch - 7, step #000194/000234	Loss: 0.248047
Epoch - 7, step #000195/000234	Loss: 0.179512
Epoch - 7, step #000196/000234	Loss: 0.189747
Epoch - 7, step #000197/000234	Loss: 0.179710
Epoch - 7, step #000198/000234	Loss: 0.261901
Epoch - 7, step #000199/000234	Loss: 0.273203
Epoch - 7, step #000200/000234	Loss: 0.205502
Epoch - 7, step #000201/000234	Loss: 0.217125
Epoch - 7, step #000202/000234	Loss: 0.256893
Epoch - 7, step #000203/000234	Loss: 0.176829
Epoch - 7, step #000204/000234	Loss: 0.197724
Epoch - 7, step #000205/000234	Loss: 0.220545
Epoch - 7, step #000206/000234	Loss: 0.168901
Epoch - 7, step #000207/000234	Loss: 0.252346
Epoch - 7, step #000208/000234	Loss: 0.260369
Epoch - 7, step #000209/000234	Loss: 0.151632
Epoch - 7, step #000210/000234	Loss: 0.239587
Epoch - 7, step #000211/000234	Loss: 0.287286
Epoch - 7, step #000212/000234	Loss: 0.179755
Epoch - 7, step #000213/000234	Loss: 0.218314
Epoch - 7, step #000214/000234	Loss: 0.216783
Epoch - 7, step #000215/000234	Loss: 0.245819
Epoch - 7, step #000216/000234	Loss: 0.163545
Epoch - 7, step #000217/000234	Loss: 0.260536
Epoch - 7, step #000218/000234	Loss: 0.167491
Epoch - 7, step #000219/000234	Loss: 0.222622
Epoch - 7, step #000220/000234	Loss: 0.194912
Epoch - 7, step #000221/000234	Loss: 0.177624
Epoch - 7, step #000222/000234	Loss: 0.121732
Epoch - 7, step #000223/000234	Loss: 0.231771
Epoch - 7, step #000224/000234	Loss: 0.155338
Epoch - 7, step #000225/000234	Loss: 0.269395
Epoch - 7, step #000226/000234	Loss: 0.213937
Epoch - 7, step #000227/000234	Loss: 0.199330
Epoch - 7, step #000228/000234	Loss: 0.178638
Epoch - 7, step #000229/000234	Loss: 0.281086
Epoch - 7, step #000230/000234	Loss: 0.216411
Epoch - 7, step #000231/000234	Loss: 0.280569
Epoch - 7, step #000232/000234	Loss: 0.288855
Epoch - 7, step #000233/000234	Loss: 0.211217
E[7], train Loss: 0.225496, training Acc: 0.932, val loss: 0.121, val Acc: 0.965	 Time: 10.454 seconds
Epoch - 8, step #000000/000234	Loss: 0.215197
Epoch - 8, step #000001/000234	Loss: 0.267304
Epoch - 8, step #000002/000234	Loss: 0.290103
Epoch - 8, step #000003/000234	Loss: 0.248257
Epoch - 8, step #000004/000234	Loss: 0.165438
Epoch - 8, step #000005/000234	Loss: 0.212232
Epoch - 8, step #000006/000234	Loss: 0.166989
Epoch - 8, step #000007/000234	Loss: 0.279931
Epoch - 8, step #000008/000234	Loss: 0.139532
Epoch - 8, step #000009/000234	Loss: 0.198214
Epoch - 8, step #000010/000234	Loss: 0.171200
Epoch - 8, step #000011/000234	Loss: 0.244973
Epoch - 8, step #000012/000234	Loss: 0.231848
Epoch - 8, step #000013/000234	Loss: 0.242536
Epoch - 8, step #000014/000234	Loss: 0.200445
Epoch - 8, step #000015/000234	Loss: 0.295255
Epoch - 8, step #000016/000234	Loss: 0.183808
Epoch - 8, step #000017/000234	Loss: 0.173905
Epoch - 8, step #000018/000234	Loss: 0.122475
Epoch - 8, step #000019/000234	Loss: 0.207541
Epoch - 8, step #000020/000234	Loss: 0.234983
Epoch - 8, step #000021/000234	Loss: 0.259993
Epoch - 8, step #000022/000234	Loss: 0.219203
Epoch - 8, step #000023/000234	Loss: 0.290082
Epoch - 8, step #000024/000234	Loss: 0.208316
Epoch - 8, step #000025/000234	Loss: 0.246781
Epoch - 8, step #000026/000234	Loss: 0.152564
Epoch - 8, step #000027/000234	Loss: 0.257771
Epoch - 8, step #000028/000234	Loss: 0.155029
Epoch - 8, step #000029/000234	Loss: 0.162916
Epoch - 8, step #000030/000234	Loss: 0.181717
Epoch - 8, step #000031/000234	Loss: 0.218247
Epoch - 8, step #000032/000234	Loss: 0.176685
Epoch - 8, step #000033/000234	Loss: 0.263966
Epoch - 8, step #000034/000234	Loss: 0.188958
Epoch - 8, step #000035/000234	Loss: 0.162346
Epoch - 8, step #000036/000234	Loss: 0.140213
Epoch - 8, step #000037/000234	Loss: 0.288965
Epoch - 8, step #000038/000234	Loss: 0.210308
Epoch - 8, step #000039/000234	Loss: 0.227646
Epoch - 8, step #000040/000234	Loss: 0.214037
Epoch - 8, step #000041/000234	Loss: 0.199067
Epoch - 8, step #000042/000234	Loss: 0.187113
Epoch - 8, step #000043/000234	Loss: 0.201183
Epoch - 8, step #000044/000234	Loss: 0.236067
Epoch - 8, step #000045/000234	Loss: 0.234679
Epoch - 8, step #000046/000234	Loss: 0.296265
Epoch - 8, step #000047/000234	Loss: 0.204301
Epoch - 8, step #000048/000234	Loss: 0.239542
Epoch - 8, step #000049/000234	Loss: 0.185791
Epoch - 8, step #000050/000234	Loss: 0.152380
Epoch - 8, step #000051/000234	Loss: 0.210719
Epoch - 8, step #000052/000234	Loss: 0.245508
Epoch - 8, step #000053/000234	Loss: 0.268460
Epoch - 8, step #000054/000234	Loss: 0.188508
Epoch - 8, step #000055/000234	Loss: 0.209681
Epoch - 8, step #000056/000234	Loss: 0.167084
Epoch - 8, step #000057/000234	Loss: 0.224936
Epoch - 8, step #000058/000234	Loss: 0.208705
Epoch - 8, step #000059/000234	Loss: 0.243489
Epoch - 8, step #000060/000234	Loss: 0.209334
Epoch - 8, step #000061/000234	Loss: 0.216614
Epoch - 8, step #000062/000234	Loss: 0.198416
Epoch - 8, step #000063/000234	Loss: 0.133966
Epoch - 8, step #000064/000234	Loss: 0.305099
Epoch - 8, step #000065/000234	Loss: 0.201003
Epoch - 8, step #000066/000234	Loss: 0.181874
Epoch - 8, step #000067/000234	Loss: 0.241698
Epoch - 8, step #000068/000234	Loss: 0.246708
Epoch - 8, step #000069/000234	Loss: 0.304846
Epoch - 8, step #000070/000234	Loss: 0.161575
Epoch - 8, step #000071/000234	Loss: 0.258775
Epoch - 8, step #000072/000234	Loss: 0.231171
Epoch - 8, step #000073/000234	Loss: 0.264236
Epoch - 8, step #000074/000234	Loss: 0.266898
Epoch - 8, step #000075/000234	Loss: 0.203553
Epoch - 8, step #000076/000234	Loss: 0.205841
Epoch - 8, step #000077/000234	Loss: 0.161074
Epoch - 8, step #000078/000234	Loss: 0.209336
Epoch - 8, step #000079/000234	Loss: 0.316652
Epoch - 8, step #000080/000234	Loss: 0.177467
Epoch - 8, step #000081/000234	Loss: 0.225680
Epoch - 8, step #000082/000234	Loss: 0.158321
Epoch - 8, step #000083/000234	Loss: 0.213806
Epoch - 8, step #000084/000234	Loss: 0.265364
Epoch - 8, step #000085/000234	Loss: 0.228082
Epoch - 8, step #000086/000234	Loss: 0.165868
Epoch - 8, step #000087/000234	Loss: 0.170535
Epoch - 8, step #000088/000234	Loss: 0.273513
Epoch - 8, step #000089/000234	Loss: 0.261920
Epoch - 8, step #000090/000234	Loss: 0.238756
Epoch - 8, step #000091/000234	Loss: 0.296499
Epoch - 8, step #000092/000234	Loss: 0.149861
Epoch - 8, step #000093/000234	Loss: 0.212138
Epoch - 8, step #000094/000234	Loss: 0.212049
Epoch - 8, step #000095/000234	Loss: 0.196503
Epoch - 8, step #000096/000234	Loss: 0.190641
Epoch - 8, step #000097/000234	Loss: 0.235644
Epoch - 8, step #000098/000234	Loss: 0.209445
Epoch - 8, step #000099/000234	Loss: 0.236666
Epoch - 8, step #000100/000234	Loss: 0.180110
Epoch - 8, step #000101/000234	Loss: 0.251146
Epoch - 8, step #000102/000234	Loss: 0.238798
Epoch - 8, step #000103/000234	Loss: 0.218894
Epoch - 8, step #000104/000234	Loss: 0.184791
Epoch - 8, step #000105/000234	Loss: 0.225584
Epoch - 8, step #000106/000234	Loss: 0.290167
Epoch - 8, step #000107/000234	Loss: 0.228482
Epoch - 8, step #000108/000234	Loss: 0.183684
Epoch - 8, step #000109/000234	Loss: 0.246628
Epoch - 8, step #000110/000234	Loss: 0.143895
Epoch - 8, step #000111/000234	Loss: 0.234361
Epoch - 8, step #000112/000234	Loss: 0.315852
Epoch - 8, step #000113/000234	Loss: 0.311081
Epoch - 8, step #000114/000234	Loss: 0.162329
Epoch - 8, step #000115/000234	Loss: 0.242698
Epoch - 8, step #000116/000234	Loss: 0.205711
Epoch - 8, step #000117/000234	Loss: 0.235616
Epoch - 8, step #000118/000234	Loss: 0.180871
Epoch - 8, step #000119/000234	Loss: 0.203514
Epoch - 8, step #000120/000234	Loss: 0.171753
Epoch - 8, step #000121/000234	Loss: 0.244791
Epoch - 8, step #000122/000234	Loss: 0.206951
Epoch - 8, step #000123/000234	Loss: 0.260429
Epoch - 8, step #000124/000234	Loss: 0.168795
Epoch - 8, step #000125/000234	Loss: 0.183516
Epoch - 8, step #000126/000234	Loss: 0.254775
Epoch - 8, step #000127/000234	Loss: 0.181577
Epoch - 8, step #000128/000234	Loss: 0.258570
Epoch - 8, step #000129/000234	Loss: 0.109272
Epoch - 8, step #000130/000234	Loss: 0.222463
Epoch - 8, step #000131/000234	Loss: 0.195694
Epoch - 8, step #000132/000234	Loss: 0.255293
Epoch - 8, step #000133/000234	Loss: 0.158065
Epoch - 8, step #000134/000234	Loss: 0.248937
Epoch - 8, step #000135/000234	Loss: 0.225300
Epoch - 8, step #000136/000234	Loss: 0.288045
Epoch - 8, step #000137/000234	Loss: 0.131406
Epoch - 8, step #000138/000234	Loss: 0.232789
Epoch - 8, step #000139/000234	Loss: 0.213409
Epoch - 8, step #000140/000234	Loss: 0.190531
Epoch - 8, step #000141/000234	Loss: 0.261429
Epoch - 8, step #000142/000234	Loss: 0.198653
Epoch - 8, step #000143/000234	Loss: 0.250411
Epoch - 8, step #000144/000234	Loss: 0.191337
Epoch - 8, step #000145/000234	Loss: 0.165754
Epoch - 8, step #000146/000234	Loss: 0.190518
Epoch - 8, step #000147/000234	Loss: 0.178699
Epoch - 8, step #000148/000234	Loss: 0.269420
Epoch - 8, step #000149/000234	Loss: 0.215569
Epoch - 8, step #000150/000234	Loss: 0.244484
Epoch - 8, step #000151/000234	Loss: 0.153449
Epoch - 8, step #000152/000234	Loss: 0.224005
Epoch - 8, step #000153/000234	Loss: 0.171338
Epoch - 8, step #000154/000234	Loss: 0.248978
Epoch - 8, step #000155/000234	Loss: 0.272133
Epoch - 8, step #000156/000234	Loss: 0.207700
Epoch - 8, step #000157/000234	Loss: 0.286955
Epoch - 8, step #000158/000234	Loss: 0.200554
Epoch - 8, step #000159/000234	Loss: 0.233542
Epoch - 8, step #000160/000234	Loss: 0.232279
Epoch - 8, step #000161/000234	Loss: 0.261739
Epoch - 8, step #000162/000234	Loss: 0.163533
Epoch - 8, step #000163/000234	Loss: 0.240550
Epoch - 8, step #000164/000234	Loss: 0.187579
Epoch - 8, step #000165/000234	Loss: 0.188886
Epoch - 8, step #000166/000234	Loss: 0.202380
Epoch - 8, step #000167/000234	Loss: 0.267612
Epoch - 8, step #000168/000234	Loss: 0.175961
Epoch - 8, step #000169/000234	Loss: 0.267618
Epoch - 8, step #000170/000234	Loss: 0.181075
Epoch - 8, step #000171/000234	Loss: 0.211426
Epoch - 8, step #000172/000234	Loss: 0.216158
Epoch - 8, step #000173/000234	Loss: 0.253423
Epoch - 8, step #000174/000234	Loss: 0.178548
Epoch - 8, step #000175/000234	Loss: 0.145688
Epoch - 8, step #000176/000234	Loss: 0.240834
Epoch - 8, step #000177/000234	Loss: 0.201580
Epoch - 8, step #000178/000234	Loss: 0.176392
Epoch - 8, step #000179/000234	Loss: 0.212740
Epoch - 8, step #000180/000234	Loss: 0.175689
Epoch - 8, step #000181/000234	Loss: 0.162993
Epoch - 8, step #000182/000234	Loss: 0.252652
Epoch - 8, step #000183/000234	Loss: 0.211316
Epoch - 8, step #000184/000234	Loss: 0.202815
Epoch - 8, step #000185/000234	Loss: 0.186522
Epoch - 8, step #000186/000234	Loss: 0.290345
Epoch - 8, step #000187/000234	Loss: 0.197156
Epoch - 8, step #000188/000234	Loss: 0.181066
Epoch - 8, step #000189/000234	Loss: 0.211114
Epoch - 8, step #000190/000234	Loss: 0.177021
Epoch - 8, step #000191/000234	Loss: 0.167331
Epoch - 8, step #000192/000234	Loss: 0.174664
Epoch - 8, step #000193/000234	Loss: 0.148026
Epoch - 8, step #000194/000234	Loss: 0.199130
Epoch - 8, step #000195/000234	Loss: 0.242656
Epoch - 8, step #000196/000234	Loss: 0.137236
Epoch - 8, step #000197/000234	Loss: 0.190126
Epoch - 8, step #000198/000234	Loss: 0.142433
Epoch - 8, step #000199/000234	Loss: 0.280831
Epoch - 8, step #000200/000234	Loss: 0.213905
Epoch - 8, step #000201/000234	Loss: 0.166369
Epoch - 8, step #000202/000234	Loss: 0.271608
Epoch - 8, step #000203/000234	Loss: 0.190354
Epoch - 8, step #000204/000234	Loss: 0.199847
Epoch - 8, step #000205/000234	Loss: 0.237812
Epoch - 8, step #000206/000234	Loss: 0.337696
Epoch - 8, step #000207/000234	Loss: 0.209929
Epoch - 8, step #000208/000234	Loss: 0.242029
Epoch - 8, step #000209/000234	Loss: 0.207126
Epoch - 8, step #000210/000234	Loss: 0.239660
Epoch - 8, step #000211/000234	Loss: 0.158926
Epoch - 8, step #000212/000234	Loss: 0.232053
Epoch - 8, step #000213/000234	Loss: 0.205123
Epoch - 8, step #000214/000234	Loss: 0.237265
Epoch - 8, step #000215/000234	Loss: 0.254728
Epoch - 8, step #000216/000234	Loss: 0.231252
Epoch - 8, step #000217/000234	Loss: 0.298150
Epoch - 8, step #000218/000234	Loss: 0.157671
Epoch - 8, step #000219/000234	Loss: 0.218199
Epoch - 8, step #000220/000234	Loss: 0.179743
Epoch - 8, step #000221/000234	Loss: 0.161058
Epoch - 8, step #000222/000234	Loss: 0.259041
Epoch - 8, step #000223/000234	Loss: 0.311414
Epoch - 8, step #000224/000234	Loss: 0.251360
Epoch - 8, step #000225/000234	Loss: 0.131891
Epoch - 8, step #000226/000234	Loss: 0.136189
Epoch - 8, step #000227/000234	Loss: 0.184093
Epoch - 8, step #000228/000234	Loss: 0.277747
Epoch - 8, step #000229/000234	Loss: 0.202449
Epoch - 8, step #000230/000234	Loss: 0.235004
Epoch - 8, step #000231/000234	Loss: 0.153014
Epoch - 8, step #000232/000234	Loss: 0.174515
Epoch - 8, step #000233/000234	Loss: 0.144175
E[8], train Loss: 0.214354, training Acc: 0.936, val loss: 0.110, val Acc: 0.967	 Time: 10.084 seconds
Epoch - 9, step #000000/000234	Loss: 0.184010
Epoch - 9, step #000001/000234	Loss: 0.189309
Epoch - 9, step #000002/000234	Loss: 0.184354
Epoch - 9, step #000003/000234	Loss: 0.137346
Epoch - 9, step #000004/000234	Loss: 0.227126
Epoch - 9, step #000005/000234	Loss: 0.127959
Epoch - 9, step #000006/000234	Loss: 0.148801
Epoch - 9, step #000007/000234	Loss: 0.176744
Epoch - 9, step #000008/000234	Loss: 0.247326
Epoch - 9, step #000009/000234	Loss: 0.232134
Epoch - 9, step #000010/000234	Loss: 0.190394
Epoch - 9, step #000011/000234	Loss: 0.249192
Epoch - 9, step #000012/000234	Loss: 0.299848
Epoch - 9, step #000013/000234	Loss: 0.148573
Epoch - 9, step #000014/000234	Loss: 0.175253
Epoch - 9, step #000015/000234	Loss: 0.198138
Epoch - 9, step #000016/000234	Loss: 0.189258
Epoch - 9, step #000017/000234	Loss: 0.149536
Epoch - 9, step #000018/000234	Loss: 0.224584
Epoch - 9, step #000019/000234	Loss: 0.160677
Epoch - 9, step #000020/000234	Loss: 0.228107
Epoch - 9, step #000021/000234	Loss: 0.166551
Epoch - 9, step #000022/000234	Loss: 0.274446
Epoch - 9, step #000023/000234	Loss: 0.161556
Epoch - 9, step #000024/000234	Loss: 0.206316
Epoch - 9, step #000025/000234	Loss: 0.231768
Epoch - 9, step #000026/000234	Loss: 0.187376
Epoch - 9, step #000027/000234	Loss: 0.193091
Epoch - 9, step #000028/000234	Loss: 0.143933
Epoch - 9, step #000029/000234	Loss: 0.287733
Epoch - 9, step #000030/000234	Loss: 0.205067
Epoch - 9, step #000031/000234	Loss: 0.190971
Epoch - 9, step #000032/000234	Loss: 0.323165
Epoch - 9, step #000033/000234	Loss: 0.233930
Epoch - 9, step #000034/000234	Loss: 0.326817
Epoch - 9, step #000035/000234	Loss: 0.223433
Epoch - 9, step #000036/000234	Loss: 0.217252
Epoch - 9, step #000037/000234	Loss: 0.200463
Epoch - 9, step #000038/000234	Loss: 0.183937
Epoch - 9, step #000039/000234	Loss: 0.192445
Epoch - 9, step #000040/000234	Loss: 0.163945
Epoch - 9, step #000041/000234	Loss: 0.285055
Epoch - 9, step #000042/000234	Loss: 0.210823
Epoch - 9, step #000043/000234	Loss: 0.205637
Epoch - 9, step #000044/000234	Loss: 0.215987
Epoch - 9, step #000045/000234	Loss: 0.183518
Epoch - 9, step #000046/000234	Loss: 0.170163
Epoch - 9, step #000047/000234	Loss: 0.122833
Epoch - 9, step #000048/000234	Loss: 0.237670
Epoch - 9, step #000049/000234	Loss: 0.158784
Epoch - 9, step #000050/000234	Loss: 0.194668
Epoch - 9, step #000051/000234	Loss: 0.199942
Epoch - 9, step #000052/000234	Loss: 0.148634
Epoch - 9, step #000053/000234	Loss: 0.199792
Epoch - 9, step #000054/000234	Loss: 0.236918
Epoch - 9, step #000055/000234	Loss: 0.159634
Epoch - 9, step #000056/000234	Loss: 0.168038
Epoch - 9, step #000057/000234	Loss: 0.219238
Epoch - 9, step #000058/000234	Loss: 0.115398
Epoch - 9, step #000059/000234	Loss: 0.246287
Epoch - 9, step #000060/000234	Loss: 0.249607
Epoch - 9, step #000061/000234	Loss: 0.222393
Epoch - 9, step #000062/000234	Loss: 0.207716
Epoch - 9, step #000063/000234	Loss: 0.223341
Epoch - 9, step #000064/000234	Loss: 0.230938
Epoch - 9, step #000065/000234	Loss: 0.223100
Epoch - 9, step #000066/000234	Loss: 0.210858
Epoch - 9, step #000067/000234	Loss: 0.201897
Epoch - 9, step #000068/000234	Loss: 0.224268
Epoch - 9, step #000069/000234	Loss: 0.181966
Epoch - 9, step #000070/000234	Loss: 0.187542
Epoch - 9, step #000071/000234	Loss: 0.280706
Epoch - 9, step #000072/000234	Loss: 0.193124
Epoch - 9, step #000073/000234	Loss: 0.148836
Epoch - 9, step #000074/000234	Loss: 0.211840
Epoch - 9, step #000075/000234	Loss: 0.163398
Epoch - 9, step #000076/000234	Loss: 0.235992
Epoch - 9, step #000077/000234	Loss: 0.260325
Epoch - 9, step #000078/000234	Loss: 0.195353
Epoch - 9, step #000079/000234	Loss: 0.248780
Epoch - 9, step #000080/000234	Loss: 0.117660
Epoch - 9, step #000081/000234	Loss: 0.205720
Epoch - 9, step #000082/000234	Loss: 0.169297
Epoch - 9, step #000083/000234	Loss: 0.197764
Epoch - 9, step #000084/000234	Loss: 0.205204
Epoch - 9, step #000085/000234	Loss: 0.195588
Epoch - 9, step #000086/000234	Loss: 0.286041
Epoch - 9, step #000087/000234	Loss: 0.194866
Epoch - 9, step #000088/000234	Loss: 0.153214
Epoch - 9, step #000089/000234	Loss: 0.254812
Epoch - 9, step #000090/000234	Loss: 0.170199
Epoch - 9, step #000091/000234	Loss: 0.216175
Epoch - 9, step #000092/000234	Loss: 0.186794
Epoch - 9, step #000093/000234	Loss: 0.248218
Epoch - 9, step #000094/000234	Loss: 0.269261
Epoch - 9, step #000095/000234	Loss: 0.226757
Epoch - 9, step #000096/000234	Loss: 0.209448
Epoch - 9, step #000097/000234	Loss: 0.212368
Epoch - 9, step #000098/000234	Loss: 0.281134
Epoch - 9, step #000099/000234	Loss: 0.202711
Epoch - 9, step #000100/000234	Loss: 0.159613
Epoch - 9, step #000101/000234	Loss: 0.152714
Epoch - 9, step #000102/000234	Loss: 0.164217
Epoch - 9, step #000103/000234	Loss: 0.126019
Epoch - 9, step #000104/000234	Loss: 0.181304
Epoch - 9, step #000105/000234	Loss: 0.292727
Epoch - 9, step #000106/000234	Loss: 0.216463
Epoch - 9, step #000107/000234	Loss: 0.188117
Epoch - 9, step #000108/000234	Loss: 0.214873
Epoch - 9, step #000109/000234	Loss: 0.133179
Epoch - 9, step #000110/000234	Loss: 0.128628
Epoch - 9, step #000111/000234	Loss: 0.199906
Epoch - 9, step #000112/000234	Loss: 0.151803
Epoch - 9, step #000113/000234	Loss: 0.269314
Epoch - 9, step #000114/000234	Loss: 0.206427
Epoch - 9, step #000115/000234	Loss: 0.183727
Epoch - 9, step #000116/000234	Loss: 0.356018
Epoch - 9, step #000117/000234	Loss: 0.313361
Epoch - 9, step #000118/000234	Loss: 0.230630
Epoch - 9, step #000119/000234	Loss: 0.204226
Epoch - 9, step #000120/000234	Loss: 0.275438
Epoch - 9, step #000121/000234	Loss: 0.196764
Epoch - 9, step #000122/000234	Loss: 0.341175
Epoch - 9, step #000123/000234	Loss: 0.179320
Epoch - 9, step #000124/000234	Loss: 0.230876
Epoch - 9, step #000125/000234	Loss: 0.246471
Epoch - 9, step #000126/000234	Loss: 0.131575
Epoch - 9, step #000127/000234	Loss: 0.222415
Epoch - 9, step #000128/000234	Loss: 0.229299
Epoch - 9, step #000129/000234	Loss: 0.207380
Epoch - 9, step #000130/000234	Loss: 0.197864
Epoch - 9, step #000131/000234	Loss: 0.193085
Epoch - 9, step #000132/000234	Loss: 0.180969
Epoch - 9, step #000133/000234	Loss: 0.214043
Epoch - 9, step #000134/000234	Loss: 0.146158
Epoch - 9, step #000135/000234	Loss: 0.179412
Epoch - 9, step #000136/000234	Loss: 0.154456
Epoch - 9, step #000137/000234	Loss: 0.169051
Epoch - 9, step #000138/000234	Loss: 0.184758
Epoch - 9, step #000139/000234	Loss: 0.153768
Epoch - 9, step #000140/000234	Loss: 0.191330
Epoch - 9, step #000141/000234	Loss: 0.222210
Epoch - 9, step #000142/000234	Loss: 0.177130
Epoch - 9, step #000143/000234	Loss: 0.185033
Epoch - 9, step #000144/000234	Loss: 0.143379
Epoch - 9, step #000145/000234	Loss: 0.204534
Epoch - 9, step #000146/000234	Loss: 0.166384
Epoch - 9, step #000147/000234	Loss: 0.125604
Epoch - 9, step #000148/000234	Loss: 0.166519
Epoch - 9, step #000149/000234	Loss: 0.180062
Epoch - 9, step #000150/000234	Loss: 0.239234
Epoch - 9, step #000151/000234	Loss: 0.185628
Epoch - 9, step #000152/000234	Loss: 0.238078
Epoch - 9, step #000153/000234	Loss: 0.287931
Epoch - 9, step #000154/000234	Loss: 0.183566
Epoch - 9, step #000155/000234	Loss: 0.193035
Epoch - 9, step #000156/000234	Loss: 0.150576
Epoch - 9, step #000157/000234	Loss: 0.280518
Epoch - 9, step #000158/000234	Loss: 0.160801
Epoch - 9, step #000159/000234	Loss: 0.211642
Epoch - 9, step #000160/000234	Loss: 0.181872
Epoch - 9, step #000161/000234	Loss: 0.262185
Epoch - 9, step #000162/000234	Loss: 0.161117
Epoch - 9, step #000163/000234	Loss: 0.294379
Epoch - 9, step #000164/000234	Loss: 0.236976
Epoch - 9, step #000165/000234	Loss: 0.239891
Epoch - 9, step #000166/000234	Loss: 0.226348
Epoch - 9, step #000167/000234	Loss: 0.204564
Epoch - 9, step #000168/000234	Loss: 0.202948
Epoch - 9, step #000169/000234	Loss: 0.192465
Epoch - 9, step #000170/000234	Loss: 0.201106
Epoch - 9, step #000171/000234	Loss: 0.210860
Epoch - 9, step #000172/000234	Loss: 0.178008
Epoch - 9, step #000173/000234	Loss: 0.219156
Epoch - 9, step #000174/000234	Loss: 0.147782
Epoch - 9, step #000175/000234	Loss: 0.171979
Epoch - 9, step #000176/000234	Loss: 0.203529
Epoch - 9, step #000177/000234	Loss: 0.165050
Epoch - 9, step #000178/000234	Loss: 0.202162
Epoch - 9, step #000179/000234	Loss: 0.235512
Epoch - 9, step #000180/000234	Loss: 0.181854
Epoch - 9, step #000181/000234	Loss: 0.257780
Epoch - 9, step #000182/000234	Loss: 0.242958
Epoch - 9, step #000183/000234	Loss: 0.163036
Epoch - 9, step #000184/000234	Loss: 0.218422
Epoch - 9, step #000185/000234	Loss: 0.203980
Epoch - 9, step #000186/000234	Loss: 0.171206
Epoch - 9, step #000187/000234	Loss: 0.220190
Epoch - 9, step #000188/000234	Loss: 0.201936
Epoch - 9, step #000189/000234	Loss: 0.209436
Epoch - 9, step #000190/000234	Loss: 0.181249
Epoch - 9, step #000191/000234	Loss: 0.225198
Epoch - 9, step #000192/000234	Loss: 0.151408
Epoch - 9, step #000193/000234	Loss: 0.216947
Epoch - 9, step #000194/000234	Loss: 0.162449
Epoch - 9, step #000195/000234	Loss: 0.236569
Epoch - 9, step #000196/000234	Loss: 0.109956
Epoch - 9, step #000197/000234	Loss: 0.100042
Epoch - 9, step #000198/000234	Loss: 0.198784
Epoch - 9, step #000199/000234	Loss: 0.190323
Epoch - 9, step #000200/000234	Loss: 0.289023
Epoch - 9, step #000201/000234	Loss: 0.182070
Epoch - 9, step #000202/000234	Loss: 0.332526
Epoch - 9, step #000203/000234	Loss: 0.123071
Epoch - 9, step #000204/000234	Loss: 0.178546
Epoch - 9, step #000205/000234	Loss: 0.160198
Epoch - 9, step #000206/000234	Loss: 0.223795
Epoch - 9, step #000207/000234	Loss: 0.235560
Epoch - 9, step #000208/000234	Loss: 0.219848
Epoch - 9, step #000209/000234	Loss: 0.149765
Epoch - 9, step #000210/000234	Loss: 0.202950
Epoch - 9, step #000211/000234	Loss: 0.132107
Epoch - 9, step #000212/000234	Loss: 0.197297
Epoch - 9, step #000213/000234	Loss: 0.178054
Epoch - 9, step #000214/000234	Loss: 0.175981
Epoch - 9, step #000215/000234	Loss: 0.207740
Epoch - 9, step #000216/000234	Loss: 0.243807
Epoch - 9, step #000217/000234	Loss: 0.206593
Epoch - 9, step #000218/000234	Loss: 0.135676
Epoch - 9, step #000219/000234	Loss: 0.190580
Epoch - 9, step #000220/000234	Loss: 0.187390
Epoch - 9, step #000221/000234	Loss: 0.209208
Epoch - 9, step #000222/000234	Loss: 0.135545
Epoch - 9, step #000223/000234	Loss: 0.259554
Epoch - 9, step #000224/000234	Loss: 0.209548
Epoch - 9, step #000225/000234	Loss: 0.167682
Epoch - 9, step #000226/000234	Loss: 0.142639
Epoch - 9, step #000227/000234	Loss: 0.184924
Epoch - 9, step #000228/000234	Loss: 0.159969
Epoch - 9, step #000229/000234	Loss: 0.224406
Epoch - 9, step #000230/000234	Loss: 0.165133
Epoch - 9, step #000231/000234	Loss: 0.239352
Epoch - 9, step #000232/000234	Loss: 0.166304
Epoch - 9, step #000233/000234	Loss: 0.251006
E[9], train Loss: 0.201783, training Acc: 0.940, val loss: 0.105, val Acc: 0.968	 Time: 10.100 seconds
Epoch - 10, step #000000/000234	Loss: 0.247482
Epoch - 10, step #000001/000234	Loss: 0.208714
Epoch - 10, step #000002/000234	Loss: 0.183848
Epoch - 10, step #000003/000234	Loss: 0.174580
Epoch - 10, step #000004/000234	Loss: 0.231191
Epoch - 10, step #000005/000234	Loss: 0.227612
Epoch - 10, step #000006/000234	Loss: 0.195992
Epoch - 10, step #000007/000234	Loss: 0.202484
Epoch - 10, step #000008/000234	Loss: 0.169362
Epoch - 10, step #000009/000234	Loss: 0.113027
Epoch - 10, step #000010/000234	Loss: 0.137103
Epoch - 10, step #000011/000234	Loss: 0.157748
Epoch - 10, step #000012/000234	Loss: 0.191095
Epoch - 10, step #000013/000234	Loss: 0.139488
Epoch - 10, step #000014/000234	Loss: 0.134109
Epoch - 10, step #000015/000234	Loss: 0.172450
Epoch - 10, step #000016/000234	Loss: 0.181805
Epoch - 10, step #000017/000234	Loss: 0.146239
Epoch - 10, step #000018/000234	Loss: 0.165675
Epoch - 10, step #000019/000234	Loss: 0.180310
Epoch - 10, step #000020/000234	Loss: 0.177657
Epoch - 10, step #000021/000234	Loss: 0.162605
Epoch - 10, step #000022/000234	Loss: 0.192040
Epoch - 10, step #000023/000234	Loss: 0.208976
Epoch - 10, step #000024/000234	Loss: 0.200959
Epoch - 10, step #000025/000234	Loss: 0.213654
Epoch - 10, step #000026/000234	Loss: 0.324189
Epoch - 10, step #000027/000234	Loss: 0.226720
Epoch - 10, step #000028/000234	Loss: 0.206940
Epoch - 10, step #000029/000234	Loss: 0.193514
Epoch - 10, step #000030/000234	Loss: 0.205787
Epoch - 10, step #000031/000234	Loss: 0.302966
Epoch - 10, step #000032/000234	Loss: 0.170289
Epoch - 10, step #000033/000234	Loss: 0.269873
Epoch - 10, step #000034/000234	Loss: 0.178265
Epoch - 10, step #000035/000234	Loss: 0.220198
Epoch - 10, step #000036/000234	Loss: 0.214556
Epoch - 10, step #000037/000234	Loss: 0.100672
Epoch - 10, step #000038/000234	Loss: 0.145626
Epoch - 10, step #000039/000234	Loss: 0.133189
Epoch - 10, step #000040/000234	Loss: 0.234736
Epoch - 10, step #000041/000234	Loss: 0.188771
Epoch - 10, step #000042/000234	Loss: 0.212114
Epoch - 10, step #000043/000234	Loss: 0.210347
Epoch - 10, step #000044/000234	Loss: 0.142810
Epoch - 10, step #000045/000234	Loss: 0.202988
Epoch - 10, step #000046/000234	Loss: 0.158401
Epoch - 10, step #000047/000234	Loss: 0.269887
Epoch - 10, step #000048/000234	Loss: 0.190240
Epoch - 10, step #000049/000234	Loss: 0.096966
Epoch - 10, step #000050/000234	Loss: 0.176062
Epoch - 10, step #000051/000234	Loss: 0.144697
Epoch - 10, step #000052/000234	Loss: 0.155065
Epoch - 10, step #000053/000234	Loss: 0.210050
Epoch - 10, step #000054/000234	Loss: 0.152764
Epoch - 10, step #000055/000234	Loss: 0.167197
Epoch - 10, step #000056/000234	Loss: 0.156704
Epoch - 10, step #000057/000234	Loss: 0.183850
Epoch - 10, step #000058/000234	Loss: 0.129313
Epoch - 10, step #000059/000234	Loss: 0.122962
Epoch - 10, step #000060/000234	Loss: 0.161721
Epoch - 10, step #000061/000234	Loss: 0.159137
Epoch - 10, step #000062/000234	Loss: 0.208841
Epoch - 10, step #000063/000234	Loss: 0.130429
Epoch - 10, step #000064/000234	Loss: 0.188759
Epoch - 10, step #000065/000234	Loss: 0.176874
Epoch - 10, step #000066/000234	Loss: 0.262159
Epoch - 10, step #000067/000234	Loss: 0.191233
Epoch - 10, step #000068/000234	Loss: 0.175000
Epoch - 10, step #000069/000234	Loss: 0.225519
Epoch - 10, step #000070/000234	Loss: 0.128684
Epoch - 10, step #000071/000234	Loss: 0.220913
Epoch - 10, step #000072/000234	Loss: 0.167655
Epoch - 10, step #000073/000234	Loss: 0.173560
Epoch - 10, step #000074/000234	Loss: 0.328949
Epoch - 10, step #000075/000234	Loss: 0.198955
Epoch - 10, step #000076/000234	Loss: 0.221972
Epoch - 10, step #000077/000234	Loss: 0.155990
Epoch - 10, step #000078/000234	Loss: 0.230773
Epoch - 10, step #000079/000234	Loss: 0.213589
Epoch - 10, step #000080/000234	Loss: 0.210268
Epoch - 10, step #000081/000234	Loss: 0.168707
Epoch - 10, step #000082/000234	Loss: 0.137431
Epoch - 10, step #000083/000234	Loss: 0.196220
Epoch - 10, step #000084/000234	Loss: 0.141207
Epoch - 10, step #000085/000234	Loss: 0.209783
Epoch - 10, step #000086/000234	Loss: 0.190572
Epoch - 10, step #000087/000234	Loss: 0.280058
Epoch - 10, step #000088/000234	Loss: 0.139386
Epoch - 10, step #000089/000234	Loss: 0.172124
Epoch - 10, step #000090/000234	Loss: 0.200803
Epoch - 10, step #000091/000234	Loss: 0.147739
Epoch - 10, step #000092/000234	Loss: 0.178890
Epoch - 10, step #000093/000234	Loss: 0.225733
Epoch - 10, step #000094/000234	Loss: 0.229877
Epoch - 10, step #000095/000234	Loss: 0.217831
Epoch - 10, step #000096/000234	Loss: 0.139296
Epoch - 10, step #000097/000234	Loss: 0.179366
Epoch - 10, step #000098/000234	Loss: 0.200397
Epoch - 10, step #000099/000234	Loss: 0.195169
Epoch - 10, step #000100/000234	Loss: 0.167510
Epoch - 10, step #000101/000234	Loss: 0.238045
Epoch - 10, step #000102/000234	Loss: 0.294515
Epoch - 10, step #000103/000234	Loss: 0.140693
Epoch - 10, step #000104/000234	Loss: 0.236079
Epoch - 10, step #000105/000234	Loss: 0.201910
Epoch - 10, step #000106/000234	Loss: 0.175650
Epoch - 10, step #000107/000234	Loss: 0.370374
Epoch - 10, step #000108/000234	Loss: 0.126521
Epoch - 10, step #000109/000234	Loss: 0.177910
Epoch - 10, step #000110/000234	Loss: 0.198473
Epoch - 10, step #000111/000234	Loss: 0.264301
Epoch - 10, step #000112/000234	Loss: 0.180507
Epoch - 10, step #000113/000234	Loss: 0.214430
Epoch - 10, step #000114/000234	Loss: 0.216069
Epoch - 10, step #000115/000234	Loss: 0.211153
Epoch - 10, step #000116/000234	Loss: 0.192990
Epoch - 10, step #000117/000234	Loss: 0.200554
Epoch - 10, step #000118/000234	Loss: 0.268092
Epoch - 10, step #000119/000234	Loss: 0.163939
Epoch - 10, step #000120/000234	Loss: 0.193197
Epoch - 10, step #000121/000234	Loss: 0.162692
Epoch - 10, step #000122/000234	Loss: 0.174918
Epoch - 10, step #000123/000234	Loss: 0.270215
Epoch - 10, step #000124/000234	Loss: 0.220374
Epoch - 10, step #000125/000234	Loss: 0.199173
Epoch - 10, step #000126/000234	Loss: 0.331435
Epoch - 10, step #000127/000234	Loss: 0.115339
Epoch - 10, step #000128/000234	Loss: 0.190182
Epoch - 10, step #000129/000234	Loss: 0.273758
Epoch - 10, step #000130/000234	Loss: 0.168429
Epoch - 10, step #000131/000234	Loss: 0.190195
Epoch - 10, step #000132/000234	Loss: 0.245161
Epoch - 10, step #000133/000234	Loss: 0.219119
Epoch - 10, step #000134/000234	Loss: 0.187522
Epoch - 10, step #000135/000234	Loss: 0.298916
Epoch - 10, step #000136/000234	Loss: 0.190334
Epoch - 10, step #000137/000234	Loss: 0.209737
Epoch - 10, step #000138/000234	Loss: 0.182330
Epoch - 10, step #000139/000234	Loss: 0.232879
Epoch - 10, step #000140/000234	Loss: 0.164421
Epoch - 10, step #000141/000234	Loss: 0.264539
Epoch - 10, step #000142/000234	Loss: 0.183360
Epoch - 10, step #000143/000234	Loss: 0.155589
Epoch - 10, step #000144/000234	Loss: 0.225783
Epoch - 10, step #000145/000234	Loss: 0.185311
Epoch - 10, step #000146/000234	Loss: 0.222855
Epoch - 10, step #000147/000234	Loss: 0.250291
Epoch - 10, step #000148/000234	Loss: 0.219722
Epoch - 10, step #000149/000234	Loss: 0.206965
Epoch - 10, step #000150/000234	Loss: 0.160952
Epoch - 10, step #000151/000234	Loss: 0.191062
Epoch - 10, step #000152/000234	Loss: 0.180110
Epoch - 10, step #000153/000234	Loss: 0.215003
Epoch - 10, step #000154/000234	Loss: 0.204503
Epoch - 10, step #000155/000234	Loss: 0.164625
Epoch - 10, step #000156/000234	Loss: 0.169575
Epoch - 10, step #000157/000234	Loss: 0.177654
Epoch - 10, step #000158/000234	Loss: 0.229802
Epoch - 10, step #000159/000234	Loss: 0.156226
Epoch - 10, step #000160/000234	Loss: 0.187243
Epoch - 10, step #000161/000234	Loss: 0.182233
Epoch - 10, step #000162/000234	Loss: 0.253514
Epoch - 10, step #000163/000234	Loss: 0.124574
Epoch - 10, step #000164/000234	Loss: 0.220518
Epoch - 10, step #000165/000234	Loss: 0.240387
Epoch - 10, step #000166/000234	Loss: 0.212787
Epoch - 10, step #000167/000234	Loss: 0.201424
Epoch - 10, step #000168/000234	Loss: 0.184856
Epoch - 10, step #000169/000234	Loss: 0.256021
Epoch - 10, step #000170/000234	Loss: 0.266324
Epoch - 10, step #000171/000234	Loss: 0.223890
Epoch - 10, step #000172/000234	Loss: 0.147805
Epoch - 10, step #000173/000234	Loss: 0.160753
Epoch - 10, step #000174/000234	Loss: 0.268458
Epoch - 10, step #000175/000234	Loss: 0.164317
Epoch - 10, step #000176/000234	Loss: 0.203421
Epoch - 10, step #000177/000234	Loss: 0.235703
Epoch - 10, step #000178/000234	Loss: 0.191346
Epoch - 10, step #000179/000234	Loss: 0.201432
Epoch - 10, step #000180/000234	Loss: 0.227390
Epoch - 10, step #000181/000234	Loss: 0.157782
Epoch - 10, step #000182/000234	Loss: 0.138083
Epoch - 10, step #000183/000234	Loss: 0.215215
Epoch - 10, step #000184/000234	Loss: 0.148203
Epoch - 10, step #000185/000234	Loss: 0.150003
Epoch - 10, step #000186/000234	Loss: 0.230470
Epoch - 10, step #000187/000234	Loss: 0.223332
Epoch - 10, step #000188/000234	Loss: 0.153516
Epoch - 10, step #000189/000234	Loss: 0.259774
Epoch - 10, step #000190/000234	Loss: 0.185028
Epoch - 10, step #000191/000234	Loss: 0.174186
Epoch - 10, step #000192/000234	Loss: 0.153885
Epoch - 10, step #000193/000234	Loss: 0.301802
Epoch - 10, step #000194/000234	Loss: 0.224355
Epoch - 10, step #000195/000234	Loss: 0.249909
Epoch - 10, step #000196/000234	Loss: 0.194612
Epoch - 10, step #000197/000234	Loss: 0.176648
Epoch - 10, step #000198/000234	Loss: 0.209363
Epoch - 10, step #000199/000234	Loss: 0.213673
Epoch - 10, step #000200/000234	Loss: 0.191352
Epoch - 10, step #000201/000234	Loss: 0.196700
Epoch - 10, step #000202/000234	Loss: 0.179111
Epoch - 10, step #000203/000234	Loss: 0.212880
Epoch - 10, step #000204/000234	Loss: 0.168683
Epoch - 10, step #000205/000234	Loss: 0.206548
Epoch - 10, step #000206/000234	Loss: 0.108537
Epoch - 10, step #000207/000234	Loss: 0.135468
Epoch - 10, step #000208/000234	Loss: 0.176600
Epoch - 10, step #000209/000234	Loss: 0.203173
Epoch - 10, step #000210/000234	Loss: 0.214771
Epoch - 10, step #000211/000234	Loss: 0.198055
Epoch - 10, step #000212/000234	Loss: 0.192079
Epoch - 10, step #000213/000234	Loss: 0.222661
Epoch - 10, step #000214/000234	Loss: 0.140437
Epoch - 10, step #000215/000234	Loss: 0.147209
Epoch - 10, step #000216/000234	Loss: 0.204400
Epoch - 10, step #000217/000234	Loss: 0.144112
Epoch - 10, step #000218/000234	Loss: 0.156813
Epoch - 10, step #000219/000234	Loss: 0.161458
Epoch - 10, step #000220/000234	Loss: 0.154570
Epoch - 10, step #000221/000234	Loss: 0.190088
Epoch - 10, step #000222/000234	Loss: 0.134446
Epoch - 10, step #000223/000234	Loss: 0.219449
Epoch - 10, step #000224/000234	Loss: 0.168031
Epoch - 10, step #000225/000234	Loss: 0.131827
Epoch - 10, step #000226/000234	Loss: 0.184578
Epoch - 10, step #000227/000234	Loss: 0.255658
Epoch - 10, step #000228/000234	Loss: 0.178372
Epoch - 10, step #000229/000234	Loss: 0.152475
Epoch - 10, step #000230/000234	Loss: 0.150636
Epoch - 10, step #000231/000234	Loss: 0.226160
Epoch - 10, step #000232/000234	Loss: 0.173050
Epoch - 10, step #000233/000234	Loss: 0.212561
E[10], train Loss: 0.194135, training Acc: 0.943, val loss: 0.101, val Acc: 0.969	 Time: 10.104 seconds
Epoch - 11, step #000000/000234	Loss: 0.150438
Epoch - 11, step #000001/000234	Loss: 0.160070
Epoch - 11, step #000002/000234	Loss: 0.175842
Epoch - 11, step #000003/000234	Loss: 0.158991
Epoch - 11, step #000004/000234	Loss: 0.168811
Epoch - 11, step #000005/000234	Loss: 0.156805
Epoch - 11, step #000006/000234	Loss: 0.137343
Epoch - 11, step #000007/000234	Loss: 0.137172
Epoch - 11, step #000008/000234	Loss: 0.169676
Epoch - 11, step #000009/000234	Loss: 0.158878
Epoch - 11, step #000010/000234	Loss: 0.186650
Epoch - 11, step #000011/000234	Loss: 0.123941
Epoch - 11, step #000012/000234	Loss: 0.163206
Epoch - 11, step #000013/000234	Loss: 0.209771
Epoch - 11, step #000014/000234	Loss: 0.213922
Epoch - 11, step #000015/000234	Loss: 0.251026
Epoch - 11, step #000016/000234	Loss: 0.207712
Epoch - 11, step #000017/000234	Loss: 0.212876
Epoch - 11, step #000018/000234	Loss: 0.190678
Epoch - 11, step #000019/000234	Loss: 0.153754
Epoch - 11, step #000020/000234	Loss: 0.257667
Epoch - 11, step #000021/000234	Loss: 0.226083
Epoch - 11, step #000022/000234	Loss: 0.150283
Epoch - 11, step #000023/000234	Loss: 0.255379
Epoch - 11, step #000024/000234	Loss: 0.170841
Epoch - 11, step #000025/000234	Loss: 0.217269
Epoch - 11, step #000026/000234	Loss: 0.152812
Epoch - 11, step #000027/000234	Loss: 0.189912
Epoch - 11, step #000028/000234	Loss: 0.189409
Epoch - 11, step #000029/000234	Loss: 0.262061
Epoch - 11, step #000030/000234	Loss: 0.142256
Epoch - 11, step #000031/000234	Loss: 0.220662
Epoch - 11, step #000032/000234	Loss: 0.172490
Epoch - 11, step #000033/000234	Loss: 0.189470
Epoch - 11, step #000034/000234	Loss: 0.136195
Epoch - 11, step #000035/000234	Loss: 0.176630
Epoch - 11, step #000036/000234	Loss: 0.165911
Epoch - 11, step #000037/000234	Loss: 0.152434
Epoch - 11, step #000038/000234	Loss: 0.206333
Epoch - 11, step #000039/000234	Loss: 0.235619
Epoch - 11, step #000040/000234	Loss: 0.126812
Epoch - 11, step #000041/000234	Loss: 0.222245
Epoch - 11, step #000042/000234	Loss: 0.218184
Epoch - 11, step #000043/000234	Loss: 0.159854
Epoch - 11, step #000044/000234	Loss: 0.155487
Epoch - 11, step #000045/000234	Loss: 0.191422
Epoch - 11, step #000046/000234	Loss: 0.167321
Epoch - 11, step #000047/000234	Loss: 0.213590
Epoch - 11, step #000048/000234	Loss: 0.215907
Epoch - 11, step #000049/000234	Loss: 0.246881
Epoch - 11, step #000050/000234	Loss: 0.170142
Epoch - 11, step #000051/000234	Loss: 0.157538
Epoch - 11, step #000052/000234	Loss: 0.288173
Epoch - 11, step #000053/000234	Loss: 0.170094
Epoch - 11, step #000054/000234	Loss: 0.167034
Epoch - 11, step #000055/000234	Loss: 0.163411
Epoch - 11, step #000056/000234	Loss: 0.147943
Epoch - 11, step #000057/000234	Loss: 0.204222
Epoch - 11, step #000058/000234	Loss: 0.306671
Epoch - 11, step #000059/000234	Loss: 0.188216
Epoch - 11, step #000060/000234	Loss: 0.205724
Epoch - 11, step #000061/000234	Loss: 0.131141
Epoch - 11, step #000062/000234	Loss: 0.205257
Epoch - 11, step #000063/000234	Loss: 0.192547
Epoch - 11, step #000064/000234	Loss: 0.216283
Epoch - 11, step #000065/000234	Loss: 0.159501
Epoch - 11, step #000066/000234	Loss: 0.156549
Epoch - 11, step #000067/000234	Loss: 0.200581
Epoch - 11, step #000068/000234	Loss: 0.187114
Epoch - 11, step #000069/000234	Loss: 0.236595
Epoch - 11, step #000070/000234	Loss: 0.177423
Epoch - 11, step #000071/000234	Loss: 0.129871
Epoch - 11, step #000072/000234	Loss: 0.158569
Epoch - 11, step #000073/000234	Loss: 0.180547
Epoch - 11, step #000074/000234	Loss: 0.216695
Epoch - 11, step #000075/000234	Loss: 0.121225
Epoch - 11, step #000076/000234	Loss: 0.156319
Epoch - 11, step #000077/000234	Loss: 0.155635
Epoch - 11, step #000078/000234	Loss: 0.183088
Epoch - 11, step #000079/000234	Loss: 0.161646
Epoch - 11, step #000080/000234	Loss: 0.175469
Epoch - 11, step #000081/000234	Loss: 0.140518
Epoch - 11, step #000082/000234	Loss: 0.136754
Epoch - 11, step #000083/000234	Loss: 0.135310
Epoch - 11, step #000084/000234	Loss: 0.197485
Epoch - 11, step #000085/000234	Loss: 0.196171
Epoch - 11, step #000086/000234	Loss: 0.185680
Epoch - 11, step #000087/000234	Loss: 0.232282
Epoch - 11, step #000088/000234	Loss: 0.197882
Epoch - 11, step #000089/000234	Loss: 0.216933
Epoch - 11, step #000090/000234	Loss: 0.149023
Epoch - 11, step #000091/000234	Loss: 0.113059
Epoch - 11, step #000092/000234	Loss: 0.123671
Epoch - 11, step #000093/000234	Loss: 0.156205
Epoch - 11, step #000094/000234	Loss: 0.156747
Epoch - 11, step #000095/000234	Loss: 0.148450
Epoch - 11, step #000096/000234	Loss: 0.182837
Epoch - 11, step #000097/000234	Loss: 0.157794
Epoch - 11, step #000098/000234	Loss: 0.229359
Epoch - 11, step #000099/000234	Loss: 0.107178
Epoch - 11, step #000100/000234	Loss: 0.199636
Epoch - 11, step #000101/000234	Loss: 0.207709
Epoch - 11, step #000102/000234	Loss: 0.227812
Epoch - 11, step #000103/000234	Loss: 0.119960
Epoch - 11, step #000104/000234	Loss: 0.168622
Epoch - 11, step #000105/000234	Loss: 0.229143
Epoch - 11, step #000106/000234	Loss: 0.127156
Epoch - 11, step #000107/000234	Loss: 0.201365
Epoch - 11, step #000108/000234	Loss: 0.188284
Epoch - 11, step #000109/000234	Loss: 0.229976
Epoch - 11, step #000110/000234	Loss: 0.159440
Epoch - 11, step #000111/000234	Loss: 0.220310
Epoch - 11, step #000112/000234	Loss: 0.204727
Epoch - 11, step #000113/000234	Loss: 0.122633
Epoch - 11, step #000114/000234	Loss: 0.171901
Epoch - 11, step #000115/000234	Loss: 0.250102
Epoch - 11, step #000116/000234	Loss: 0.276628
Epoch - 11, step #000117/000234	Loss: 0.123616
Epoch - 11, step #000118/000234	Loss: 0.188459
Epoch - 11, step #000119/000234	Loss: 0.196213
Epoch - 11, step #000120/000234	Loss: 0.156559
Epoch - 11, step #000121/000234	Loss: 0.141803
Epoch - 11, step #000122/000234	Loss: 0.214702
Epoch - 11, step #000123/000234	Loss: 0.164782
Epoch - 11, step #000124/000234	Loss: 0.108815
Epoch - 11, step #000125/000234	Loss: 0.177215
Epoch - 11, step #000126/000234	Loss: 0.191527
Epoch - 11, step #000127/000234	Loss: 0.147530
Epoch - 11, step #000128/000234	Loss: 0.186291
Epoch - 11, step #000129/000234	Loss: 0.141487
Epoch - 11, step #000130/000234	Loss: 0.190792
Epoch - 11, step #000131/000234	Loss: 0.178248
Epoch - 11, step #000132/000234	Loss: 0.188557
Epoch - 11, step #000133/000234	Loss: 0.211668
Epoch - 11, step #000134/000234	Loss: 0.251536
Epoch - 11, step #000135/000234	Loss: 0.222088
Epoch - 11, step #000136/000234	Loss: 0.175926
Epoch - 11, step #000137/000234	Loss: 0.164264
Epoch - 11, step #000138/000234	Loss: 0.174818
Epoch - 11, step #000139/000234	Loss: 0.210495
Epoch - 11, step #000140/000234	Loss: 0.233617
Epoch - 11, step #000141/000234	Loss: 0.202803
Epoch - 11, step #000142/000234	Loss: 0.205949
Epoch - 11, step #000143/000234	Loss: 0.217543
Epoch - 11, step #000144/000234	Loss: 0.308611
Epoch - 11, step #000145/000234	Loss: 0.227384
Epoch - 11, step #000146/000234	Loss: 0.184504
Epoch - 11, step #000147/000234	Loss: 0.159757
Epoch - 11, step #000148/000234	Loss: 0.246304
Epoch - 11, step #000149/000234	Loss: 0.178284
Epoch - 11, step #000150/000234	Loss: 0.165771
Epoch - 11, step #000151/000234	Loss: 0.141333
Epoch - 11, step #000152/000234	Loss: 0.188664
Epoch - 11, step #000153/000234	Loss: 0.176799
Epoch - 11, step #000154/000234	Loss: 0.167129
Epoch - 11, step #000155/000234	Loss: 0.234447
Epoch - 11, step #000156/000234	Loss: 0.222397
Epoch - 11, step #000157/000234	Loss: 0.273114
Epoch - 11, step #000158/000234	Loss: 0.133546
Epoch - 11, step #000159/000234	Loss: 0.248043
Epoch - 11, step #000160/000234	Loss: 0.256984
Epoch - 11, step #000161/000234	Loss: 0.254090
Epoch - 11, step #000162/000234	Loss: 0.273253
Epoch - 11, step #000163/000234	Loss: 0.239837
Epoch - 11, step #000164/000234	Loss: 0.182540
Epoch - 11, step #000165/000234	Loss: 0.188233
Epoch - 11, step #000166/000234	Loss: 0.173008
Epoch - 11, step #000167/000234	Loss: 0.173202
Epoch - 11, step #000168/000234	Loss: 0.132260
Epoch - 11, step #000169/000234	Loss: 0.306751
Epoch - 11, step #000170/000234	Loss: 0.227540
Epoch - 11, step #000171/000234	Loss: 0.211319
Epoch - 11, step #000172/000234	Loss: 0.196151
Epoch - 11, step #000173/000234	Loss: 0.158529
Epoch - 11, step #000174/000234	Loss: 0.189261
Epoch - 11, step #000175/000234	Loss: 0.172216
Epoch - 11, step #000176/000234	Loss: 0.153357
Epoch - 11, step #000177/000234	Loss: 0.179595
Epoch - 11, step #000178/000234	Loss: 0.162250
Epoch - 11, step #000179/000234	Loss: 0.164655
Epoch - 11, step #000180/000234	Loss: 0.209047
Epoch - 11, step #000181/000234	Loss: 0.109254
Epoch - 11, step #000182/000234	Loss: 0.152029
Epoch - 11, step #000183/000234	Loss: 0.149731
Epoch - 11, step #000184/000234	Loss: 0.172601
Epoch - 11, step #000185/000234	Loss: 0.241427
Epoch - 11, step #000186/000234	Loss: 0.192429
Epoch - 11, step #000187/000234	Loss: 0.147861
Epoch - 11, step #000188/000234	Loss: 0.189763
Epoch - 11, step #000189/000234	Loss: 0.143621
Epoch - 11, step #000190/000234	Loss: 0.140455
Epoch - 11, step #000191/000234	Loss: 0.170034
Epoch - 11, step #000192/000234	Loss: 0.150489
Epoch - 11, step #000193/000234	Loss: 0.239890
Epoch - 11, step #000194/000234	Loss: 0.159383
Epoch - 11, step #000195/000234	Loss: 0.164738
Epoch - 11, step #000196/000234	Loss: 0.190419
Epoch - 11, step #000197/000234	Loss: 0.157974
Epoch - 11, step #000198/000234	Loss: 0.223080
Epoch - 11, step #000199/000234	Loss: 0.142448
Epoch - 11, step #000200/000234	Loss: 0.159438
Epoch - 11, step #000201/000234	Loss: 0.158726
Epoch - 11, step #000202/000234	Loss: 0.144700
Epoch - 11, step #000203/000234	Loss: 0.151710
Epoch - 11, step #000204/000234	Loss: 0.089285
Epoch - 11, step #000205/000234	Loss: 0.171585
Epoch - 11, step #000206/000234	Loss: 0.119392
Epoch - 11, step #000207/000234	Loss: 0.097388
Epoch - 11, step #000208/000234	Loss: 0.204486
Epoch - 11, step #000209/000234	Loss: 0.104700
Epoch - 11, step #000210/000234	Loss: 0.167895
Epoch - 11, step #000211/000234	Loss: 0.249141
Epoch - 11, step #000212/000234	Loss: 0.162908
Epoch - 11, step #000213/000234	Loss: 0.141866
Epoch - 11, step #000214/000234	Loss: 0.170880
Epoch - 11, step #000215/000234	Loss: 0.141384
Epoch - 11, step #000216/000234	Loss: 0.127212
Epoch - 11, step #000217/000234	Loss: 0.139634
Epoch - 11, step #000218/000234	Loss: 0.149059
Epoch - 11, step #000219/000234	Loss: 0.166363
Epoch - 11, step #000220/000234	Loss: 0.166839
Epoch - 11, step #000221/000234	Loss: 0.135512
Epoch - 11, step #000222/000234	Loss: 0.138134
Epoch - 11, step #000223/000234	Loss: 0.203865
Epoch - 11, step #000224/000234	Loss: 0.264023
Epoch - 11, step #000225/000234	Loss: 0.106806
Epoch - 11, step #000226/000234	Loss: 0.171607
Epoch - 11, step #000227/000234	Loss: 0.181362
Epoch - 11, step #000228/000234	Loss: 0.208887
Epoch - 11, step #000229/000234	Loss: 0.281037
Epoch - 11, step #000230/000234	Loss: 0.104798
Epoch - 11, step #000231/000234	Loss: 0.188610
Epoch - 11, step #000232/000234	Loss: 0.196647
Epoch - 11, step #000233/000234	Loss: 0.178568
E[11], train Loss: 0.182156, training Acc: 0.945, val loss: 0.098, val Acc: 0.971	 Time: 10.326 seconds
Epoch - 12, step #000000/000234	Loss: 0.133623
Epoch - 12, step #000001/000234	Loss: 0.235266
Epoch - 12, step #000002/000234	Loss: 0.157271
Epoch - 12, step #000003/000234	Loss: 0.166020
Epoch - 12, step #000004/000234	Loss: 0.182938
Epoch - 12, step #000005/000234	Loss: 0.126700
Epoch - 12, step #000006/000234	Loss: 0.150386
Epoch - 12, step #000007/000234	Loss: 0.143594
Epoch - 12, step #000008/000234	Loss: 0.141741
Epoch - 12, step #000009/000234	Loss: 0.189947
Epoch - 12, step #000010/000234	Loss: 0.101732
Epoch - 12, step #000011/000234	Loss: 0.094999
Epoch - 12, step #000012/000234	Loss: 0.148030
Epoch - 12, step #000013/000234	Loss: 0.212303
Epoch - 12, step #000014/000234	Loss: 0.212439
Epoch - 12, step #000015/000234	Loss: 0.177340
Epoch - 12, step #000016/000234	Loss: 0.155429
Epoch - 12, step #000017/000234	Loss: 0.154613
Epoch - 12, step #000018/000234	Loss: 0.205777
Epoch - 12, step #000019/000234	Loss: 0.097070
Epoch - 12, step #000020/000234	Loss: 0.140369
Epoch - 12, step #000021/000234	Loss: 0.208321
Epoch - 12, step #000022/000234	Loss: 0.234934
Epoch - 12, step #000023/000234	Loss: 0.116315
Epoch - 12, step #000024/000234	Loss: 0.174866
Epoch - 12, step #000025/000234	Loss: 0.134669
Epoch - 12, step #000026/000234	Loss: 0.121684
Epoch - 12, step #000027/000234	Loss: 0.147816
Epoch - 12, step #000028/000234	Loss: 0.177678
Epoch - 12, step #000029/000234	Loss: 0.170594
Epoch - 12, step #000030/000234	Loss: 0.093025
Epoch - 12, step #000031/000234	Loss: 0.178822
Epoch - 12, step #000032/000234	Loss: 0.163727
Epoch - 12, step #000033/000234	Loss: 0.214908
Epoch - 12, step #000034/000234	Loss: 0.150892
Epoch - 12, step #000035/000234	Loss: 0.112680
Epoch - 12, step #000036/000234	Loss: 0.132856
Epoch - 12, step #000037/000234	Loss: 0.174381
Epoch - 12, step #000038/000234	Loss: 0.151288
Epoch - 12, step #000039/000234	Loss: 0.229273
Epoch - 12, step #000040/000234	Loss: 0.132226
Epoch - 12, step #000041/000234	Loss: 0.106027
Epoch - 12, step #000042/000234	Loss: 0.128156
Epoch - 12, step #000043/000234	Loss: 0.196729
Epoch - 12, step #000044/000234	Loss: 0.162695
Epoch - 12, step #000045/000234	Loss: 0.247610
Epoch - 12, step #000046/000234	Loss: 0.150295
Epoch - 12, step #000047/000234	Loss: 0.131099
Epoch - 12, step #000048/000234	Loss: 0.195051
Epoch - 12, step #000049/000234	Loss: 0.254228
Epoch - 12, step #000050/000234	Loss: 0.221629
Epoch - 12, step #000051/000234	Loss: 0.233920
Epoch - 12, step #000052/000234	Loss: 0.154691
Epoch - 12, step #000053/000234	Loss: 0.168759
Epoch - 12, step #000054/000234	Loss: 0.218091
Epoch - 12, step #000055/000234	Loss: 0.146851
Epoch - 12, step #000056/000234	Loss: 0.166681
Epoch - 12, step #000057/000234	Loss: 0.105871
Epoch - 12, step #000058/000234	Loss: 0.195530
Epoch - 12, step #000059/000234	Loss: 0.227644
Epoch - 12, step #000060/000234	Loss: 0.227297
Epoch - 12, step #000061/000234	Loss: 0.198729
Epoch - 12, step #000062/000234	Loss: 0.169186
Epoch - 12, step #000063/000234	Loss: 0.212989
Epoch - 12, step #000064/000234	Loss: 0.175844
Epoch - 12, step #000065/000234	Loss: 0.175086
Epoch - 12, step #000066/000234	Loss: 0.203892
Epoch - 12, step #000067/000234	Loss: 0.242452
Epoch - 12, step #000068/000234	Loss: 0.168279
Epoch - 12, step #000069/000234	Loss: 0.142200
Epoch - 12, step #000070/000234	Loss: 0.128135
Epoch - 12, step #000071/000234	Loss: 0.147376
Epoch - 12, step #000072/000234	Loss: 0.161434
Epoch - 12, step #000073/000234	Loss: 0.163623
Epoch - 12, step #000074/000234	Loss: 0.218267
Epoch - 12, step #000075/000234	Loss: 0.222777
Epoch - 12, step #000076/000234	Loss: 0.213973
Epoch - 12, step #000077/000234	Loss: 0.139160
Epoch - 12, step #000078/000234	Loss: 0.194956
Epoch - 12, step #000079/000234	Loss: 0.174733
Epoch - 12, step #000080/000234	Loss: 0.129848
Epoch - 12, step #000081/000234	Loss: 0.124358
Epoch - 12, step #000082/000234	Loss: 0.271160
Epoch - 12, step #000083/000234	Loss: 0.260549
Epoch - 12, step #000084/000234	Loss: 0.153677
Epoch - 12, step #000085/000234	Loss: 0.280795
Epoch - 12, step #000086/000234	Loss: 0.243418
Epoch - 12, step #000087/000234	Loss: 0.164534
Epoch - 12, step #000088/000234	Loss: 0.264737
Epoch - 12, step #000089/000234	Loss: 0.197079
Epoch - 12, step #000090/000234	Loss: 0.148439
Epoch - 12, step #000091/000234	Loss: 0.225027
Epoch - 12, step #000092/000234	Loss: 0.260585
Epoch - 12, step #000093/000234	Loss: 0.149018
Epoch - 12, step #000094/000234	Loss: 0.147517
Epoch - 12, step #000095/000234	Loss: 0.156651
Epoch - 12, step #000096/000234	Loss: 0.215186
Epoch - 12, step #000097/000234	Loss: 0.214718
Epoch - 12, step #000098/000234	Loss: 0.186144
Epoch - 12, step #000099/000234	Loss: 0.178881
Epoch - 12, step #000100/000234	Loss: 0.148661
Epoch - 12, step #000101/000234	Loss: 0.208590
Epoch - 12, step #000102/000234	Loss: 0.254869
Epoch - 12, step #000103/000234	Loss: 0.140676
Epoch - 12, step #000104/000234	Loss: 0.176799
Epoch - 12, step #000105/000234	Loss: 0.194211
Epoch - 12, step #000106/000234	Loss: 0.149104
Epoch - 12, step #000107/000234	Loss: 0.102399
Epoch - 12, step #000108/000234	Loss: 0.177362
Epoch - 12, step #000109/000234	Loss: 0.140064
Epoch - 12, step #000110/000234	Loss: 0.191354
Epoch - 12, step #000111/000234	Loss: 0.246437
Epoch - 12, step #000112/000234	Loss: 0.281331
Epoch - 12, step #000113/000234	Loss: 0.138448
Epoch - 12, step #000114/000234	Loss: 0.160885
Epoch - 12, step #000115/000234	Loss: 0.262643
Epoch - 12, step #000116/000234	Loss: 0.177237
Epoch - 12, step #000117/000234	Loss: 0.173670
Epoch - 12, step #000118/000234	Loss: 0.232083
Epoch - 12, step #000119/000234	Loss: 0.173652
Epoch - 12, step #000120/000234	Loss: 0.154430
Epoch - 12, step #000121/000234	Loss: 0.113072
Epoch - 12, step #000122/000234	Loss: 0.225049
Epoch - 12, step #000123/000234	Loss: 0.140824
Epoch - 12, step #000124/000234	Loss: 0.162584
Epoch - 12, step #000125/000234	Loss: 0.183761
Epoch - 12, step #000126/000234	Loss: 0.272453
Epoch - 12, step #000127/000234	Loss: 0.152896
Epoch - 12, step #000128/000234	Loss: 0.180130
Epoch - 12, step #000129/000234	Loss: 0.151303
Epoch - 12, step #000130/000234	Loss: 0.186074
Epoch - 12, step #000131/000234	Loss: 0.243966
Epoch - 12, step #000132/000234	Loss: 0.207252
Epoch - 12, step #000133/000234	Loss: 0.141090
Epoch - 12, step #000134/000234	Loss: 0.211539
Epoch - 12, step #000135/000234	Loss: 0.264951
Epoch - 12, step #000136/000234	Loss: 0.114050
Epoch - 12, step #000137/000234	Loss: 0.240959
Epoch - 12, step #000138/000234	Loss: 0.160438
Epoch - 12, step #000139/000234	Loss: 0.183751
Epoch - 12, step #000140/000234	Loss: 0.187316
Epoch - 12, step #000141/000234	Loss: 0.108845
Epoch - 12, step #000142/000234	Loss: 0.183823
Epoch - 12, step #000143/000234	Loss: 0.193266
Epoch - 12, step #000144/000234	Loss: 0.185094
Epoch - 12, step #000145/000234	Loss: 0.131900
Epoch - 12, step #000146/000234	Loss: 0.198341
Epoch - 12, step #000147/000234	Loss: 0.112287
Epoch - 12, step #000148/000234	Loss: 0.247985
Epoch - 12, step #000149/000234	Loss: 0.187471
Epoch - 12, step #000150/000234	Loss: 0.154888
Epoch - 12, step #000151/000234	Loss: 0.293298
Epoch - 12, step #000152/000234	Loss: 0.179015
Epoch - 12, step #000153/000234	Loss: 0.213463
Epoch - 12, step #000154/000234	Loss: 0.202150
Epoch - 12, step #000155/000234	Loss: 0.149305
Epoch - 12, step #000156/000234	Loss: 0.156918
Epoch - 12, step #000157/000234	Loss: 0.184047
Epoch - 12, step #000158/000234	Loss: 0.128936
Epoch - 12, step #000159/000234	Loss: 0.116010
Epoch - 12, step #000160/000234	Loss: 0.176314
Epoch - 12, step #000161/000234	Loss: 0.198303
Epoch - 12, step #000162/000234	Loss: 0.161919
Epoch - 12, step #000163/000234	Loss: 0.180119
Epoch - 12, step #000164/000234	Loss: 0.207082
Epoch - 12, step #000165/000234	Loss: 0.230644
Epoch - 12, step #000166/000234	Loss: 0.160969
Epoch - 12, step #000167/000234	Loss: 0.174735
Epoch - 12, step #000168/000234	Loss: 0.206716
Epoch - 12, step #000169/000234	Loss: 0.222196
Epoch - 12, step #000170/000234	Loss: 0.209296
Epoch - 12, step #000171/000234	Loss: 0.217606
Epoch - 12, step #000172/000234	Loss: 0.268406
Epoch - 12, step #000173/000234	Loss: 0.201802
Epoch - 12, step #000174/000234	Loss: 0.211977
Epoch - 12, step #000175/000234	Loss: 0.133626
Epoch - 12, step #000176/000234	Loss: 0.200288
Epoch - 12, step #000177/000234	Loss: 0.120867
Epoch - 12, step #000178/000234	Loss: 0.124766
Epoch - 12, step #000179/000234	Loss: 0.180487
Epoch - 12, step #000180/000234	Loss: 0.189746
Epoch - 12, step #000181/000234	Loss: 0.109187
Epoch - 12, step #000182/000234	Loss: 0.200545
Epoch - 12, step #000183/000234	Loss: 0.190988
Epoch - 12, step #000184/000234	Loss: 0.156923
Epoch - 12, step #000185/000234	Loss: 0.253991
Epoch - 12, step #000186/000234	Loss: 0.144505
Epoch - 12, step #000187/000234	Loss: 0.189880
Epoch - 12, step #000188/000234	Loss: 0.195066
Epoch - 12, step #000189/000234	Loss: 0.193246
Epoch - 12, step #000190/000234	Loss: 0.172676
Epoch - 12, step #000191/000234	Loss: 0.142904
Epoch - 12, step #000192/000234	Loss: 0.157075
Epoch - 12, step #000193/000234	Loss: 0.130541
Epoch - 12, step #000194/000234	Loss: 0.141061
Epoch - 12, step #000195/000234	Loss: 0.157237
Epoch - 12, step #000196/000234	Loss: 0.131170
Epoch - 12, step #000197/000234	Loss: 0.158750
Epoch - 12, step #000198/000234	Loss: 0.168460
Epoch - 12, step #000199/000234	Loss: 0.193597
Epoch - 12, step #000200/000234	Loss: 0.203887
Epoch - 12, step #000201/000234	Loss: 0.151448
Epoch - 12, step #000202/000234	Loss: 0.172638
Epoch - 12, step #000203/000234	Loss: 0.112198
Epoch - 12, step #000204/000234	Loss: 0.213249
Epoch - 12, step #000205/000234	Loss: 0.093835
Epoch - 12, step #000206/000234	Loss: 0.167793
Epoch - 12, step #000207/000234	Loss: 0.167064
Epoch - 12, step #000208/000234	Loss: 0.184029
Epoch - 12, step #000209/000234	Loss: 0.135889
Epoch - 12, step #000210/000234	Loss: 0.154867
Epoch - 12, step #000211/000234	Loss: 0.115352
Epoch - 12, step #000212/000234	Loss: 0.184051
Epoch - 12, step #000213/000234	Loss: 0.162110
Epoch - 12, step #000214/000234	Loss: 0.216969
Epoch - 12, step #000215/000234	Loss: 0.191276
Epoch - 12, step #000216/000234	Loss: 0.166838
Epoch - 12, step #000217/000234	Loss: 0.108042
Epoch - 12, step #000218/000234	Loss: 0.172674
Epoch - 12, step #000219/000234	Loss: 0.210391
Epoch - 12, step #000220/000234	Loss: 0.178955
Epoch - 12, step #000221/000234	Loss: 0.182649
Epoch - 12, step #000222/000234	Loss: 0.117196
Epoch - 12, step #000223/000234	Loss: 0.118778
Epoch - 12, step #000224/000234	Loss: 0.146814
Epoch - 12, step #000225/000234	Loss: 0.213336
Epoch - 12, step #000226/000234	Loss: 0.156750
Epoch - 12, step #000227/000234	Loss: 0.221465
Epoch - 12, step #000228/000234	Loss: 0.085596
Epoch - 12, step #000229/000234	Loss: 0.171149
Epoch - 12, step #000230/000234	Loss: 0.137275
Epoch - 12, step #000231/000234	Loss: 0.165009
Epoch - 12, step #000232/000234	Loss: 0.146293
Epoch - 12, step #000233/000234	Loss: 0.175833
E[12], train Loss: 0.176135, training Acc: 0.948, val loss: 0.090, val Acc: 0.974	 Time: 10.121 seconds
Epoch - 13, step #000000/000234	Loss: 0.203267
Epoch - 13, step #000001/000234	Loss: 0.151804
Epoch - 13, step #000002/000234	Loss: 0.246880
Epoch - 13, step #000003/000234	Loss: 0.118706
Epoch - 13, step #000004/000234	Loss: 0.185183
Epoch - 13, step #000005/000234	Loss: 0.090392
Epoch - 13, step #000006/000234	Loss: 0.143226
Epoch - 13, step #000007/000234	Loss: 0.159294
Epoch - 13, step #000008/000234	Loss: 0.096776
Epoch - 13, step #000009/000234	Loss: 0.155127
Epoch - 13, step #000010/000234	Loss: 0.143234
Epoch - 13, step #000011/000234	Loss: 0.157677
Epoch - 13, step #000012/000234	Loss: 0.241322
Epoch - 13, step #000013/000234	Loss: 0.198098
Epoch - 13, step #000014/000234	Loss: 0.137342
Epoch - 13, step #000015/000234	Loss: 0.241073
Epoch - 13, step #000016/000234	Loss: 0.172831
Epoch - 13, step #000017/000234	Loss: 0.224000
Epoch - 13, step #000018/000234	Loss: 0.158811
Epoch - 13, step #000019/000234	Loss: 0.133212
Epoch - 13, step #000020/000234	Loss: 0.293272
Epoch - 13, step #000021/000234	Loss: 0.245176
Epoch - 13, step #000022/000234	Loss: 0.162491
Epoch - 13, step #000023/000234	Loss: 0.167455
Epoch - 13, step #000024/000234	Loss: 0.155594
Epoch - 13, step #000025/000234	Loss: 0.208740
Epoch - 13, step #000026/000234	Loss: 0.141884
Epoch - 13, step #000027/000234	Loss: 0.187417
Epoch - 13, step #000028/000234	Loss: 0.170282
Epoch - 13, step #000029/000234	Loss: 0.194873
Epoch - 13, step #000030/000234	Loss: 0.100283
Epoch - 13, step #000031/000234	Loss: 0.199828
Epoch - 13, step #000032/000234	Loss: 0.238460
Epoch - 13, step #000033/000234	Loss: 0.211682
Epoch - 13, step #000034/000234	Loss: 0.112558
Epoch - 13, step #000035/000234	Loss: 0.078901
Epoch - 13, step #000036/000234	Loss: 0.142776
Epoch - 13, step #000037/000234	Loss: 0.102253
Epoch - 13, step #000038/000234	Loss: 0.125645
Epoch - 13, step #000039/000234	Loss: 0.134119
Epoch - 13, step #000040/000234	Loss: 0.226747
Epoch - 13, step #000041/000234	Loss: 0.175146
Epoch - 13, step #000042/000234	Loss: 0.200704
Epoch - 13, step #000043/000234	Loss: 0.151886
Epoch - 13, step #000044/000234	Loss: 0.138522
Epoch - 13, step #000045/000234	Loss: 0.163533
Epoch - 13, step #000046/000234	Loss: 0.171218
Epoch - 13, step #000047/000234	Loss: 0.198676
Epoch - 13, step #000048/000234	Loss: 0.175087
Epoch - 13, step #000049/000234	Loss: 0.155661
Epoch - 13, step #000050/000234	Loss: 0.138750
Epoch - 13, step #000051/000234	Loss: 0.157880
Epoch - 13, step #000052/000234	Loss: 0.196320
Epoch - 13, step #000053/000234	Loss: 0.145501
Epoch - 13, step #000054/000234	Loss: 0.188264
Epoch - 13, step #000055/000234	Loss: 0.141471
Epoch - 13, step #000056/000234	Loss: 0.166320
Epoch - 13, step #000057/000234	Loss: 0.162630
Epoch - 13, step #000058/000234	Loss: 0.158581
Epoch - 13, step #000059/000234	Loss: 0.116806
Epoch - 13, step #000060/000234	Loss: 0.185685
Epoch - 13, step #000061/000234	Loss: 0.176165
Epoch - 13, step #000062/000234	Loss: 0.228208
Epoch - 13, step #000063/000234	Loss: 0.174441
Epoch - 13, step #000064/000234	Loss: 0.110576
Epoch - 13, step #000065/000234	Loss: 0.110284
Epoch - 13, step #000066/000234	Loss: 0.110527
Epoch - 13, step #000067/000234	Loss: 0.121328
Epoch - 13, step #000068/000234	Loss: 0.215274
Epoch - 13, step #000069/000234	Loss: 0.173660
Epoch - 13, step #000070/000234	Loss: 0.128499
Epoch - 13, step #000071/000234	Loss: 0.144172
Epoch - 13, step #000072/000234	Loss: 0.183610
Epoch - 13, step #000073/000234	Loss: 0.147060
Epoch - 13, step #000074/000234	Loss: 0.201200
Epoch - 13, step #000075/000234	Loss: 0.145583
Epoch - 13, step #000076/000234	Loss: 0.170216
Epoch - 13, step #000077/000234	Loss: 0.265454
Epoch - 13, step #000078/000234	Loss: 0.188044
Epoch - 13, step #000079/000234	Loss: 0.219502
Epoch - 13, step #000080/000234	Loss: 0.184065
Epoch - 13, step #000081/000234	Loss: 0.122272
Epoch - 13, step #000082/000234	Loss: 0.150029
Epoch - 13, step #000083/000234	Loss: 0.190152
Epoch - 13, step #000084/000234	Loss: 0.154445
Epoch - 13, step #000085/000234	Loss: 0.169692
Epoch - 13, step #000086/000234	Loss: 0.197817
Epoch - 13, step #000087/000234	Loss: 0.131547
Epoch - 13, step #000088/000234	Loss: 0.182016
Epoch - 13, step #000089/000234	Loss: 0.193197
Epoch - 13, step #000090/000234	Loss: 0.199902
Epoch - 13, step #000091/000234	Loss: 0.137178
Epoch - 13, step #000092/000234	Loss: 0.138774
Epoch - 13, step #000093/000234	Loss: 0.187282
Epoch - 13, step #000094/000234	Loss: 0.099774
Epoch - 13, step #000095/000234	Loss: 0.179887
Epoch - 13, step #000096/000234	Loss: 0.219926
Epoch - 13, step #000097/000234	Loss: 0.192850
Epoch - 13, step #000098/000234	Loss: 0.200998
Epoch - 13, step #000099/000234	Loss: 0.137560
Epoch - 13, step #000100/000234	Loss: 0.210235
Epoch - 13, step #000101/000234	Loss: 0.149440
Epoch - 13, step #000102/000234	Loss: 0.140230
Epoch - 13, step #000103/000234	Loss: 0.151585
Epoch - 13, step #000104/000234	Loss: 0.147987
Epoch - 13, step #000105/000234	Loss: 0.122713
Epoch - 13, step #000106/000234	Loss: 0.152108
Epoch - 13, step #000107/000234	Loss: 0.195338
Epoch - 13, step #000108/000234	Loss: 0.181481
Epoch - 13, step #000109/000234	Loss: 0.131021
Epoch - 13, step #000110/000234	Loss: 0.120650
Epoch - 13, step #000111/000234	Loss: 0.173362
Epoch - 13, step #000112/000234	Loss: 0.162876
Epoch - 13, step #000113/000234	Loss: 0.154553
Epoch - 13, step #000114/000234	Loss: 0.184214
Epoch - 13, step #000115/000234	Loss: 0.182548
Epoch - 13, step #000116/000234	Loss: 0.145186
Epoch - 13, step #000117/000234	Loss: 0.177037
Epoch - 13, step #000118/000234	Loss: 0.183474
Epoch - 13, step #000119/000234	Loss: 0.185722
Epoch - 13, step #000120/000234	Loss: 0.113826
Epoch - 13, step #000121/000234	Loss: 0.223477
Epoch - 13, step #000122/000234	Loss: 0.225357
Epoch - 13, step #000123/000234	Loss: 0.217117
Epoch - 13, step #000124/000234	Loss: 0.172076
Epoch - 13, step #000125/000234	Loss: 0.182519
Epoch - 13, step #000126/000234	Loss: 0.179961
Epoch - 13, step #000127/000234	Loss: 0.138826
Epoch - 13, step #000128/000234	Loss: 0.222458
Epoch - 13, step #000129/000234	Loss: 0.196416
Epoch - 13, step #000130/000234	Loss: 0.241081
Epoch - 13, step #000131/000234	Loss: 0.157740
Epoch - 13, step #000132/000234	Loss: 0.140133
Epoch - 13, step #000133/000234	Loss: 0.096486
Epoch - 13, step #000134/000234	Loss: 0.135442
Epoch - 13, step #000135/000234	Loss: 0.208096
Epoch - 13, step #000136/000234	Loss: 0.125658
Epoch - 13, step #000137/000234	Loss: 0.210169
Epoch - 13, step #000138/000234	Loss: 0.187655
Epoch - 13, step #000139/000234	Loss: 0.134108
Epoch - 13, step #000140/000234	Loss: 0.226307
Epoch - 13, step #000141/000234	Loss: 0.189874
Epoch - 13, step #000142/000234	Loss: 0.179585
Epoch - 13, step #000143/000234	Loss: 0.239498
Epoch - 13, step #000144/000234	Loss: 0.196553
Epoch - 13, step #000145/000234	Loss: 0.187355
Epoch - 13, step #000146/000234	Loss: 0.151747
Epoch - 13, step #000147/000234	Loss: 0.178854
Epoch - 13, step #000148/000234	Loss: 0.223847
Epoch - 13, step #000149/000234	Loss: 0.132999
Epoch - 13, step #000150/000234	Loss: 0.150434
Epoch - 13, step #000151/000234	Loss: 0.192819
Epoch - 13, step #000152/000234	Loss: 0.125873
Epoch - 13, step #000153/000234	Loss: 0.204724
Epoch - 13, step #000154/000234	Loss: 0.158602
Epoch - 13, step #000155/000234	Loss: 0.165776
Epoch - 13, step #000156/000234	Loss: 0.194970
Epoch - 13, step #000157/000234	Loss: 0.263569
Epoch - 13, step #000158/000234	Loss: 0.193753
Epoch - 13, step #000159/000234	Loss: 0.217685
Epoch - 13, step #000160/000234	Loss: 0.187857
Epoch - 13, step #000161/000234	Loss: 0.177090
Epoch - 13, step #000162/000234	Loss: 0.190542
Epoch - 13, step #000163/000234	Loss: 0.135085
Epoch - 13, step #000164/000234	Loss: 0.214733
Epoch - 13, step #000165/000234	Loss: 0.178541
Epoch - 13, step #000166/000234	Loss: 0.147300
Epoch - 13, step #000167/000234	Loss: 0.130385
Epoch - 13, step #000168/000234	Loss: 0.197201
Epoch - 13, step #000169/000234	Loss: 0.121942
Epoch - 13, step #000170/000234	Loss: 0.188290
Epoch - 13, step #000171/000234	Loss: 0.133311
Epoch - 13, step #000172/000234	Loss: 0.164056
Epoch - 13, step #000173/000234	Loss: 0.198332
Epoch - 13, step #000174/000234	Loss: 0.190469
Epoch - 13, step #000175/000234	Loss: 0.118739
Epoch - 13, step #000176/000234	Loss: 0.165981
Epoch - 13, step #000177/000234	Loss: 0.188039
Epoch - 13, step #000178/000234	Loss: 0.154919
Epoch - 13, step #000179/000234	Loss: 0.142023
Epoch - 13, step #000180/000234	Loss: 0.230797
Epoch - 13, step #000181/000234	Loss: 0.204607
Epoch - 13, step #000182/000234	Loss: 0.142858
Epoch - 13, step #000183/000234	Loss: 0.139208
Epoch - 13, step #000184/000234	Loss: 0.179829
Epoch - 13, step #000185/000234	Loss: 0.176744
Epoch - 13, step #000186/000234	Loss: 0.176400
Epoch - 13, step #000187/000234	Loss: 0.156653
Epoch - 13, step #000188/000234	Loss: 0.207057
Epoch - 13, step #000189/000234	Loss: 0.147459
Epoch - 13, step #000190/000234	Loss: 0.193066
Epoch - 13, step #000191/000234	Loss: 0.121767
Epoch - 13, step #000192/000234	Loss: 0.201141
Epoch - 13, step #000193/000234	Loss: 0.186766
Epoch - 13, step #000194/000234	Loss: 0.123909
Epoch - 13, step #000195/000234	Loss: 0.185878
Epoch - 13, step #000196/000234	Loss: 0.152356
Epoch - 13, step #000197/000234	Loss: 0.137390
Epoch - 13, step #000198/000234	Loss: 0.188815
Epoch - 13, step #000199/000234	Loss: 0.114272
Epoch - 13, step #000200/000234	Loss: 0.190038
Epoch - 13, step #000201/000234	Loss: 0.146718
Epoch - 13, step #000202/000234	Loss: 0.134481
Epoch - 13, step #000203/000234	Loss: 0.088444
Epoch - 13, step #000204/000234	Loss: 0.153064
Epoch - 13, step #000205/000234	Loss: 0.141588
Epoch - 13, step #000206/000234	Loss: 0.262042
Epoch - 13, step #000207/000234	Loss: 0.133750
Epoch - 13, step #000208/000234	Loss: 0.162985
Epoch - 13, step #000209/000234	Loss: 0.157441
Epoch - 13, step #000210/000234	Loss: 0.196421
Epoch - 13, step #000211/000234	Loss: 0.165449
Epoch - 13, step #000212/000234	Loss: 0.138969
Epoch - 13, step #000213/000234	Loss: 0.104059
Epoch - 13, step #000214/000234	Loss: 0.206550
Epoch - 13, step #000215/000234	Loss: 0.130514
Epoch - 13, step #000216/000234	Loss: 0.092995
Epoch - 13, step #000217/000234	Loss: 0.180048
Epoch - 13, step #000218/000234	Loss: 0.163603
Epoch - 13, step #000219/000234	Loss: 0.196640
Epoch - 13, step #000220/000234	Loss: 0.153194
Epoch - 13, step #000221/000234	Loss: 0.173635
Epoch - 13, step #000222/000234	Loss: 0.112680
Epoch - 13, step #000223/000234	Loss: 0.172762
Epoch - 13, step #000224/000234	Loss: 0.099469
Epoch - 13, step #000225/000234	Loss: 0.181157
Epoch - 13, step #000226/000234	Loss: 0.102269
Epoch - 13, step #000227/000234	Loss: 0.232372
Epoch - 13, step #000228/000234	Loss: 0.105843
Epoch - 13, step #000229/000234	Loss: 0.212021
Epoch - 13, step #000230/000234	Loss: 0.187140
Epoch - 13, step #000231/000234	Loss: 0.149816
Epoch - 13, step #000232/000234	Loss: 0.212085
Epoch - 13, step #000233/000234	Loss: 0.154919
E[13], train Loss: 0.168601, training Acc: 0.950, val loss: 0.086, val Acc: 0.974	 Time: 10.162 seconds
Epoch - 14, step #000000/000234	Loss: 0.181846
Epoch - 14, step #000001/000234	Loss: 0.127497
Epoch - 14, step #000002/000234	Loss: 0.176759
Epoch - 14, step #000003/000234	Loss: 0.196674
Epoch - 14, step #000004/000234	Loss: 0.197909
Epoch - 14, step #000005/000234	Loss: 0.126370
Epoch - 14, step #000006/000234	Loss: 0.153403
Epoch - 14, step #000007/000234	Loss: 0.098592
Epoch - 14, step #000008/000234	Loss: 0.133647
Epoch - 14, step #000009/000234	Loss: 0.174166
Epoch - 14, step #000010/000234	Loss: 0.110913
Epoch - 14, step #000011/000234	Loss: 0.213376
Epoch - 14, step #000012/000234	Loss: 0.098214
Epoch - 14, step #000013/000234	Loss: 0.187936
Epoch - 14, step #000014/000234	Loss: 0.161669
Epoch - 14, step #000015/000234	Loss: 0.177462
Epoch - 14, step #000016/000234	Loss: 0.143774
Epoch - 14, step #000017/000234	Loss: 0.109924
Epoch - 14, step #000018/000234	Loss: 0.125019
Epoch - 14, step #000019/000234	Loss: 0.116779
Epoch - 14, step #000020/000234	Loss: 0.125550
Epoch - 14, step #000021/000234	Loss: 0.189528
Epoch - 14, step #000022/000234	Loss: 0.174387
Epoch - 14, step #000023/000234	Loss: 0.206529
Epoch - 14, step #000024/000234	Loss: 0.222897
Epoch - 14, step #000025/000234	Loss: 0.178617
Epoch - 14, step #000026/000234	Loss: 0.176130
Epoch - 14, step #000027/000234	Loss: 0.112462
Epoch - 14, step #000028/000234	Loss: 0.214721
Epoch - 14, step #000029/000234	Loss: 0.179772
Epoch - 14, step #000030/000234	Loss: 0.124678
Epoch - 14, step #000031/000234	Loss: 0.128309
Epoch - 14, step #000032/000234	Loss: 0.119249
Epoch - 14, step #000033/000234	Loss: 0.119316
Epoch - 14, step #000034/000234	Loss: 0.204903
Epoch - 14, step #000035/000234	Loss: 0.189026
Epoch - 14, step #000036/000234	Loss: 0.220434
Epoch - 14, step #000037/000234	Loss: 0.090882
Epoch - 14, step #000038/000234	Loss: 0.138674
Epoch - 14, step #000039/000234	Loss: 0.163436
Epoch - 14, step #000040/000234	Loss: 0.121452
Epoch - 14, step #000041/000234	Loss: 0.195536
Epoch - 14, step #000042/000234	Loss: 0.154351
Epoch - 14, step #000043/000234	Loss: 0.122584
Epoch - 14, step #000044/000234	Loss: 0.193559
Epoch - 14, step #000045/000234	Loss: 0.097485
Epoch - 14, step #000046/000234	Loss: 0.123804
Epoch - 14, step #000047/000234	Loss: 0.174775
Epoch - 14, step #000048/000234	Loss: 0.170901
Epoch - 14, step #000049/000234	Loss: 0.183547
Epoch - 14, step #000050/000234	Loss: 0.144061
Epoch - 14, step #000051/000234	Loss: 0.190566
Epoch - 14, step #000052/000234	Loss: 0.164294
Epoch - 14, step #000053/000234	Loss: 0.134987
Epoch - 14, step #000054/000234	Loss: 0.173844
Epoch - 14, step #000055/000234	Loss: 0.104711
Epoch - 14, step #000056/000234	Loss: 0.092970
Epoch - 14, step #000057/000234	Loss: 0.108923
Epoch - 14, step #000058/000234	Loss: 0.145653
Epoch - 14, step #000059/000234	Loss: 0.227859
Epoch - 14, step #000060/000234	Loss: 0.133210
Epoch - 14, step #000061/000234	Loss: 0.245111
Epoch - 14, step #000062/000234	Loss: 0.189385
Epoch - 14, step #000063/000234	Loss: 0.178887
Epoch - 14, step #000064/000234	Loss: 0.161928
Epoch - 14, step #000065/000234	Loss: 0.206800
Epoch - 14, step #000066/000234	Loss: 0.155202
Epoch - 14, step #000067/000234	Loss: 0.166837
Epoch - 14, step #000068/000234	Loss: 0.157908
Epoch - 14, step #000069/000234	Loss: 0.116403
Epoch - 14, step #000070/000234	Loss: 0.160764
Epoch - 14, step #000071/000234	Loss: 0.162533
Epoch - 14, step #000072/000234	Loss: 0.191389
Epoch - 14, step #000073/000234	Loss: 0.185975
Epoch - 14, step #000074/000234	Loss: 0.129368
Epoch - 14, step #000075/000234	Loss: 0.134307
Epoch - 14, step #000076/000234	Loss: 0.110758
Epoch - 14, step #000077/000234	Loss: 0.117886
Epoch - 14, step #000078/000234	Loss: 0.138092
Epoch - 14, step #000079/000234	Loss: 0.099635
Epoch - 14, step #000080/000234	Loss: 0.209514
Epoch - 14, step #000081/000234	Loss: 0.230709
Epoch - 14, step #000082/000234	Loss: 0.166909
Epoch - 14, step #000083/000234	Loss: 0.168793
Epoch - 14, step #000084/000234	Loss: 0.146362
Epoch - 14, step #000085/000234	Loss: 0.212941
Epoch - 14, step #000086/000234	Loss: 0.095642
Epoch - 14, step #000087/000234	Loss: 0.153614
Epoch - 14, step #000088/000234	Loss: 0.152529
Epoch - 14, step #000089/000234	Loss: 0.147392
Epoch - 14, step #000090/000234	Loss: 0.083807
Epoch - 14, step #000091/000234	Loss: 0.084160
Epoch - 14, step #000092/000234	Loss: 0.155376
Epoch - 14, step #000093/000234	Loss: 0.269275
Epoch - 14, step #000094/000234	Loss: 0.116773
Epoch - 14, step #000095/000234	Loss: 0.175933
Epoch - 14, step #000096/000234	Loss: 0.142221
Epoch - 14, step #000097/000234	Loss: 0.114060
Epoch - 14, step #000098/000234	Loss: 0.127610
Epoch - 14, step #000099/000234	Loss: 0.162739
Epoch - 14, step #000100/000234	Loss: 0.187915
Epoch - 14, step #000101/000234	Loss: 0.171548
Epoch - 14, step #000102/000234	Loss: 0.142704
Epoch - 14, step #000103/000234	Loss: 0.145539
Epoch - 14, step #000104/000234	Loss: 0.156483
Epoch - 14, step #000105/000234	Loss: 0.191412
Epoch - 14, step #000106/000234	Loss: 0.138184
Epoch - 14, step #000107/000234	Loss: 0.146307
Epoch - 14, step #000108/000234	Loss: 0.174595
Epoch - 14, step #000109/000234	Loss: 0.121089
Epoch - 14, step #000110/000234	Loss: 0.186643
Epoch - 14, step #000111/000234	Loss: 0.110718
Epoch - 14, step #000112/000234	Loss: 0.177158
Epoch - 14, step #000113/000234	Loss: 0.199130
Epoch - 14, step #000114/000234	Loss: 0.138931
Epoch - 14, step #000115/000234	Loss: 0.132293
Epoch - 14, step #000116/000234	Loss: 0.115665
Epoch - 14, step #000117/000234	Loss: 0.205748
Epoch - 14, step #000118/000234	Loss: 0.207684
Epoch - 14, step #000119/000234	Loss: 0.156402
Epoch - 14, step #000120/000234	Loss: 0.245067
Epoch - 14, step #000121/000234	Loss: 0.190336
Epoch - 14, step #000122/000234	Loss: 0.282844
Epoch - 14, step #000123/000234	Loss: 0.132950
Epoch - 14, step #000124/000234	Loss: 0.114639
Epoch - 14, step #000125/000234	Loss: 0.209417
Epoch - 14, step #000126/000234	Loss: 0.142287
Epoch - 14, step #000127/000234	Loss: 0.156904
Epoch - 14, step #000128/000234	Loss: 0.166692
Epoch - 14, step #000129/000234	Loss: 0.178746
Epoch - 14, step #000130/000234	Loss: 0.210617
Epoch - 14, step #000131/000234	Loss: 0.162413
Epoch - 14, step #000132/000234	Loss: 0.287125
Epoch - 14, step #000133/000234	Loss: 0.154917
Epoch - 14, step #000134/000234	Loss: 0.221703
Epoch - 14, step #000135/000234	Loss: 0.140596
Epoch - 14, step #000136/000234	Loss: 0.118744
Epoch - 14, step #000137/000234	Loss: 0.156012
Epoch - 14, step #000138/000234	Loss: 0.170985
Epoch - 14, step #000139/000234	Loss: 0.130215
Epoch - 14, step #000140/000234	Loss: 0.165745
Epoch - 14, step #000141/000234	Loss: 0.175601
Epoch - 14, step #000142/000234	Loss: 0.174419
Epoch - 14, step #000143/000234	Loss: 0.153000
Epoch - 14, step #000144/000234	Loss: 0.134738
Epoch - 14, step #000145/000234	Loss: 0.128177
Epoch - 14, step #000146/000234	Loss: 0.138294
Epoch - 14, step #000147/000234	Loss: 0.165625
Epoch - 14, step #000148/000234	Loss: 0.193181
Epoch - 14, step #000149/000234	Loss: 0.215539
Epoch - 14, step #000150/000234	Loss: 0.167113
Epoch - 14, step #000151/000234	Loss: 0.152850
Epoch - 14, step #000152/000234	Loss: 0.145078
Epoch - 14, step #000153/000234	Loss: 0.173274
Epoch - 14, step #000154/000234	Loss: 0.201086
Epoch - 14, step #000155/000234	Loss: 0.198027
Epoch - 14, step #000156/000234	Loss: 0.177796
Epoch - 14, step #000157/000234	Loss: 0.140772
Epoch - 14, step #000158/000234	Loss: 0.113539
Epoch - 14, step #000159/000234	Loss: 0.150508
Epoch - 14, step #000160/000234	Loss: 0.178327
Epoch - 14, step #000161/000234	Loss: 0.167871
Epoch - 14, step #000162/000234	Loss: 0.129106
Epoch - 14, step #000163/000234	Loss: 0.180046
Epoch - 14, step #000164/000234	Loss: 0.144375
Epoch - 14, step #000165/000234	Loss: 0.174938
Epoch - 14, step #000166/000234	Loss: 0.225805
Epoch - 14, step #000167/000234	Loss: 0.136866
Epoch - 14, step #000168/000234	Loss: 0.181977
Epoch - 14, step #000169/000234	Loss: 0.137202
Epoch - 14, step #000170/000234	Loss: 0.182557
Epoch - 14, step #000171/000234	Loss: 0.151854
Epoch - 14, step #000172/000234	Loss: 0.159319
Epoch - 14, step #000173/000234	Loss: 0.150013
Epoch - 14, step #000174/000234	Loss: 0.106023
Epoch - 14, step #000175/000234	Loss: 0.167383
Epoch - 14, step #000176/000234	Loss: 0.166085
Epoch - 14, step #000177/000234	Loss: 0.149457
Epoch - 14, step #000178/000234	Loss: 0.116010
Epoch - 14, step #000179/000234	Loss: 0.152601
Epoch - 14, step #000180/000234	Loss: 0.152062
Epoch - 14, step #000181/000234	Loss: 0.162172
Epoch - 14, step #000182/000234	Loss: 0.220726
Epoch - 14, step #000183/000234	Loss: 0.178023
Epoch - 14, step #000184/000234	Loss: 0.110412
Epoch - 14, step #000185/000234	Loss: 0.130290
Epoch - 14, step #000186/000234	Loss: 0.194524
Epoch - 14, step #000187/000234	Loss: 0.151010
Epoch - 14, step #000188/000234	Loss: 0.119963
Epoch - 14, step #000189/000234	Loss: 0.170069
Epoch - 14, step #000190/000234	Loss: 0.097391
Epoch - 14, step #000191/000234	Loss: 0.155154
Epoch - 14, step #000192/000234	Loss: 0.180679
Epoch - 14, step #000193/000234	Loss: 0.158046
Epoch - 14, step #000194/000234	Loss: 0.216240
Epoch - 14, step #000195/000234	Loss: 0.157168
Epoch - 14, step #000196/000234	Loss: 0.207688
Epoch - 14, step #000197/000234	Loss: 0.197218
Epoch - 14, step #000198/000234	Loss: 0.088415
Epoch - 14, step #000199/000234	Loss: 0.200969
Epoch - 14, step #000200/000234	Loss: 0.089007
Epoch - 14, step #000201/000234	Loss: 0.110700
Epoch - 14, step #000202/000234	Loss: 0.193867
Epoch - 14, step #000203/000234	Loss: 0.225151
Epoch - 14, step #000204/000234	Loss: 0.135303
Epoch - 14, step #000205/000234	Loss: 0.226037
Epoch - 14, step #000206/000234	Loss: 0.165239
Epoch - 14, step #000207/000234	Loss: 0.126463
Epoch - 14, step #000208/000234	Loss: 0.263404
Epoch - 14, step #000209/000234	Loss: 0.104158
Epoch - 14, step #000210/000234	Loss: 0.097241
Epoch - 14, step #000211/000234	Loss: 0.214365
Epoch - 14, step #000212/000234	Loss: 0.173305
Epoch - 14, step #000213/000234	Loss: 0.199454
Epoch - 14, step #000214/000234	Loss: 0.185614
Epoch - 14, step #000215/000234	Loss: 0.144099
Epoch - 14, step #000216/000234	Loss: 0.132581
Epoch - 14, step #000217/000234	Loss: 0.135599
Epoch - 14, step #000218/000234	Loss: 0.127118
Epoch - 14, step #000219/000234	Loss: 0.100190
Epoch - 14, step #000220/000234	Loss: 0.171738
Epoch - 14, step #000221/000234	Loss: 0.097040
Epoch - 14, step #000222/000234	Loss: 0.096078
Epoch - 14, step #000223/000234	Loss: 0.124244
Epoch - 14, step #000224/000234	Loss: 0.166909
Epoch - 14, step #000225/000234	Loss: 0.154878
Epoch - 14, step #000226/000234	Loss: 0.158340
Epoch - 14, step #000227/000234	Loss: 0.095977
Epoch - 14, step #000228/000234	Loss: 0.171166
Epoch - 14, step #000229/000234	Loss: 0.153883
Epoch - 14, step #000230/000234	Loss: 0.149842
Epoch - 14, step #000231/000234	Loss: 0.148696
Epoch - 14, step #000232/000234	Loss: 0.119076
Epoch - 14, step #000233/000234	Loss: 0.079472
E[14], train Loss: 0.158385, training Acc: 0.953, val loss: 0.082, val Acc: 0.975	 Time: 10.226 seconds
Epoch - 15, step #000000/000234	Loss: 0.152546
Epoch - 15, step #000001/000234	Loss: 0.160406
Epoch - 15, step #000002/000234	Loss: 0.159838
Epoch - 15, step #000003/000234	Loss: 0.137878
Epoch - 15, step #000004/000234	Loss: 0.081695
Epoch - 15, step #000005/000234	Loss: 0.192624
Epoch - 15, step #000006/000234	Loss: 0.088054
Epoch - 15, step #000007/000234	Loss: 0.133982
Epoch - 15, step #000008/000234	Loss: 0.137734
Epoch - 15, step #000009/000234	Loss: 0.138350
Epoch - 15, step #000010/000234	Loss: 0.175554
Epoch - 15, step #000011/000234	Loss: 0.198649
Epoch - 15, step #000012/000234	Loss: 0.202143
Epoch - 15, step #000013/000234	Loss: 0.152752
Epoch - 15, step #000014/000234	Loss: 0.233031
Epoch - 15, step #000015/000234	Loss: 0.183541
Epoch - 15, step #000016/000234	Loss: 0.120124
Epoch - 15, step #000017/000234	Loss: 0.105581
Epoch - 15, step #000018/000234	Loss: 0.163240
Epoch - 15, step #000019/000234	Loss: 0.127189
Epoch - 15, step #000020/000234	Loss: 0.137930
Epoch - 15, step #000021/000234	Loss: 0.144790
Epoch - 15, step #000022/000234	Loss: 0.139302
Epoch - 15, step #000023/000234	Loss: 0.155753
Epoch - 15, step #000024/000234	Loss: 0.139699
Epoch - 15, step #000025/000234	Loss: 0.203848
Epoch - 15, step #000026/000234	Loss: 0.187622
Epoch - 15, step #000027/000234	Loss: 0.123313
Epoch - 15, step #000028/000234	Loss: 0.185204
Epoch - 15, step #000029/000234	Loss: 0.091706
Epoch - 15, step #000030/000234	Loss: 0.121895
Epoch - 15, step #000031/000234	Loss: 0.163106
Epoch - 15, step #000032/000234	Loss: 0.198291
Epoch - 15, step #000033/000234	Loss: 0.168020
Epoch - 15, step #000034/000234	Loss: 0.153066
Epoch - 15, step #000035/000234	Loss: 0.119246
Epoch - 15, step #000036/000234	Loss: 0.160105
Epoch - 15, step #000037/000234	Loss: 0.177276
Epoch - 15, step #000038/000234	Loss: 0.107970
Epoch - 15, step #000039/000234	Loss: 0.152928
Epoch - 15, step #000040/000234	Loss: 0.081069
Epoch - 15, step #000041/000234	Loss: 0.145237
Epoch - 15, step #000042/000234	Loss: 0.205910
Epoch - 15, step #000043/000234	Loss: 0.136123
Epoch - 15, step #000044/000234	Loss: 0.141095
Epoch - 15, step #000045/000234	Loss: 0.146145
Epoch - 15, step #000046/000234	Loss: 0.103708
Epoch - 15, step #000047/000234	Loss: 0.147155
Epoch - 15, step #000048/000234	Loss: 0.163046
Epoch - 15, step #000049/000234	Loss: 0.187563
Epoch - 15, step #000050/000234	Loss: 0.207820
Epoch - 15, step #000051/000234	Loss: 0.111451
Epoch - 15, step #000052/000234	Loss: 0.105299
Epoch - 15, step #000053/000234	Loss: 0.117461
Epoch - 15, step #000054/000234	Loss: 0.125470
Epoch - 15, step #000055/000234	Loss: 0.189866
Epoch - 15, step #000056/000234	Loss: 0.167640
Epoch - 15, step #000057/000234	Loss: 0.132897
Epoch - 15, step #000058/000234	Loss: 0.120606
Epoch - 15, step #000059/000234	Loss: 0.102876
Epoch - 15, step #000060/000234	Loss: 0.172541
Epoch - 15, step #000061/000234	Loss: 0.235252
Epoch - 15, step #000062/000234	Loss: 0.147915
Epoch - 15, step #000063/000234	Loss: 0.132027
Epoch - 15, step #000064/000234	Loss: 0.085286
Epoch - 15, step #000065/000234	Loss: 0.156033
Epoch - 15, step #000066/000234	Loss: 0.212129
Epoch - 15, step #000067/000234	Loss: 0.159067
Epoch - 15, step #000068/000234	Loss: 0.162889
Epoch - 15, step #000069/000234	Loss: 0.179408
Epoch - 15, step #000070/000234	Loss: 0.159886
Epoch - 15, step #000071/000234	Loss: 0.218919
Epoch - 15, step #000072/000234	Loss: 0.171914
Epoch - 15, step #000073/000234	Loss: 0.136805
Epoch - 15, step #000074/000234	Loss: 0.137322
Epoch - 15, step #000075/000234	Loss: 0.272414
Epoch - 15, step #000076/000234	Loss: 0.211928
Epoch - 15, step #000077/000234	Loss: 0.135504
Epoch - 15, step #000078/000234	Loss: 0.126505
Epoch - 15, step #000079/000234	Loss: 0.102945
Epoch - 15, step #000080/000234	Loss: 0.137138
Epoch - 15, step #000081/000234	Loss: 0.132096
Epoch - 15, step #000082/000234	Loss: 0.162843
Epoch - 15, step #000083/000234	Loss: 0.113083
Epoch - 15, step #000084/000234	Loss: 0.121893
Epoch - 15, step #000085/000234	Loss: 0.205157
Epoch - 15, step #000086/000234	Loss: 0.201007
Epoch - 15, step #000087/000234	Loss: 0.135941
Epoch - 15, step #000088/000234	Loss: 0.170272
Epoch - 15, step #000089/000234	Loss: 0.109661
Epoch - 15, step #000090/000234	Loss: 0.139357
Epoch - 15, step #000091/000234	Loss: 0.151487
Epoch - 15, step #000092/000234	Loss: 0.157306
Epoch - 15, step #000093/000234	Loss: 0.144311
Epoch - 15, step #000094/000234	Loss: 0.142287
Epoch - 15, step #000095/000234	Loss: 0.117322
Epoch - 15, step #000096/000234	Loss: 0.163521
Epoch - 15, step #000097/000234	Loss: 0.177174
Epoch - 15, step #000098/000234	Loss: 0.105861
Epoch - 15, step #000099/000234	Loss: 0.171227
Epoch - 15, step #000100/000234	Loss: 0.162328
Epoch - 15, step #000101/000234	Loss: 0.089869
Epoch - 15, step #000102/000234	Loss: 0.141805
Epoch - 15, step #000103/000234	Loss: 0.094481
Epoch - 15, step #000104/000234	Loss: 0.173790
Epoch - 15, step #000105/000234	Loss: 0.148309
Epoch - 15, step #000106/000234	Loss: 0.145413
Epoch - 15, step #000107/000234	Loss: 0.091603
Epoch - 15, step #000108/000234	Loss: 0.167352
Epoch - 15, step #000109/000234	Loss: 0.177638
Epoch - 15, step #000110/000234	Loss: 0.123728
Epoch - 15, step #000111/000234	Loss: 0.092136
Epoch - 15, step #000112/000234	Loss: 0.101756
Epoch - 15, step #000113/000234	Loss: 0.226611
Epoch - 15, step #000114/000234	Loss: 0.175881
Epoch - 15, step #000115/000234	Loss: 0.158920
Epoch - 15, step #000116/000234	Loss: 0.072958
Epoch - 15, step #000117/000234	Loss: 0.244188
Epoch - 15, step #000118/000234	Loss: 0.210563
Epoch - 15, step #000119/000234	Loss: 0.123854
Epoch - 15, step #000120/000234	Loss: 0.138960
Epoch - 15, step #000121/000234	Loss: 0.214129
Epoch - 15, step #000122/000234	Loss: 0.111706
Epoch - 15, step #000123/000234	Loss: 0.141073
Epoch - 15, step #000124/000234	Loss: 0.183193
Epoch - 15, step #000125/000234	Loss: 0.138380
Epoch - 15, step #000126/000234	Loss: 0.184573
Epoch - 15, step #000127/000234	Loss: 0.123541
Epoch - 15, step #000128/000234	Loss: 0.129714
Epoch - 15, step #000129/000234	Loss: 0.132741
Epoch - 15, step #000130/000234	Loss: 0.099649
Epoch - 15, step #000131/000234	Loss: 0.185220
Epoch - 15, step #000132/000234	Loss: 0.099923
Epoch - 15, step #000133/000234	Loss: 0.116517
Epoch - 15, step #000134/000234	Loss: 0.182889
Epoch - 15, step #000135/000234	Loss: 0.204119
Epoch - 15, step #000136/000234	Loss: 0.182421
Epoch - 15, step #000137/000234	Loss: 0.152859
Epoch - 15, step #000138/000234	Loss: 0.128257
Epoch - 15, step #000139/000234	Loss: 0.147550
Epoch - 15, step #000140/000234	Loss: 0.116652
Epoch - 15, step #000141/000234	Loss: 0.192979
Epoch - 15, step #000142/000234	Loss: 0.178612
Epoch - 15, step #000143/000234	Loss: 0.171620
Epoch - 15, step #000144/000234	Loss: 0.193391
Epoch - 15, step #000145/000234	Loss: 0.218612
Epoch - 15, step #000146/000234	Loss: 0.127925
Epoch - 15, step #000147/000234	Loss: 0.171744
Epoch - 15, step #000148/000234	Loss: 0.164057
Epoch - 15, step #000149/000234	Loss: 0.163386
Epoch - 15, step #000150/000234	Loss: 0.130283
Epoch - 15, step #000151/000234	Loss: 0.154653
Epoch - 15, step #000152/000234	Loss: 0.133360
Epoch - 15, step #000153/000234	Loss: 0.166790
Epoch - 15, step #000154/000234	Loss: 0.154771
Epoch - 15, step #000155/000234	Loss: 0.108169
Epoch - 15, step #000156/000234	Loss: 0.205402
Epoch - 15, step #000157/000234	Loss: 0.167467
Epoch - 15, step #000158/000234	Loss: 0.228360
Epoch - 15, step #000159/000234	Loss: 0.232248
Epoch - 15, step #000160/000234	Loss: 0.146979
Epoch - 15, step #000161/000234	Loss: 0.188026
Epoch - 15, step #000162/000234	Loss: 0.164987
Epoch - 15, step #000163/000234	Loss: 0.139463
Epoch - 15, step #000164/000234	Loss: 0.205427
Epoch - 15, step #000165/000234	Loss: 0.142935
Epoch - 15, step #000166/000234	Loss: 0.163360
Epoch - 15, step #000167/000234	Loss: 0.228652
Epoch - 15, step #000168/000234	Loss: 0.185139
Epoch - 15, step #000169/000234	Loss: 0.124192
Epoch - 15, step #000170/000234	Loss: 0.157498
Epoch - 15, step #000171/000234	Loss: 0.160117
Epoch - 15, step #000172/000234	Loss: 0.181683
Epoch - 15, step #000173/000234	Loss: 0.163208
Epoch - 15, step #000174/000234	Loss: 0.287861
Epoch - 15, step #000175/000234	Loss: 0.143257
Epoch - 15, step #000176/000234	Loss: 0.151877
Epoch - 15, step #000177/000234	Loss: 0.151235
Epoch - 15, step #000178/000234	Loss: 0.177653
Epoch - 15, step #000179/000234	Loss: 0.141261
Epoch - 15, step #000180/000234	Loss: 0.110179
Epoch - 15, step #000181/000234	Loss: 0.141391
Epoch - 15, step #000182/000234	Loss: 0.237968
Epoch - 15, step #000183/000234	Loss: 0.158829
Epoch - 15, step #000184/000234	Loss: 0.140374
Epoch - 15, step #000185/000234	Loss: 0.114738
Epoch - 15, step #000186/000234	Loss: 0.158011
Epoch - 15, step #000187/000234	Loss: 0.180494
Epoch - 15, step #000188/000234	Loss: 0.171110
Epoch - 15, step #000189/000234	Loss: 0.191036
Epoch - 15, step #000190/000234	Loss: 0.118504
Epoch - 15, step #000191/000234	Loss: 0.099276
Epoch - 15, step #000192/000234	Loss: 0.176494
Epoch - 15, step #000193/000234	Loss: 0.171803
Epoch - 15, step #000194/000234	Loss: 0.166467
Epoch - 15, step #000195/000234	Loss: 0.184104
Epoch - 15, step #000196/000234	Loss: 0.097686
Epoch - 15, step #000197/000234	Loss: 0.162593
Epoch - 15, step #000198/000234	Loss: 0.212824
Epoch - 15, step #000199/000234	Loss: 0.142761
Epoch - 15, step #000200/000234	Loss: 0.173830
Epoch - 15, step #000201/000234	Loss: 0.167103
Epoch - 15, step #000202/000234	Loss: 0.117951
Epoch - 15, step #000203/000234	Loss: 0.100149
Epoch - 15, step #000204/000234	Loss: 0.117859
Epoch - 15, step #000205/000234	Loss: 0.161429
Epoch - 15, step #000206/000234	Loss: 0.171467
Epoch - 15, step #000207/000234	Loss: 0.119677
Epoch - 15, step #000208/000234	Loss: 0.134233
Epoch - 15, step #000209/000234	Loss: 0.257545
Epoch - 15, step #000210/000234	Loss: 0.135370
Epoch - 15, step #000211/000234	Loss: 0.133830
Epoch - 15, step #000212/000234	Loss: 0.129922
Epoch - 15, step #000213/000234	Loss: 0.113236
Epoch - 15, step #000214/000234	Loss: 0.098405
Epoch - 15, step #000215/000234	Loss: 0.068680
Epoch - 15, step #000216/000234	Loss: 0.147810
Epoch - 15, step #000217/000234	Loss: 0.143876
Epoch - 15, step #000218/000234	Loss: 0.105830
Epoch - 15, step #000219/000234	Loss: 0.170706
Epoch - 15, step #000220/000234	Loss: 0.128904
Epoch - 15, step #000221/000234	Loss: 0.151420
Epoch - 15, step #000222/000234	Loss: 0.166611
Epoch - 15, step #000223/000234	Loss: 0.108082
Epoch - 15, step #000224/000234	Loss: 0.084795
Epoch - 15, step #000225/000234	Loss: 0.136594
Epoch - 15, step #000226/000234	Loss: 0.081798
Epoch - 15, step #000227/000234	Loss: 0.105960
Epoch - 15, step #000228/000234	Loss: 0.107845
Epoch - 15, step #000229/000234	Loss: 0.073828
Epoch - 15, step #000230/000234	Loss: 0.107487
Epoch - 15, step #000231/000234	Loss: 0.091256
Epoch - 15, step #000232/000234	Loss: 0.120191
Epoch - 15, step #000233/000234	Loss: 0.180210
E[15], train Loss: 0.151481, training Acc: 0.955, val loss: 0.080, val Acc: 0.976	 Time: 10.251 seconds
Total training time: 173.8399407863617 seconds
# GPSs:  2
# GPSs:  2
# I am rank 1 of 2
# I am rank 0 of 2
Epoch - 0, step #000000/000117	Loss: 2.306799
Epoch - 0, step #000001/000117	Loss: 2.300089
Epoch - 0, step #000002/000117	Loss: 2.284419
Epoch - 0, step #000003/000117	Loss: 2.284147
Epoch - 0, step #000004/000117	Loss: 2.278157
Epoch - 0, step #000005/000117	Loss: 2.269543
Epoch - 0, step #000006/000117	Loss: 2.261760
Epoch - 0, step #000007/000117	Loss: 2.249686
Epoch - 0, step #000008/000117	Loss: 2.232985
Epoch - 0, step #000009/000117	Loss: 2.219394
Epoch - 0, step #000010/000117	Loss: 2.218604
Epoch - 0, step #000011/000117	Loss: 2.212885
Epoch - 0, step #000012/000117	Loss: 2.187233
Epoch - 0, step #000013/000117	Loss: 2.196071
Epoch - 0, step #000014/000117	Loss: 2.153869
Epoch - 0, step #000015/000117	Loss: 2.139363
Epoch - 0, step #000016/000117	Loss: 2.129894
Epoch - 0, step #000017/000117	Loss: 2.105051
Epoch - 0, step #000018/000117	Loss: 2.086209
Epoch - 0, step #000019/000117	Loss: 2.039609
Epoch - 0, step #000020/000117	Loss: 2.010003
Epoch - 0, step #000021/000117	Loss: 1.979207
Epoch - 0, step #000022/000117	Loss: 1.955915
Epoch - 0, step #000023/000117	Loss: 1.894459
Epoch - 0, step #000024/000117	Loss: 1.835678
Epoch - 0, step #000025/000117	Loss: 1.831749
Epoch - 0, step #000026/000117	Loss: 1.781507
Epoch - 0, step #000027/000117	Loss: 1.730414
Epoch - 0, step #000028/000117	Loss: 1.633088
Epoch - 0, step #000029/000117	Loss: 1.614564
Epoch - 0, step #000030/000117	Loss: 1.524190
Epoch - 0, step #000031/000117	Loss: 1.447896
Epoch - 0, step #000032/000117	Loss: 1.419374
Epoch - 0, step #000033/000117	Loss: 1.361390
Epoch - 0, step #000034/000117	Loss: 1.307515
Epoch - 0, step #000035/000117	Loss: 1.285745
Epoch - 0, step #000036/000117	Loss: 1.268208
Epoch - 0, step #000037/000117	Loss: 1.159829
Epoch - 0, step #000038/000117	Loss: 1.182252
Epoch - 0, step #000039/000117	Loss: 1.131326
Epoch - 0, step #000040/000117	Loss: 1.151906
Epoch - 0, step #000041/000117	Loss: 1.153239
Epoch - 0, step #000042/000117	Loss: 1.059253
Epoch - 0, step #000043/000117	Loss: 1.038819
Epoch - 0, step #000044/000117	Loss: 0.991358
Epoch - 0, step #000045/000117	Loss: 1.074563
Epoch - 0, step #000046/000117	Loss: 0.979201
Epoch - 0, step #000047/000117	Loss: 0.959032
Epoch - 0, step #000048/000117	Loss: 0.920609
Epoch - 0, step #000049/000117	Loss: 0.883588
Epoch - 0, step #000050/000117	Loss: 0.892532
Epoch - 0, step #000051/000117	Loss: 0.882117
Epoch - 0, step #000052/000117	Loss: 0.906162
Epoch - 0, step #000053/000117	Loss: 0.880935
Epoch - 0, step #000054/000117	Loss: 0.805134
Epoch - 0, step #000055/000117	Loss: 0.833061
Epoch - 0, step #000056/000117	Loss: 1.010439
Epoch - 0, step #000057/000117	Loss: 0.896523
Epoch - 0, step #000058/000117	Loss: 0.791055
Epoch - 0, step #000059/000117	Loss: 0.794060
Epoch - 0, step #000060/000117	Loss: 0.750940
Epoch - 0, step #000061/000117	Loss: 0.768937
Epoch - 0, step #000062/000117	Loss: 0.784813
Epoch - 0, step #000063/000117	Loss: 0.745331
Epoch - 0, step #000064/000117	Loss: 0.693549
Epoch - 0, step #000065/000117	Loss: 0.729280
Epoch - 0, step #000066/000117	Loss: 0.678888
Epoch - 0, step #000067/000117	Loss: 0.856814
Epoch - 0, step #000068/000117	Loss: 0.735504
Epoch - 0, step #000069/000117	Loss: 0.766205
Epoch - 0, step #000070/000117	Loss: 0.644055
Epoch - 0, step #000071/000117	Loss: 0.732170
Epoch - 0, step #000072/000117	Loss: 0.577055
Epoch - 0, step #000073/000117	Loss: 0.701729
Epoch - 0, step #000074/000117	Loss: 0.705217
Epoch - 0, step #000075/000117	Loss: 0.672926
Epoch - 0, step #000076/000117	Loss: 0.676085
Epoch - 0, step #000077/000117	Loss: 0.608068
Epoch - 0, step #000078/000117	Loss: 0.652284
Epoch - 0, step #000079/000117	Loss: 0.667691
Epoch - 0, step #000080/000117	Loss: 0.632755
Epoch - 0, step #000081/000117	Loss: 0.626714
Epoch - 0, step #000082/000117	Loss: 0.633265
Epoch - 0, step #000083/000117	Loss: 0.587431
Epoch - 0, step #000084/000117	Loss: 0.632700
Epoch - 0, step #000085/000117	Loss: 0.593945
Epoch - 0, step #000086/000117	Loss: 0.651533
Epoch - 0, step #000087/000117	Loss: 0.562570
Epoch - 0, step #000088/000117	Loss: 0.696046
Epoch - 0, step #000089/000117	Loss: 0.515901
Epoch - 0, step #000090/000117	Loss: 0.639279
Epoch - 0, step #000091/000117	Loss: 0.625876
Epoch - 0, step #000092/000117	Loss: 0.650429
Epoch - 0, step #000093/000117	Loss: 0.597822
Epoch - 0, step #000094/000117	Loss: 0.562360
Epoch - 0, step #000095/000117	Loss: 0.568665
Epoch - 0, step #000096/000117	Loss: 0.673317
Epoch - 0, step #000097/000117	Loss: 0.513674
Epoch - 0, step #000098/000117	Loss: 0.578782
Epoch - 0, step #000099/000117	Loss: 0.573797
Epoch - 0, step #000100/000117	Loss: 0.510720
Epoch - 0, step #000101/000117	Loss: 0.543772
Epoch - 0, step #000102/000117	Loss: 0.617217
Epoch - 0, step #000103/000117	Loss: 0.488919
Epoch - 0, step #000104/000117	Loss: 0.610219
Epoch - 0, step #000105/000117	Loss: 0.519433
Epoch - 0, step #000106/000117	Loss: 0.458256
Epoch - 0, step #000107/000117	Loss: 0.538216
Epoch - 0, step #000108/000117	Loss: 0.556235
Epoch - 0, step #000109/000117	Loss: 0.563567
Epoch - 0, step #000110/000117	Loss: 0.613095
Epoch - 0, step #000111/000117	Loss: 0.543529
Epoch - 0, step #000112/000117	Loss: 0.532510
Epoch - 0, step #000113/000117	Loss: 0.499309
Epoch - 0, step #000114/000117	Loss: 0.494364
Epoch - 0, step #000115/000117	Loss: 0.471278
Epoch - 0, step #000116/000117	Loss: 0.487021
E[0], train Loss: 1.108767, training Acc: 0.645, val loss: 0.394, val Acc: 0.887	 Time: 14.280 seconds
E[0], train Loss: 1.108767, training Acc: 0.645, val loss: 0.419, val Acc: 0.875	 Time: 21.130 seconds
Epoch - 1, step #000000/000117	Loss: 0.537967
Epoch - 1, step #000001/000117	Loss: 0.473891
Epoch - 1, step #000002/000117	Loss: 0.467720
Epoch - 1, step #000003/000117	Loss: 0.536553
Epoch - 1, step #000004/000117	Loss: 0.497047
Epoch - 1, step #000005/000117	Loss: 0.473978
Epoch - 1, step #000006/000117	Loss: 0.600664
Epoch - 1, step #000007/000117	Loss: 0.481040
Epoch - 1, step #000008/000117	Loss: 0.489769
Epoch - 1, step #000009/000117	Loss: 0.504265
Epoch - 1, step #000010/000117	Loss: 0.512949
Epoch - 1, step #000011/000117	Loss: 0.484158
Epoch - 1, step #000012/000117	Loss: 0.478018
Epoch - 1, step #000013/000117	Loss: 0.471397
Epoch - 1, step #000014/000117	Loss: 0.523990
Epoch - 1, step #000015/000117	Loss: 0.527620
Epoch - 1, step #000016/000117	Loss: 0.492719
Epoch - 1, step #000017/000117	Loss: 0.516202
Epoch - 1, step #000018/000117	Loss: 0.536288
Epoch - 1, step #000019/000117	Loss: 0.478335
Epoch - 1, step #000020/000117	Loss: 0.575052
Epoch - 1, step #000021/000117	Loss: 0.517798
Epoch - 1, step #000022/000117	Loss: 0.532454
Epoch - 1, step #000023/000117	Loss: 0.471038
Epoch - 1, step #000024/000117	Loss: 0.434433
Epoch - 1, step #000025/000117	Loss: 0.517870
Epoch - 1, step #000026/000117	Loss: 0.485655
Epoch - 1, step #000027/000117	Loss: 0.484605
Epoch - 1, step #000028/000117	Loss: 0.446628
Epoch - 1, step #000029/000117	Loss: 0.516876
Epoch - 1, step #000030/000117	Loss: 0.497160
Epoch - 1, step #000031/000117	Loss: 0.478460
Epoch - 1, step #000032/000117	Loss: 0.458676
Epoch - 1, step #000033/000117	Loss: 0.481244
Epoch - 1, step #000034/000117	Loss: 0.496270
Epoch - 1, step #000035/000117	Loss: 0.482319
Epoch - 1, step #000036/000117	Loss: 0.474875
Epoch - 1, step #000037/000117	Loss: 0.507579
Epoch - 1, step #000038/000117	Loss: 0.517531
Epoch - 1, step #000039/000117	Loss: 0.597063
Epoch - 1, step #000040/000117	Loss: 0.389440
Epoch - 1, step #000041/000117	Loss: 0.449393
Epoch - 1, step #000042/000117	Loss: 0.567786
Epoch - 1, step #000043/000117	Loss: 0.460781
Epoch - 1, step #000044/000117	Loss: 0.513152
Epoch - 1, step #000045/000117	Loss: 0.538224
Epoch - 1, step #000046/000117	Loss: 0.467969
Epoch - 1, step #000047/000117	Loss: 0.443962
Epoch - 1, step #000048/000117	Loss: 0.455206
Epoch - 1, step #000049/000117	Loss: 0.471854
Epoch - 1, step #000050/000117	Loss: 0.486893
Epoch - 1, step #000051/000117	Loss: 0.529859
Epoch - 1, step #000052/000117	Loss: 0.466614
Epoch - 1, step #000053/000117	Loss: 0.490513
Epoch - 1, step #000054/000117	Loss: 0.507685
Epoch - 1, step #000055/000117	Loss: 0.463226
Epoch - 1, step #000056/000117	Loss: 0.444322
Epoch - 1, step #000057/000117	Loss: 0.474841
Epoch - 1, step #000058/000117	Loss: 0.470381
Epoch - 1, step #000059/000117	Loss: 0.434366
Epoch - 1, step #000060/000117	Loss: 0.433211
Epoch - 1, step #000061/000117	Loss: 0.499456
Epoch - 1, step #000062/000117	Loss: 0.434000
Epoch - 1, step #000063/000117	Loss: 0.443712
Epoch - 1, step #000064/000117	Loss: 0.526710
Epoch - 1, step #000065/000117	Loss: 0.479815
Epoch - 1, step #000066/000117	Loss: 0.457652
Epoch - 1, step #000067/000117	Loss: 0.461497
Epoch - 1, step #000068/000117	Loss: 0.458613
Epoch - 1, step #000069/000117	Loss: 0.421033
Epoch - 1, step #000070/000117	Loss: 0.415878
Epoch - 1, step #000071/000117	Loss: 0.374542
Epoch - 1, step #000072/000117	Loss: 0.519132
Epoch - 1, step #000073/000117	Loss: 0.378824
Epoch - 1, step #000074/000117	Loss: 0.450036
Epoch - 1, step #000075/000117	Loss: 0.412088
Epoch - 1, step #000076/000117	Loss: 0.418182
Epoch - 1, step #000077/000117	Loss: 0.379922
Epoch - 1, step #000078/000117	Loss: 0.403705
Epoch - 1, step #000079/000117	Loss: 0.391797
Epoch - 1, step #000080/000117	Loss: 0.440362
Epoch - 1, step #000081/000117	Loss: 0.461571
Epoch - 1, step #000082/000117	Loss: 0.469365
Epoch - 1, step #000083/000117	Loss: 0.445016
Epoch - 1, step #000084/000117	Loss: 0.438301
Epoch - 1, step #000085/000117	Loss: 0.431234
Epoch - 1, step #000086/000117	Loss: 0.423246
Epoch - 1, step #000087/000117	Loss: 0.407932
Epoch - 1, step #000088/000117	Loss: 0.380707
Epoch - 1, step #000089/000117	Loss: 0.358805
Epoch - 1, step #000090/000117	Loss: 0.395859
Epoch - 1, step #000091/000117	Loss: 0.392329
Epoch - 1, step #000092/000117	Loss: 0.342990
Epoch - 1, step #000093/000117	Loss: 0.408696
Epoch - 1, step #000094/000117	Loss: 0.366778
Epoch - 1, step #000095/000117	Loss: 0.364325
Epoch - 1, step #000096/000117	Loss: 0.407620
Epoch - 1, step #000097/000117	Loss: 0.514996
Epoch - 1, step #000098/000117	Loss: 0.405356
Epoch - 1, step #000099/000117	Loss: 0.428914
Epoch - 1, step #000100/000117	Loss: 0.401943
Epoch - 1, step #000101/000117	Loss: 0.355264
Epoch - 1, step #000102/000117	Loss: 0.381906
Epoch - 1, step #000103/000117	Loss: 0.412142
Epoch - 1, step #000104/000117	Loss: 0.416699
Epoch - 1, step #000105/000117	Loss: 0.420372
Epoch - 1, step #000106/000117	Loss: 0.483512
Epoch - 1, step #000107/000117	Loss: 0.358446
Epoch - 1, step #000108/000117	Loss: 0.356703
Epoch - 1, step #000109/000117	Loss: 0.427688
Epoch - 1, step #000110/000117	Loss: 0.391136
Epoch - 1, step #000111/000117	Loss: 0.469799
Epoch - 1, step #000112/000117	Loss: 0.398415
Epoch - 1, step #000113/000117	Loss: 0.417643
Epoch - 1, step #000114/000117	Loss: 0.441669
Epoch - 1, step #000115/000117	Loss: 0.412607
Epoch - 1, step #000116/000117	Loss: 0.391130
E[1], train Loss: 0.457828, training Acc: 0.858, val loss: 0.337, val Acc: 0.904	 Time: 6.269 seconds
E[1], train Loss: 0.457828, training Acc: 0.858, val loss: 0.317, val Acc: 0.903	 Time: 20.665 seconds
Epoch - 2, step #000000/000117	Loss: 0.351980
Epoch - 2, step #000001/000117	Loss: 0.386367
Epoch - 2, step #000002/000117	Loss: 0.393615
Epoch - 2, step #000003/000117	Loss: 0.451025
Epoch - 2, step #000004/000117	Loss: 0.420930
Epoch - 2, step #000005/000117	Loss: 0.406633
Epoch - 2, step #000006/000117	Loss: 0.311171
Epoch - 2, step #000007/000117	Loss: 0.384403
Epoch - 2, step #000008/000117	Loss: 0.564623
Epoch - 2, step #000009/000117	Loss: 0.397740
Epoch - 2, step #000010/000117	Loss: 0.382913
Epoch - 2, step #000011/000117	Loss: 0.346106
Epoch - 2, step #000012/000117	Loss: 0.359650
Epoch - 2, step #000013/000117	Loss: 0.434972
Epoch - 2, step #000014/000117	Loss: 0.408504
Epoch - 2, step #000015/000117	Loss: 0.349348
Epoch - 2, step #000016/000117	Loss: 0.366710
Epoch - 2, step #000017/000117	Loss: 0.478929
Epoch - 2, step #000018/000117	Loss: 0.340094
Epoch - 2, step #000019/000117	Loss: 0.423311
Epoch - 2, step #000020/000117	Loss: 0.330752
Epoch - 2, step #000021/000117	Loss: 0.344399
Epoch - 2, step #000022/000117	Loss: 0.403383
Epoch - 2, step #000023/000117	Loss: 0.377887
Epoch - 2, step #000024/000117	Loss: 0.373461
Epoch - 2, step #000025/000117	Loss: 0.390136
Epoch - 2, step #000026/000117	Loss: 0.396932
Epoch - 2, step #000027/000117	Loss: 0.417781
Epoch - 2, step #000028/000117	Loss: 0.485683
Epoch - 2, step #000029/000117	Loss: 0.495401
Epoch - 2, step #000030/000117	Loss: 0.364871
Epoch - 2, step #000031/000117	Loss: 0.410490
Epoch - 2, step #000032/000117	Loss: 0.435431
Epoch - 2, step #000033/000117	Loss: 0.315025
Epoch - 2, step #000034/000117	Loss: 0.369549
Epoch - 2, step #000035/000117	Loss: 0.384385
Epoch - 2, step #000036/000117	Loss: 0.346084
Epoch - 2, step #000037/000117	Loss: 0.374261
Epoch - 2, step #000038/000117	Loss: 0.368796
Epoch - 2, step #000039/000117	Loss: 0.352013
Epoch - 2, step #000040/000117	Loss: 0.377547
Epoch - 2, step #000041/000117	Loss: 0.397162
Epoch - 2, step #000042/000117	Loss: 0.363231
Epoch - 2, step #000043/000117	Loss: 0.335564
Epoch - 2, step #000044/000117	Loss: 0.356563
Epoch - 2, step #000045/000117	Loss: 0.312755
Epoch - 2, step #000046/000117	Loss: 0.315252
Epoch - 2, step #000047/000117	Loss: 0.380563
Epoch - 2, step #000048/000117	Loss: 0.338855
Epoch - 2, step #000049/000117	Loss: 0.335284
Epoch - 2, step #000050/000117	Loss: 0.302554
Epoch - 2, step #000051/000117	Loss: 0.393007
Epoch - 2, step #000052/000117	Loss: 0.418525
Epoch - 2, step #000053/000117	Loss: 0.368432
Epoch - 2, step #000054/000117	Loss: 0.325117
Epoch - 2, step #000055/000117	Loss: 0.357129
Epoch - 2, step #000056/000117	Loss: 0.401993
Epoch - 2, step #000057/000117	Loss: 0.334357
Epoch - 2, step #000058/000117	Loss: 0.362264
Epoch - 2, step #000059/000117	Loss: 0.346710
Epoch - 2, step #000060/000117	Loss: 0.408238
Epoch - 2, step #000061/000117	Loss: 0.382649
Epoch - 2, step #000062/000117	Loss: 0.362999
Epoch - 2, step #000063/000117	Loss: 0.405873
Epoch - 2, step #000064/000117	Loss: 0.428129
Epoch - 2, step #000065/000117	Loss: 0.379219
Epoch - 2, step #000066/000117	Loss: 0.402539
Epoch - 2, step #000067/000117	Loss: 0.413019
Epoch - 2, step #000068/000117	Loss: 0.388242
Epoch - 2, step #000069/000117	Loss: 0.444387
Epoch - 2, step #000070/000117	Loss: 0.337018
Epoch - 2, step #000071/000117	Loss: 0.388893
Epoch - 2, step #000072/000117	Loss: 0.382704
Epoch - 2, step #000073/000117	Loss: 0.335871
Epoch - 2, step #000074/000117	Loss: 0.420770
Epoch - 2, step #000075/000117	Loss: 0.315492
Epoch - 2, step #000076/000117	Loss: 0.421362
Epoch - 2, step #000077/000117	Loss: 0.332232
Epoch - 2, step #000078/000117	Loss: 0.392494
Epoch - 2, step #000079/000117	Loss: 0.367850
Epoch - 2, step #000080/000117	Loss: 0.385718
Epoch - 2, step #000081/000117	Loss: 0.299415
Epoch - 2, step #000082/000117	Loss: 0.360681
Epoch - 2, step #000083/000117	Loss: 0.416469
Epoch - 2, step #000084/000117	Loss: 0.398504
Epoch - 2, step #000085/000117	Loss: 0.338864
Epoch - 2, step #000086/000117	Loss: 0.406237
Epoch - 2, step #000087/000117	Loss: 0.342286
Epoch - 2, step #000088/000117	Loss: 0.345736
Epoch - 2, step #000089/000117	Loss: 0.348982
Epoch - 2, step #000090/000117	Loss: 0.379227
Epoch - 2, step #000091/000117	Loss: 0.343538
Epoch - 2, step #000092/000117	Loss: 0.328045
Epoch - 2, step #000093/000117	Loss: 0.358412
Epoch - 2, step #000094/000117	Loss: 0.399171
Epoch - 2, step #000095/000117	Loss: 0.330358
Epoch - 2, step #000096/000117	Loss: 0.349419
Epoch - 2, step #000097/000117	Loss: 0.388551
Epoch - 2, step #000098/000117	Loss: 0.332588
Epoch - 2, step #000099/000117	Loss: 0.370231
Epoch - 2, step #000100/000117	Loss: 0.347037
Epoch - 2, step #000101/000117	Loss: 0.327048
Epoch - 2, step #000102/000117	Loss: 0.335632
Epoch - 2, step #000103/000117	Loss: 0.286619
Epoch - 2, step #000104/000117	Loss: 0.302837
Epoch - 2, step #000105/000117	Loss: 0.370904
Epoch - 2, step #000106/000117	Loss: 0.288724
Epoch - 2, step #000107/000117	Loss: 0.301030
Epoch - 2, step #000108/000117	Loss: 0.342672
Epoch - 2, step #000109/000117	Loss: 0.367868
Epoch - 2, step #000110/000117	Loss: 0.375526
Epoch - 2, step #000111/000117	Loss: 0.366335
Epoch - 2, step #000112/000117	Loss: 0.402459
Epoch - 2, step #000113/000117	Loss: 0.357068
Epoch - 2, step #000114/000117	Loss: 0.312233
Epoch - 2, step #000115/000117	Loss: 0.355175
Epoch - 2, step #000116/000117	Loss: 0.333748
E[2], train Loss: 0.371999, training Acc: 0.887, val loss: 0.283, val Acc: 0.917	 Time: 13.299 seconds
E[2], train Loss: 0.371999, training Acc: 0.887, val loss: 0.265, val Acc: 0.919	 Time: 10.431 seconds
Epoch - 3, step #000000/000117	Loss: 0.313410
Epoch - 3, step #000001/000117	Loss: 0.311391
Epoch - 3, step #000002/000117	Loss: 0.350642
Epoch - 3, step #000003/000117	Loss: 0.291950
Epoch - 3, step #000004/000117	Loss: 0.345411
Epoch - 3, step #000005/000117	Loss: 0.259214
Epoch - 3, step #000006/000117	Loss: 0.259107
Epoch - 3, step #000007/000117	Loss: 0.311838
Epoch - 3, step #000008/000117	Loss: 0.327034
Epoch - 3, step #000009/000117	Loss: 0.347669
Epoch - 3, step #000010/000117	Loss: 0.417433
Epoch - 3, step #000011/000117	Loss: 0.348282
Epoch - 3, step #000012/000117	Loss: 0.344049
Epoch - 3, step #000013/000117	Loss: 0.352692
Epoch - 3, step #000014/000117	Loss: 0.352321
Epoch - 3, step #000015/000117	Loss: 0.373279
Epoch - 3, step #000016/000117	Loss: 0.329574
Epoch - 3, step #000017/000117	Loss: 0.348503
Epoch - 3, step #000018/000117	Loss: 0.319603
Epoch - 3, step #000019/000117	Loss: 0.349924
Epoch - 3, step #000020/000117	Loss: 0.359519
Epoch - 3, step #000021/000117	Loss: 0.323633
Epoch - 3, step #000022/000117	Loss: 0.321522
Epoch - 3, step #000023/000117	Loss: 0.356839
Epoch - 3, step #000024/000117	Loss: 0.376276
Epoch - 3, step #000025/000117	Loss: 0.315427
Epoch - 3, step #000026/000117	Loss: 0.363481
Epoch - 3, step #000027/000117	Loss: 0.345847
Epoch - 3, step #000028/000117	Loss: 0.323500
Epoch - 3, step #000029/000117	Loss: 0.305136
Epoch - 3, step #000030/000117	Loss: 0.360116
Epoch - 3, step #000031/000117	Loss: 0.356976
Epoch - 3, step #000032/000117	Loss: 0.313552
Epoch - 3, step #000033/000117	Loss: 0.324682
Epoch - 3, step #000034/000117	Loss: 0.309376
Epoch - 3, step #000035/000117	Loss: 0.386818
Epoch - 3, step #000036/000117	Loss: 0.319303
Epoch - 3, step #000037/000117	Loss: 0.319891
Epoch - 3, step #000038/000117	Loss: 0.342120
Epoch - 3, step #000039/000117	Loss: 0.334812
Epoch - 3, step #000040/000117	Loss: 0.373872
Epoch - 3, step #000041/000117	Loss: 0.305258
Epoch - 3, step #000042/000117	Loss: 0.376954
Epoch - 3, step #000043/000117	Loss: 0.299535
Epoch - 3, step #000044/000117	Loss: 0.323553
Epoch - 3, step #000045/000117	Loss: 0.348573
Epoch - 3, step #000046/000117	Loss: 0.343406
Epoch - 3, step #000047/000117	Loss: 0.300588
Epoch - 3, step #000048/000117	Loss: 0.331991
Epoch - 3, step #000049/000117	Loss: 0.301318
Epoch - 3, step #000050/000117	Loss: 0.330768
Epoch - 3, step #000051/000117	Loss: 0.326527
Epoch - 3, step #000052/000117	Loss: 0.330970
Epoch - 3, step #000053/000117	Loss: 0.383678
Epoch - 3, step #000054/000117	Loss: 0.323608
Epoch - 3, step #000055/000117	Loss: 0.312031
Epoch - 3, step #000056/000117	Loss: 0.279777
Epoch - 3, step #000057/000117	Loss: 0.341893
Epoch - 3, step #000058/000117	Loss: 0.316345
Epoch - 3, step #000059/000117	Loss: 0.307136
Epoch - 3, step #000060/000117	Loss: 0.389544
Epoch - 3, step #000061/000117	Loss: 0.318503
Epoch - 3, step #000062/000117	Loss: 0.383790
Epoch - 3, step #000063/000117	Loss: 0.299601
Epoch - 3, step #000064/000117	Loss: 0.375731
Epoch - 3, step #000065/000117	Loss: 0.299103
Epoch - 3, step #000066/000117	Loss: 0.330928
Epoch - 3, step #000067/000117	Loss: 0.291561
Epoch - 3, step #000068/000117	Loss: 0.279506
Epoch - 3, step #000069/000117	Loss: 0.379827
Epoch - 3, step #000070/000117	Loss: 0.348957
Epoch - 3, step #000071/000117	Loss: 0.345368
Epoch - 3, step #000072/000117	Loss: 0.349622
Epoch - 3, step #000073/000117	Loss: 0.338853
Epoch - 3, step #000074/000117	Loss: 0.341275
Epoch - 3, step #000075/000117	Loss: 0.258491
Epoch - 3, step #000076/000117	Loss: 0.296693
Epoch - 3, step #000077/000117	Loss: 0.346516
Epoch - 3, step #000078/000117	Loss: 0.385285
Epoch - 3, step #000079/000117	Loss: 0.338478
Epoch - 3, step #000080/000117	Loss: 0.312214
Epoch - 3, step #000081/000117	Loss: 0.265569
Epoch - 3, step #000082/000117	Loss: 0.324067
Epoch - 3, step #000083/000117	Loss: 0.303725
Epoch - 3, step #000084/000117	Loss: 0.276117
Epoch - 3, step #000085/000117	Loss: 0.311037
Epoch - 3, step #000086/000117	Loss: 0.312758
Epoch - 3, step #000087/000117	Loss: 0.363249
Epoch - 3, step #000088/000117	Loss: 0.348505
Epoch - 3, step #000089/000117	Loss: 0.352152
Epoch - 3, step #000090/000117	Loss: 0.289175
Epoch - 3, step #000091/000117	Loss: 0.327855
Epoch - 3, step #000092/000117	Loss: 0.351672
Epoch - 3, step #000093/000117	Loss: 0.319927
Epoch - 3, step #000094/000117	Loss: 0.328182
Epoch - 3, step #000095/000117	Loss: 0.296764
Epoch - 3, step #000096/000117	Loss: 0.331507
Epoch - 3, step #000097/000117	Loss: 0.254528
Epoch - 3, step #000098/000117	Loss: 0.290213
Epoch - 3, step #000099/000117	Loss: 0.287980
Epoch - 3, step #000100/000117	Loss: 0.260981
Epoch - 3, step #000101/000117	Loss: 0.276570
Epoch - 3, step #000102/000117	Loss: 0.261146
Epoch - 3, step #000103/000117	Loss: 0.381489
Epoch - 3, step #000104/000117	Loss: 0.322132
Epoch - 3, step #000105/000117	Loss: 0.314001
Epoch - 3, step #000106/000117	Loss: 0.291925
Epoch - 3, step #000107/000117	Loss: 0.320490
Epoch - 3, step #000108/000117	Loss: 0.307185
Epoch - 3, step #000109/000117	Loss: 0.348947
Epoch - 3, step #000110/000117	Loss: 0.383354
Epoch - 3, step #000111/000117	Loss: 0.323491
Epoch - 3, step #000112/000117	Loss: 0.300061
Epoch - 3, step #000113/000117	Loss: 0.354495
Epoch - 3, step #000114/000117	Loss: 0.342046
Epoch - 3, step #000115/000117	Loss: 0.312675
Epoch - 3, step #000116/000117	Loss: 0.303288
E[3], train Loss: 0.327513, training Acc: 0.899, val loss: 0.253, val Acc: 0.927	 Time: 10.322 seconds
E[3], train Loss: 0.327513, training Acc: 0.899, val loss: 0.229, val Acc: 0.930	 Time: 10.444 seconds
Epoch - 4, step #000000/000117	Loss: 0.324315
Epoch - 4, step #000001/000117	Loss: 0.304448
Epoch - 4, step #000002/000117	Loss: 0.303409
Epoch - 4, step #000003/000117	Loss: 0.277443
Epoch - 4, step #000004/000117	Loss: 0.240417
Epoch - 4, step #000005/000117	Loss: 0.266675
Epoch - 4, step #000006/000117	Loss: 0.272008
Epoch - 4, step #000007/000117	Loss: 0.298269
Epoch - 4, step #000008/000117	Loss: 0.283709
Epoch - 4, step #000009/000117	Loss: 0.303412
Epoch - 4, step #000010/000117	Loss: 0.343558
Epoch - 4, step #000011/000117	Loss: 0.297598
Epoch - 4, step #000012/000117	Loss: 0.347172
Epoch - 4, step #000013/000117	Loss: 0.262704
Epoch - 4, step #000014/000117	Loss: 0.273074
Epoch - 4, step #000015/000117	Loss: 0.302339
Epoch - 4, step #000016/000117	Loss: 0.422953
Epoch - 4, step #000017/000117	Loss: 0.310334
Epoch - 4, step #000018/000117	Loss: 0.276465
Epoch - 4, step #000019/000117	Loss: 0.297706
Epoch - 4, step #000020/000117	Loss: 0.344107
Epoch - 4, step #000021/000117	Loss: 0.292359
Epoch - 4, step #000022/000117	Loss: 0.249333
Epoch - 4, step #000023/000117	Loss: 0.353527
Epoch - 4, step #000024/000117	Loss: 0.248330
Epoch - 4, step #000025/000117	Loss: 0.288875
Epoch - 4, step #000026/000117	Loss: 0.275751
Epoch - 4, step #000027/000117	Loss: 0.375792
Epoch - 4, step #000028/000117	Loss: 0.331062
Epoch - 4, step #000029/000117	Loss: 0.311709
Epoch - 4, step #000030/000117	Loss: 0.279392
Epoch - 4, step #000031/000117	Loss: 0.328371
Epoch - 4, step #000032/000117	Loss: 0.295627
Epoch - 4, step #000033/000117	Loss: 0.296804
Epoch - 4, step #000034/000117	Loss: 0.236512
Epoch - 4, step #000035/000117	Loss: 0.317927
Epoch - 4, step #000036/000117	Loss: 0.319328
Epoch - 4, step #000037/000117	Loss: 0.315014
Epoch - 4, step #000038/000117	Loss: 0.265393
Epoch - 4, step #000039/000117	Loss: 0.335180
Epoch - 4, step #000040/000117	Loss: 0.296791
Epoch - 4, step #000041/000117	Loss: 0.289989
Epoch - 4, step #000042/000117	Loss: 0.293821
Epoch - 4, step #000043/000117	Loss: 0.285740
Epoch - 4, step #000044/000117	Loss: 0.244618
Epoch - 4, step #000045/000117	Loss: 0.319653
Epoch - 4, step #000046/000117	Loss: 0.335062
Epoch - 4, step #000047/000117	Loss: 0.276926
Epoch - 4, step #000048/000117	Loss: 0.326969
Epoch - 4, step #000049/000117	Loss: 0.388976
Epoch - 4, step #000050/000117	Loss: 0.358755
Epoch - 4, step #000051/000117	Loss: 0.310521
Epoch - 4, step #000052/000117	Loss: 0.290613
Epoch - 4, step #000053/000117	Loss: 0.373561
Epoch - 4, step #000054/000117	Loss: 0.319225
Epoch - 4, step #000055/000117	Loss: 0.274655
Epoch - 4, step #000056/000117	Loss: 0.316734
Epoch - 4, step #000057/000117	Loss: 0.318434
Epoch - 4, step #000058/000117	Loss: 0.328043
Epoch - 4, step #000059/000117	Loss: 0.302398
Epoch - 4, step #000060/000117	Loss: 0.321766
Epoch - 4, step #000061/000117	Loss: 0.271860
Epoch - 4, step #000062/000117	Loss: 0.288611
Epoch - 4, step #000063/000117	Loss: 0.339394
Epoch - 4, step #000064/000117	Loss: 0.304071
Epoch - 4, step #000065/000117	Loss: 0.305780
Epoch - 4, step #000066/000117	Loss: 0.298270
Epoch - 4, step #000067/000117	Loss: 0.319812
Epoch - 4, step #000068/000117	Loss: 0.325363
Epoch - 4, step #000069/000117	Loss: 0.299534
Epoch - 4, step #000070/000117	Loss: 0.299353
Epoch - 4, step #000071/000117	Loss: 0.324059
Epoch - 4, step #000072/000117	Loss: 0.261430
Epoch - 4, step #000073/000117	Loss: 0.211706
Epoch - 4, step #000074/000117	Loss: 0.250692
Epoch - 4, step #000075/000117	Loss: 0.263530
Epoch - 4, step #000076/000117	Loss: 0.266605
Epoch - 4, step #000077/000117	Loss: 0.343943
Epoch - 4, step #000078/000117	Loss: 0.340704
Epoch - 4, step #000079/000117	Loss: 0.307130
Epoch - 4, step #000080/000117	Loss: 0.291456
Epoch - 4, step #000081/000117	Loss: 0.288907
Epoch - 4, step #000082/000117	Loss: 0.364348
Epoch - 4, step #000083/000117	Loss: 0.277985
Epoch - 4, step #000084/000117	Loss: 0.278032
Epoch - 4, step #000085/000117	Loss: 0.216905
Epoch - 4, step #000086/000117	Loss: 0.293986
Epoch - 4, step #000087/000117	Loss: 0.275911
Epoch - 4, step #000088/000117	Loss: 0.343021
Epoch - 4, step #000089/000117	Loss: 0.337616
Epoch - 4, step #000090/000117	Loss: 0.242484
Epoch - 4, step #000091/000117	Loss: 0.287324
Epoch - 4, step #000092/000117	Loss: 0.302800
Epoch - 4, step #000093/000117	Loss: 0.284225
Epoch - 4, step #000094/000117	Loss: 0.262258
Epoch - 4, step #000095/000117	Loss: 0.244811
Epoch - 4, step #000096/000117	Loss: 0.325662
Epoch - 4, step #000097/000117	Loss: 0.302484
Epoch - 4, step #000098/000117	Loss: 0.340469
Epoch - 4, step #000099/000117	Loss: 0.265603
Epoch - 4, step #000100/000117	Loss: 0.330787
Epoch - 4, step #000101/000117	Loss: 0.233089
Epoch - 4, step #000102/000117	Loss: 0.294294
Epoch - 4, step #000103/000117	Loss: 0.273864
Epoch - 4, step #000104/000117	Loss: 0.295424
Epoch - 4, step #000105/000117	Loss: 0.234286
Epoch - 4, step #000106/000117	Loss: 0.380185
Epoch - 4, step #000107/000117	Loss: 0.239950
Epoch - 4, step #000108/000117	Loss: 0.269107
Epoch - 4, step #000109/000117	Loss: 0.333437
Epoch - 4, step #000110/000117	Loss: 0.317006
Epoch - 4, step #000111/000117	Loss: 0.294695
Epoch - 4, step #000112/000117	Loss: 0.253796
Epoch - 4, step #000113/000117	Loss: 0.293892
Epoch - 4, step #000114/000117	Loss: 0.278006
Epoch - 4, step #000115/000117	Loss: 0.223460
Epoch - 4, step #000116/000117	Loss: 0.248347
E[4], train Loss: 0.298149, training Acc: 0.908, val loss: 0.238, val Acc: 0.930	 Time: 10.639 seconds
E[4], train Loss: 0.298149, training Acc: 0.908, val loss: 0.200, val Acc: 0.936	 Time: 10.448 seconds
Epoch - 5, step #000000/000117	Loss: 0.362598
Epoch - 5, step #000001/000117	Loss: 0.301767
Epoch - 5, step #000002/000117	Loss: 0.229227
Epoch - 5, step #000003/000117	Loss: 0.268818
Epoch - 5, step #000004/000117	Loss: 0.319526
Epoch - 5, step #000005/000117	Loss: 0.272492
Epoch - 5, step #000006/000117	Loss: 0.276289
Epoch - 5, step #000007/000117	Loss: 0.220022
Epoch - 5, step #000008/000117	Loss: 0.313262
Epoch - 5, step #000009/000117	Loss: 0.257600
Epoch - 5, step #000010/000117	Loss: 0.268523
Epoch - 5, step #000011/000117	Loss: 0.285620
Epoch - 5, step #000012/000117	Loss: 0.288408
Epoch - 5, step #000013/000117	Loss: 0.244489
Epoch - 5, step #000014/000117	Loss: 0.257460
Epoch - 5, step #000015/000117	Loss: 0.269149
Epoch - 5, step #000016/000117	Loss: 0.281807
Epoch - 5, step #000017/000117	Loss: 0.277738
Epoch - 5, step #000018/000117	Loss: 0.236383
Epoch - 5, step #000019/000117	Loss: 0.309404
Epoch - 5, step #000020/000117	Loss: 0.302073
Epoch - 5, step #000021/000117	Loss: 0.210852
Epoch - 5, step #000022/000117	Loss: 0.299321
Epoch - 5, step #000023/000117	Loss: 0.286013
Epoch - 5, step #000024/000117	Loss: 0.307675
Epoch - 5, step #000025/000117	Loss: 0.273316
Epoch - 5, step #000026/000117	Loss: 0.277420
Epoch - 5, step #000027/000117	Loss: 0.282141
Epoch - 5, step #000028/000117	Loss: 0.237471
Epoch - 5, step #000029/000117	Loss: 0.309876
Epoch - 5, step #000030/000117	Loss: 0.263422
Epoch - 5, step #000031/000117	Loss: 0.242352
Epoch - 5, step #000032/000117	Loss: 0.303629
Epoch - 5, step #000033/000117	Loss: 0.268990
Epoch - 5, step #000034/000117	Loss: 0.205882
Epoch - 5, step #000035/000117	Loss: 0.211218
Epoch - 5, step #000036/000117	Loss: 0.348301
Epoch - 5, step #000037/000117	Loss: 0.300088
Epoch - 5, step #000038/000117	Loss: 0.228123
Epoch - 5, step #000039/000117	Loss: 0.238677
Epoch - 5, step #000040/000117	Loss: 0.272422
Epoch - 5, step #000041/000117	Loss: 0.287303
Epoch - 5, step #000042/000117	Loss: 0.300610
Epoch - 5, step #000043/000117	Loss: 0.279061
Epoch - 5, step #000044/000117	Loss: 0.212380
Epoch - 5, step #000045/000117	Loss: 0.239167
Epoch - 5, step #000046/000117	Loss: 0.271118
Epoch - 5, step #000047/000117	Loss: 0.254413
Epoch - 5, step #000048/000117	Loss: 0.294163
Epoch - 5, step #000049/000117	Loss: 0.231717
Epoch - 5, step #000050/000117	Loss: 0.360334
Epoch - 5, step #000051/000117	Loss: 0.249870
Epoch - 5, step #000052/000117	Loss: 0.272906
Epoch - 5, step #000053/000117	Loss: 0.328929
Epoch - 5, step #000054/000117	Loss: 0.255069
Epoch - 5, step #000055/000117	Loss: 0.247989
Epoch - 5, step #000056/000117	Loss: 0.216923
Epoch - 5, step #000057/000117	Loss: 0.305402
Epoch - 5, step #000058/000117	Loss: 0.209380
Epoch - 5, step #000059/000117	Loss: 0.282490
Epoch - 5, step #000060/000117	Loss: 0.315236
Epoch - 5, step #000061/000117	Loss: 0.257268
Epoch - 5, step #000062/000117	Loss: 0.251170
Epoch - 5, step #000063/000117	Loss: 0.283814
Epoch - 5, step #000064/000117	Loss: 0.318696
Epoch - 5, step #000065/000117	Loss: 0.290799
Epoch - 5, step #000066/000117	Loss: 0.212654
Epoch - 5, step #000067/000117	Loss: 0.268805
Epoch - 5, step #000068/000117	Loss: 0.271336
Epoch - 5, step #000069/000117	Loss: 0.286214
Epoch - 5, step #000070/000117	Loss: 0.299478
Epoch - 5, step #000071/000117	Loss: 0.289504
Epoch - 5, step #000072/000117	Loss: 0.307810
Epoch - 5, step #000073/000117	Loss: 0.302288
Epoch - 5, step #000074/000117	Loss: 0.272234
Epoch - 5, step #000075/000117	Loss: 0.248026
Epoch - 5, step #000076/000117	Loss: 0.255986
Epoch - 5, step #000077/000117	Loss: 0.247830
Epoch - 5, step #000078/000117	Loss: 0.288667
Epoch - 5, step #000079/000117	Loss: 0.291013
Epoch - 5, step #000080/000117	Loss: 0.283639
Epoch - 5, step #000081/000117	Loss: 0.200875
Epoch - 5, step #000082/000117	Loss: 0.292983
Epoch - 5, step #000083/000117	Loss: 0.330443
Epoch - 5, step #000084/000117	Loss: 0.246676
Epoch - 5, step #000085/000117	Loss: 0.254673
Epoch - 5, step #000086/000117	Loss: 0.231332
Epoch - 5, step #000087/000117	Loss: 0.278664
Epoch - 5, step #000088/000117	Loss: 0.249021
Epoch - 5, step #000089/000117	Loss: 0.245765
Epoch - 5, step #000090/000117	Loss: 0.251988
Epoch - 5, step #000091/000117	Loss: 0.210341
Epoch - 5, step #000092/000117	Loss: 0.280292
Epoch - 5, step #000093/000117	Loss: 0.282750
Epoch - 5, step #000094/000117	Loss: 0.230651
Epoch - 5, step #000095/000117	Loss: 0.243935
Epoch - 5, step #000096/000117	Loss: 0.283139
Epoch - 5, step #000097/000117	Loss: 0.244010
Epoch - 5, step #000098/000117	Loss: 0.204954
Epoch - 5, step #000099/000117	Loss: 0.266824
Epoch - 5, step #000100/000117	Loss: 0.269504
Epoch - 5, step #000101/000117	Loss: 0.251715
Epoch - 5, step #000102/000117	Loss: 0.242853
Epoch - 5, step #000103/000117	Loss: 0.306833
Epoch - 5, step #000104/000117	Loss: 0.262741
Epoch - 5, step #000105/000117	Loss: 0.299258
Epoch - 5, step #000106/000117	Loss: 0.256940
Epoch - 5, step #000107/000117	Loss: 0.297115
Epoch - 5, step #000108/000117	Loss: 0.313835
Epoch - 5, step #000109/000117	Loss: 0.288131
Epoch - 5, step #000110/000117	Loss: 0.248029
Epoch - 5, step #000111/000117	Loss: 0.286244
Epoch - 5, step #000112/000117	Loss: 0.241024
Epoch - 5, step #000113/000117	Loss: 0.299182
Epoch - 5, step #000114/000117	Loss: 0.266484
Epoch - 5, step #000115/000117	Loss: 0.262558
Epoch - 5, step #000116/000117	Loss: 0.252199
E[5], train Loss: 0.270303, training Acc: 0.917, val loss: 0.226, val Acc: 0.935	 Time: 10.324 seconds
E[5], train Loss: 0.270303, training Acc: 0.917, val loss: 0.188, val Acc: 0.940	 Time: 6.134 seconds
Epoch - 6, step #000000/000117	Loss: 0.252638
Epoch - 6, step #000001/000117	Loss: 0.234735
Epoch - 6, step #000002/000117	Loss: 0.182126
Epoch - 6, step #000003/000117	Loss: 0.238156
Epoch - 6, step #000004/000117	Loss: 0.233091
Epoch - 6, step #000005/000117	Loss: 0.222360
Epoch - 6, step #000006/000117	Loss: 0.257714
Epoch - 6, step #000007/000117	Loss: 0.309396
Epoch - 6, step #000008/000117	Loss: 0.273584
Epoch - 6, step #000009/000117	Loss: 0.271856
Epoch - 6, step #000010/000117	Loss: 0.284042
Epoch - 6, step #000011/000117	Loss: 0.285051
Epoch - 6, step #000012/000117	Loss: 0.266619
Epoch - 6, step #000013/000117	Loss: 0.326634
Epoch - 6, step #000014/000117	Loss: 0.291807
Epoch - 6, step #000015/000117	Loss: 0.275134
Epoch - 6, step #000016/000117	Loss: 0.284440
Epoch - 6, step #000017/000117	Loss: 0.242077
Epoch - 6, step #000018/000117	Loss: 0.216887
Epoch - 6, step #000019/000117	Loss: 0.253861
Epoch - 6, step #000020/000117	Loss: 0.207641
Epoch - 6, step #000021/000117	Loss: 0.237785
Epoch - 6, step #000022/000117	Loss: 0.252520
Epoch - 6, step #000023/000117	Loss: 0.236722
Epoch - 6, step #000024/000117	Loss: 0.280699
Epoch - 6, step #000025/000117	Loss: 0.298680
Epoch - 6, step #000026/000117	Loss: 0.265424
Epoch - 6, step #000027/000117	Loss: 0.234375
Epoch - 6, step #000028/000117	Loss: 0.280797
Epoch - 6, step #000029/000117	Loss: 0.311989
Epoch - 6, step #000030/000117	Loss: 0.302935
Epoch - 6, step #000031/000117	Loss: 0.253392
Epoch - 6, step #000032/000117	Loss: 0.252397
Epoch - 6, step #000033/000117	Loss: 0.227181
Epoch - 6, step #000034/000117	Loss: 0.221386
Epoch - 6, step #000035/000117	Loss: 0.253167
Epoch - 6, step #000036/000117	Loss: 0.279029
Epoch - 6, step #000037/000117	Loss: 0.251990
Epoch - 6, step #000038/000117	Loss: 0.267123
Epoch - 6, step #000039/000117	Loss: 0.239335
Epoch - 6, step #000040/000117	Loss: 0.247498
Epoch - 6, step #000041/000117	Loss: 0.270099
Epoch - 6, step #000042/000117	Loss: 0.230525
Epoch - 6, step #000043/000117	Loss: 0.331191
Epoch - 6, step #000044/000117	Loss: 0.270496
Epoch - 6, step #000045/000117	Loss: 0.263249
Epoch - 6, step #000046/000117	Loss: 0.276203
Epoch - 6, step #000047/000117	Loss: 0.244182
Epoch - 6, step #000048/000117	Loss: 0.279521
Epoch - 6, step #000049/000117	Loss: 0.198558
Epoch - 6, step #000050/000117	Loss: 0.289167
Epoch - 6, step #000051/000117	Loss: 0.240248
Epoch - 6, step #000052/000117	Loss: 0.277886
Epoch - 6, step #000053/000117	Loss: 0.216042
Epoch - 6, step #000054/000117	Loss: 0.243991
Epoch - 6, step #000055/000117	Loss: 0.203040
Epoch - 6, step #000056/000117	Loss: 0.243666
Epoch - 6, step #000057/000117	Loss: 0.194355
Epoch - 6, step #000058/000117	Loss: 0.237192
Epoch - 6, step #000059/000117	Loss: 0.250215
Epoch - 6, step #000060/000117	Loss: 0.301856
Epoch - 6, step #000061/000117	Loss: 0.284698
Epoch - 6, step #000062/000117	Loss: 0.330009
Epoch - 6, step #000063/000117	Loss: 0.214943
Epoch - 6, step #000064/000117	Loss: 0.257356
Epoch - 6, step #000065/000117	Loss: 0.235380
Epoch - 6, step #000066/000117	Loss: 0.247226
Epoch - 6, step #000067/000117	Loss: 0.222100
Epoch - 6, step #000068/000117	Loss: 0.242996
Epoch - 6, step #000069/000117	Loss: 0.223059
Epoch - 6, step #000070/000117	Loss: 0.338915
Epoch - 6, step #000071/000117	Loss: 0.222883
Epoch - 6, step #000072/000117	Loss: 0.299826
Epoch - 6, step #000073/000117	Loss: 0.249048
Epoch - 6, step #000074/000117	Loss: 0.299347
Epoch - 6, step #000075/000117	Loss: 0.213648
Epoch - 6, step #000076/000117	Loss: 0.271826
Epoch - 6, step #000077/000117	Loss: 0.256497
Epoch - 6, step #000078/000117	Loss: 0.257594
Epoch - 6, step #000079/000117	Loss: 0.258562
Epoch - 6, step #000080/000117	Loss: 0.244907
Epoch - 6, step #000081/000117	Loss: 0.271562
Epoch - 6, step #000082/000117	Loss: 0.214331
Epoch - 6, step #000083/000117	Loss: 0.226169
Epoch - 6, step #000084/000117	Loss: 0.245378
Epoch - 6, step #000085/000117	Loss: 0.170342
Epoch - 6, step #000086/000117	Loss: 0.218430
Epoch - 6, step #000087/000117	Loss: 0.202230
Epoch - 6, step #000088/000117	Loss: 0.233611
Epoch - 6, step #000089/000117	Loss: 0.266335
Epoch - 6, step #000090/000117	Loss: 0.220382
Epoch - 6, step #000091/000117	Loss: 0.245643
Epoch - 6, step #000092/000117	Loss: 0.202376
Epoch - 6, step #000093/000117	Loss: 0.240756
Epoch - 6, step #000094/000117	Loss: 0.230645
Epoch - 6, step #000095/000117	Loss: 0.257279
Epoch - 6, step #000096/000117	Loss: 0.237228
Epoch - 6, step #000097/000117	Loss: 0.245210
Epoch - 6, step #000098/000117	Loss: 0.251543
Epoch - 6, step #000099/000117	Loss: 0.178321
Epoch - 6, step #000100/000117	Loss: 0.241248
Epoch - 6, step #000101/000117	Loss: 0.285071
Epoch - 6, step #000102/000117	Loss: 0.233181
Epoch - 6, step #000103/000117	Loss: 0.261535
Epoch - 6, step #000104/000117	Loss: 0.299942
Epoch - 6, step #000105/000117	Loss: 0.242608
Epoch - 6, step #000106/000117	Loss: 0.188655
Epoch - 6, step #000107/000117	Loss: 0.256114
Epoch - 6, step #000108/000117	Loss: 0.238550
Epoch - 6, step #000109/000117	Loss: 0.215955
Epoch - 6, step #000110/000117	Loss: 0.215115
Epoch - 6, step #000111/000117	Loss: 0.233636
Epoch - 6, step #000112/000117	Loss: 0.324712
Epoch - 6, step #000113/000117	Loss: 0.249520
Epoch - 6, step #000114/000117	Loss: 0.232508
Epoch - 6, step #000115/000117	Loss: 0.222538
Epoch - 6, step #000116/000117	Loss: 0.278326
E[6], train Loss: 0.251400, training Acc: 0.923, val loss: 0.213, val Acc: 0.938	 Time: 6.625 seconds
E[6], train Loss: 0.251400, training Acc: 0.923, val loss: 0.177, val Acc: 0.944	 Time: 10.426 seconds
Epoch - 7, step #000000/000117	Loss: 0.244912
Epoch - 7, step #000001/000117	Loss: 0.197898
Epoch - 7, step #000002/000117	Loss: 0.209773
Epoch - 7, step #000003/000117	Loss: 0.198472
Epoch - 7, step #000004/000117	Loss: 0.215188
Epoch - 7, step #000005/000117	Loss: 0.169236
Epoch - 7, step #000006/000117	Loss: 0.272651
Epoch - 7, step #000007/000117	Loss: 0.264425
Epoch - 7, step #000008/000117	Loss: 0.213286
Epoch - 7, step #000009/000117	Loss: 0.235584
Epoch - 7, step #000010/000117	Loss: 0.215149
Epoch - 7, step #000011/000117	Loss: 0.259920
Epoch - 7, step #000012/000117	Loss: 0.211213
Epoch - 7, step #000013/000117	Loss: 0.268711
Epoch - 7, step #000014/000117	Loss: 0.247770
Epoch - 7, step #000015/000117	Loss: 0.178384
Epoch - 7, step #000016/000117	Loss: 0.214213
Epoch - 7, step #000017/000117	Loss: 0.225707
Epoch - 7, step #000018/000117	Loss: 0.213144
Epoch - 7, step #000019/000117	Loss: 0.202886
Epoch - 7, step #000020/000117	Loss: 0.261034
Epoch - 7, step #000021/000117	Loss: 0.229522
Epoch - 7, step #000022/000117	Loss: 0.216256
Epoch - 7, step #000023/000117	Loss: 0.244782
Epoch - 7, step #000024/000117	Loss: 0.247857
Epoch - 7, step #000025/000117	Loss: 0.248247
Epoch - 7, step #000026/000117	Loss: 0.199754
Epoch - 7, step #000027/000117	Loss: 0.241835
Epoch - 7, step #000028/000117	Loss: 0.281211
Epoch - 7, step #000029/000117	Loss: 0.264838
Epoch - 7, step #000030/000117	Loss: 0.267422
Epoch - 7, step #000031/000117	Loss: 0.218320
Epoch - 7, step #000032/000117	Loss: 0.220676
Epoch - 7, step #000033/000117	Loss: 0.249288
Epoch - 7, step #000034/000117	Loss: 0.218415
Epoch - 7, step #000035/000117	Loss: 0.251786
Epoch - 7, step #000036/000117	Loss: 0.211385
Epoch - 7, step #000037/000117	Loss: 0.241387
Epoch - 7, step #000038/000117	Loss: 0.275489
Epoch - 7, step #000039/000117	Loss: 0.238805
Epoch - 7, step #000040/000117	Loss: 0.289625
Epoch - 7, step #000041/000117	Loss: 0.236671
Epoch - 7, step #000042/000117	Loss: 0.208808
Epoch - 7, step #000043/000117	Loss: 0.233374
Epoch - 7, step #000044/000117	Loss: 0.281921
Epoch - 7, step #000045/000117	Loss: 0.332917
Epoch - 7, step #000046/000117	Loss: 0.279399
Epoch - 7, step #000047/000117	Loss: 0.187579
Epoch - 7, step #000048/000117	Loss: 0.218785
Epoch - 7, step #000049/000117	Loss: 0.239762
Epoch - 7, step #000050/000117	Loss: 0.255734
Epoch - 7, step #000051/000117	Loss: 0.234198
Epoch - 7, step #000052/000117	Loss: 0.266193
Epoch - 7, step #000053/000117	Loss: 0.244313
Epoch - 7, step #000054/000117	Loss: 0.210043
Epoch - 7, step #000055/000117	Loss: 0.196878
Epoch - 7, step #000056/000117	Loss: 0.193378
Epoch - 7, step #000057/000117	Loss: 0.226488
Epoch - 7, step #000058/000117	Loss: 0.274046
Epoch - 7, step #000059/000117	Loss: 0.217866
Epoch - 7, step #000060/000117	Loss: 0.270412
Epoch - 7, step #000061/000117	Loss: 0.263739
Epoch - 7, step #000062/000117	Loss: 0.256259
Epoch - 7, step #000063/000117	Loss: 0.242573
Epoch - 7, step #000064/000117	Loss: 0.286227
Epoch - 7, step #000065/000117	Loss: 0.219061
Epoch - 7, step #000066/000117	Loss: 0.274721
Epoch - 7, step #000067/000117	Loss: 0.329997
Epoch - 7, step #000068/000117	Loss: 0.281168
Epoch - 7, step #000069/000117	Loss: 0.220660
Epoch - 7, step #000070/000117	Loss: 0.194377
Epoch - 7, step #000071/000117	Loss: 0.300092
Epoch - 7, step #000072/000117	Loss: 0.232225
Epoch - 7, step #000073/000117	Loss: 0.301705
Epoch - 7, step #000074/000117	Loss: 0.241427
Epoch - 7, step #000075/000117	Loss: 0.185258
Epoch - 7, step #000076/000117	Loss: 0.290500
Epoch - 7, step #000077/000117	Loss: 0.263197
Epoch - 7, step #000078/000117	Loss: 0.240036
Epoch - 7, step #000079/000117	Loss: 0.173909
Epoch - 7, step #000080/000117	Loss: 0.171677
Epoch - 7, step #000081/000117	Loss: 0.275963
Epoch - 7, step #000082/000117	Loss: 0.238358
Epoch - 7, step #000083/000117	Loss: 0.261072
Epoch - 7, step #000084/000117	Loss: 0.203342
Epoch - 7, step #000085/000117	Loss: 0.251659
Epoch - 7, step #000086/000117	Loss: 0.267188
Epoch - 7, step #000087/000117	Loss: 0.249459
Epoch - 7, step #000088/000117	Loss: 0.299822
Epoch - 7, step #000089/000117	Loss: 0.181534
Epoch - 7, step #000090/000117	Loss: 0.253589
Epoch - 7, step #000091/000117	Loss: 0.222994
Epoch - 7, step #000092/000117	Loss: 0.272571
Epoch - 7, step #000093/000117	Loss: 0.199928
Epoch - 7, step #000094/000117	Loss: 0.282336
Epoch - 7, step #000095/000117	Loss: 0.233911
Epoch - 7, step #000096/000117	Loss: 0.203748
Epoch - 7, step #000097/000117	Loss: 0.232042
Epoch - 7, step #000098/000117	Loss: 0.236178
Epoch - 7, step #000099/000117	Loss: 0.173364
Epoch - 7, step #000100/000117	Loss: 0.269639
Epoch - 7, step #000101/000117	Loss: 0.195862
Epoch - 7, step #000102/000117	Loss: 0.284878
Epoch - 7, step #000103/000117	Loss: 0.256445
Epoch - 7, step #000104/000117	Loss: 0.227352
Epoch - 7, step #000105/000117	Loss: 0.247368
Epoch - 7, step #000106/000117	Loss: 0.309707
Epoch - 7, step #000107/000117	Loss: 0.183127
Epoch - 7, step #000108/000117	Loss: 0.211126
Epoch - 7, step #000109/000117	Loss: 0.255573
Epoch - 7, step #000110/000117	Loss: 0.258876
Epoch - 7, step #000111/000117	Loss: 0.200304
Epoch - 7, step #000112/000117	Loss: 0.170366
Epoch - 7, step #000113/000117	Loss: 0.197780
Epoch - 7, step #000114/000117	Loss: 0.224577
Epoch - 7, step #000115/000117	Loss: 0.238252
Epoch - 7, step #000116/000117	Loss: 0.194403
E[7], train Loss: 0.237767, training Acc: 0.927, val loss: 0.212, val Acc: 0.939	 Time: 10.017 seconds
E[7], train Loss: 0.237767, training Acc: 0.927, val loss: 0.156, val Acc: 0.950	 Time: 10.424 seconds
Epoch - 8, step #000000/000117	Loss: 0.187899
Epoch - 8, step #000001/000117	Loss: 0.274659
Epoch - 8, step #000002/000117	Loss: 0.175643
Epoch - 8, step #000003/000117	Loss: 0.244051
Epoch - 8, step #000004/000117	Loss: 0.246580
Epoch - 8, step #000005/000117	Loss: 0.167825
Epoch - 8, step #000006/000117	Loss: 0.175562
Epoch - 8, step #000007/000117	Loss: 0.236007
Epoch - 8, step #000008/000117	Loss: 0.231509
Epoch - 8, step #000009/000117	Loss: 0.263990
Epoch - 8, step #000010/000117	Loss: 0.255153
Epoch - 8, step #000011/000117	Loss: 0.246019
Epoch - 8, step #000012/000117	Loss: 0.203812
Epoch - 8, step #000013/000117	Loss: 0.179441
Epoch - 8, step #000014/000117	Loss: 0.202605
Epoch - 8, step #000015/000117	Loss: 0.236039
Epoch - 8, step #000016/000117	Loss: 0.255275
Epoch - 8, step #000017/000117	Loss: 0.241800
Epoch - 8, step #000018/000117	Loss: 0.226315
Epoch - 8, step #000019/000117	Loss: 0.251522
Epoch - 8, step #000020/000117	Loss: 0.192520
Epoch - 8, step #000021/000117	Loss: 0.178794
Epoch - 8, step #000022/000117	Loss: 0.264852
Epoch - 8, step #000023/000117	Loss: 0.230065
Epoch - 8, step #000024/000117	Loss: 0.194449
Epoch - 8, step #000025/000117	Loss: 0.224588
Epoch - 8, step #000026/000117	Loss: 0.266007
Epoch - 8, step #000027/000117	Loss: 0.213225
Epoch - 8, step #000028/000117	Loss: 0.263250
Epoch - 8, step #000029/000117	Loss: 0.143938
Epoch - 8, step #000030/000117	Loss: 0.242963
Epoch - 8, step #000031/000117	Loss: 0.187987
Epoch - 8, step #000032/000117	Loss: 0.215195
Epoch - 8, step #000033/000117	Loss: 0.170456
Epoch - 8, step #000034/000117	Loss: 0.237759
Epoch - 8, step #000035/000117	Loss: 0.215680
Epoch - 8, step #000036/000117	Loss: 0.241139
Epoch - 8, step #000037/000117	Loss: 0.229529
Epoch - 8, step #000038/000117	Loss: 0.187087
Epoch - 8, step #000039/000117	Loss: 0.210453
Epoch - 8, step #000040/000117	Loss: 0.303167
Epoch - 8, step #000041/000117	Loss: 0.212461
Epoch - 8, step #000042/000117	Loss: 0.255218
Epoch - 8, step #000043/000117	Loss: 0.221295
Epoch - 8, step #000044/000117	Loss: 0.219699
Epoch - 8, step #000045/000117	Loss: 0.212219
Epoch - 8, step #000046/000117	Loss: 0.226645
Epoch - 8, step #000047/000117	Loss: 0.271877
Epoch - 8, step #000048/000117	Loss: 0.193576
Epoch - 8, step #000049/000117	Loss: 0.174953
Epoch - 8, step #000050/000117	Loss: 0.242318
Epoch - 8, step #000051/000117	Loss: 0.169423
Epoch - 8, step #000052/000117	Loss: 0.247994
Epoch - 8, step #000053/000117	Loss: 0.245712
Epoch - 8, step #000054/000117	Loss: 0.191381
Epoch - 8, step #000055/000117	Loss: 0.216018
Epoch - 8, step #000056/000117	Loss: 0.295722
Epoch - 8, step #000057/000117	Loss: 0.263271
Epoch - 8, step #000058/000117	Loss: 0.211951
Epoch - 8, step #000059/000117	Loss: 0.217128
Epoch - 8, step #000060/000117	Loss: 0.232343
Epoch - 8, step #000061/000117	Loss: 0.230455
Epoch - 8, step #000062/000117	Loss: 0.185869
Epoch - 8, step #000063/000117	Loss: 0.229476
Epoch - 8, step #000064/000117	Loss: 0.199282
Epoch - 8, step #000065/000117	Loss: 0.329830
Epoch - 8, step #000066/000117	Loss: 0.224902
Epoch - 8, step #000067/000117	Loss: 0.198088
Epoch - 8, step #000068/000117	Loss: 0.213870
Epoch - 8, step #000069/000117	Loss: 0.193312
Epoch - 8, step #000070/000117	Loss: 0.235080
Epoch - 8, step #000071/000117	Loss: 0.211882
Epoch - 8, step #000072/000117	Loss: 0.235619
Epoch - 8, step #000073/000117	Loss: 0.252359
Epoch - 8, step #000074/000117	Loss: 0.226062
Epoch - 8, step #000075/000117	Loss: 0.149099
Epoch - 8, step #000076/000117	Loss: 0.238839
Epoch - 8, step #000077/000117	Loss: 0.222005
Epoch - 8, step #000078/000117	Loss: 0.219161
Epoch - 8, step #000079/000117	Loss: 0.207583
Epoch - 8, step #000080/000117	Loss: 0.166958
Epoch - 8, step #000081/000117	Loss: 0.223742
Epoch - 8, step #000082/000117	Loss: 0.260281
Epoch - 8, step #000083/000117	Loss: 0.229918
Epoch - 8, step #000084/000117	Loss: 0.215751
Epoch - 8, step #000085/000117	Loss: 0.262210
Epoch - 8, step #000086/000117	Loss: 0.177578
Epoch - 8, step #000087/000117	Loss: 0.263350
Epoch - 8, step #000088/000117	Loss: 0.249348
Epoch - 8, step #000089/000117	Loss: 0.257473
Epoch - 8, step #000090/000117	Loss: 0.179455
Epoch - 8, step #000091/000117	Loss: 0.195235
Epoch - 8, step #000092/000117	Loss: 0.190348
Epoch - 8, step #000093/000117	Loss: 0.199240
Epoch - 8, step #000094/000117	Loss: 0.177686
Epoch - 8, step #000095/000117	Loss: 0.195756
Epoch - 8, step #000096/000117	Loss: 0.168342
Epoch - 8, step #000097/000117	Loss: 0.209563
Epoch - 8, step #000098/000117	Loss: 0.210457
Epoch - 8, step #000099/000117	Loss: 0.267111
Epoch - 8, step #000100/000117	Loss: 0.191749
Epoch - 8, step #000101/000117	Loss: 0.185510
Epoch - 8, step #000102/000117	Loss: 0.215982
Epoch - 8, step #000103/000117	Loss: 0.206185
Epoch - 8, step #000104/000117	Loss: 0.151226
Epoch - 8, step #000105/000117	Loss: 0.230442
Epoch - 8, step #000106/000117	Loss: 0.179075
Epoch - 8, step #000107/000117	Loss: 0.253848
Epoch - 8, step #000108/000117	Loss: 0.184299
Epoch - 8, step #000109/000117	Loss: 0.192154
Epoch - 8, step #000110/000117	Loss: 0.197049
Epoch - 8, step #000111/000117	Loss: 0.256820
Epoch - 8, step #000112/000117	Loss: 0.229060
Epoch - 8, step #000113/000117	Loss: 0.184480
Epoch - 8, step #000114/000117	Loss: 0.176055
Epoch - 8, step #000115/000117	Loss: 0.195534
Epoch - 8, step #000116/000117	Loss: 0.285845
E[8], train Loss: 0.219264, training Acc: 0.933, val loss: 0.189, val Acc: 0.943	 Time: 10.287 seconds
E[8], train Loss: 0.219264, training Acc: 0.933, val loss: 0.151, val Acc: 0.953	 Time: 10.425 seconds
Epoch - 9, step #000000/000117	Loss: 0.199633
Epoch - 9, step #000001/000117	Loss: 0.208892
Epoch - 9, step #000002/000117	Loss: 0.171126
Epoch - 9, step #000003/000117	Loss: 0.214185
Epoch - 9, step #000004/000117	Loss: 0.214580
Epoch - 9, step #000005/000117	Loss: 0.223783
Epoch - 9, step #000006/000117	Loss: 0.153167
Epoch - 9, step #000007/000117	Loss: 0.160504
Epoch - 9, step #000008/000117	Loss: 0.187742
Epoch - 9, step #000009/000117	Loss: 0.197356
Epoch - 9, step #000010/000117	Loss: 0.240723
Epoch - 9, step #000011/000117	Loss: 0.163705
Epoch - 9, step #000012/000117	Loss: 0.199428
Epoch - 9, step #000013/000117	Loss: 0.233962
Epoch - 9, step #000014/000117	Loss: 0.185645
Epoch - 9, step #000015/000117	Loss: 0.232081
Epoch - 9, step #000016/000117	Loss: 0.199439
Epoch - 9, step #000017/000117	Loss: 0.188789
Epoch - 9, step #000018/000117	Loss: 0.193545
Epoch - 9, step #000019/000117	Loss: 0.235770
Epoch - 9, step #000020/000117	Loss: 0.161908
Epoch - 9, step #000021/000117	Loss: 0.232929
Epoch - 9, step #000022/000117	Loss: 0.200113
Epoch - 9, step #000023/000117	Loss: 0.202567
Epoch - 9, step #000024/000117	Loss: 0.252498
Epoch - 9, step #000025/000117	Loss: 0.183804
Epoch - 9, step #000026/000117	Loss: 0.276596
Epoch - 9, step #000027/000117	Loss: 0.210745
Epoch - 9, step #000028/000117	Loss: 0.147152
Epoch - 9, step #000029/000117	Loss: 0.252471
Epoch - 9, step #000030/000117	Loss: 0.185291
Epoch - 9, step #000031/000117	Loss: 0.195551
Epoch - 9, step #000032/000117	Loss: 0.203376
Epoch - 9, step #000033/000117	Loss: 0.204978
Epoch - 9, step #000034/000117	Loss: 0.178306
Epoch - 9, step #000035/000117	Loss: 0.156448
Epoch - 9, step #000036/000117	Loss: 0.208770
Epoch - 9, step #000037/000117	Loss: 0.182713
Epoch - 9, step #000038/000117	Loss: 0.226510
Epoch - 9, step #000039/000117	Loss: 0.174983
Epoch - 9, step #000040/000117	Loss: 0.255282
Epoch - 9, step #000041/000117	Loss: 0.190770
Epoch - 9, step #000042/000117	Loss: 0.248690
Epoch - 9, step #000043/000117	Loss: 0.172220
Epoch - 9, step #000044/000117	Loss: 0.197459
Epoch - 9, step #000045/000117	Loss: 0.207578
Epoch - 9, step #000046/000117	Loss: 0.198732
Epoch - 9, step #000047/000117	Loss: 0.232206
Epoch - 9, step #000048/000117	Loss: 0.178847
Epoch - 9, step #000049/000117	Loss: 0.171049
Epoch - 9, step #000050/000117	Loss: 0.198321
Epoch - 9, step #000051/000117	Loss: 0.233361
Epoch - 9, step #000052/000117	Loss: 0.194482
Epoch - 9, step #000053/000117	Loss: 0.239071
Epoch - 9, step #000054/000117	Loss: 0.151773
Epoch - 9, step #000055/000117	Loss: 0.242139
Epoch - 9, step #000056/000117	Loss: 0.215350
Epoch - 9, step #000057/000117	Loss: 0.210179
Epoch - 9, step #000058/000117	Loss: 0.248215
Epoch - 9, step #000059/000117	Loss: 0.229516
Epoch - 9, step #000060/000117	Loss: 0.236336
Epoch - 9, step #000061/000117	Loss: 0.198004
Epoch - 9, step #000062/000117	Loss: 0.182648
Epoch - 9, step #000063/000117	Loss: 0.196131
Epoch - 9, step #000064/000117	Loss: 0.299498
Epoch - 9, step #000065/000117	Loss: 0.244903
Epoch - 9, step #000066/000117	Loss: 0.213222
Epoch - 9, step #000067/000117	Loss: 0.221030
Epoch - 9, step #000068/000117	Loss: 0.195740
Epoch - 9, step #000069/000117	Loss: 0.161235
Epoch - 9, step #000070/000117	Loss: 0.194083
Epoch - 9, step #000071/000117	Loss: 0.228586
Epoch - 9, step #000072/000117	Loss: 0.183964
Epoch - 9, step #000073/000117	Loss: 0.284407
Epoch - 9, step #000074/000117	Loss: 0.244460
Epoch - 9, step #000075/000117	Loss: 0.280377
Epoch - 9, step #000076/000117	Loss: 0.173840
Epoch - 9, step #000077/000117	Loss: 0.227594
Epoch - 9, step #000078/000117	Loss: 0.234932
Epoch - 9, step #000079/000117	Loss: 0.216978
Epoch - 9, step #000080/000117	Loss: 0.184242
Epoch - 9, step #000081/000117	Loss: 0.197061
Epoch - 9, step #000082/000117	Loss: 0.302981
Epoch - 9, step #000083/000117	Loss: 0.180931
Epoch - 9, step #000084/000117	Loss: 0.200655
Epoch - 9, step #000085/000117	Loss: 0.192714
Epoch - 9, step #000086/000117	Loss: 0.234010
Epoch - 9, step #000087/000117	Loss: 0.174174
Epoch - 9, step #000088/000117	Loss: 0.219165
Epoch - 9, step #000089/000117	Loss: 0.164256
Epoch - 9, step #000090/000117	Loss: 0.191175
Epoch - 9, step #000091/000117	Loss: 0.205594
Epoch - 9, step #000092/000117	Loss: 0.238017
Epoch - 9, step #000093/000117	Loss: 0.237631
Epoch - 9, step #000094/000117	Loss: 0.213178
Epoch - 9, step #000095/000117	Loss: 0.230074
Epoch - 9, step #000096/000117	Loss: 0.227029
Epoch - 9, step #000097/000117	Loss: 0.204241
Epoch - 9, step #000098/000117	Loss: 0.220184
Epoch - 9, step #000099/000117	Loss: 0.167447
Epoch - 9, step #000100/000117	Loss: 0.203688
Epoch - 9, step #000101/000117	Loss: 0.187296
Epoch - 9, step #000102/000117	Loss: 0.221994
Epoch - 9, step #000103/000117	Loss: 0.165119
Epoch - 9, step #000104/000117	Loss: 0.214381
Epoch - 9, step #000105/000117	Loss: 0.170866
Epoch - 9, step #000106/000117	Loss: 0.203760
Epoch - 9, step #000107/000117	Loss: 0.162022
Epoch - 9, step #000108/000117	Loss: 0.145037
Epoch - 9, step #000109/000117	Loss: 0.157964
Epoch - 9, step #000110/000117	Loss: 0.240698
Epoch - 9, step #000111/000117	Loss: 0.164143
Epoch - 9, step #000112/000117	Loss: 0.191328
Epoch - 9, step #000113/000117	Loss: 0.204713
Epoch - 9, step #000114/000117	Loss: 0.177681
Epoch - 9, step #000115/000117	Loss: 0.169096
Epoch - 9, step #000116/000117	Loss: 0.206733
E[9], train Loss: 0.205524, training Acc: 0.936, val loss: 0.183, val Acc: 0.946	 Time: 10.588 seconds
E[9], train Loss: 0.205524, training Acc: 0.936, val loss: 0.134, val Acc: 0.957	 Time: 10.435 seconds
Epoch - 10, step #000000/000117	Loss: 0.227737
Epoch - 10, step #000001/000117	Loss: 0.172766
Epoch - 10, step #000002/000117	Loss: 0.172106
Epoch - 10, step #000003/000117	Loss: 0.161142
Epoch - 10, step #000004/000117	Loss: 0.193454
Epoch - 10, step #000005/000117	Loss: 0.181060
Epoch - 10, step #000006/000117	Loss: 0.232189
Epoch - 10, step #000007/000117	Loss: 0.175639
Epoch - 10, step #000008/000117	Loss: 0.167292
Epoch - 10, step #000009/000117	Loss: 0.182048
Epoch - 10, step #000010/000117	Loss: 0.187102
Epoch - 10, step #000011/000117	Loss: 0.238495
Epoch - 10, step #000012/000117	Loss: 0.165821
Epoch - 10, step #000013/000117	Loss: 0.194059
Epoch - 10, step #000014/000117	Loss: 0.156537
Epoch - 10, step #000015/000117	Loss: 0.224590
Epoch - 10, step #000016/000117	Loss: 0.189221
Epoch - 10, step #000017/000117	Loss: 0.215739
Epoch - 10, step #000018/000117	Loss: 0.198011
Epoch - 10, step #000019/000117	Loss: 0.187658
Epoch - 10, step #000020/000117	Loss: 0.183180
Epoch - 10, step #000021/000117	Loss: 0.169897
Epoch - 10, step #000022/000117	Loss: 0.166870
Epoch - 10, step #000023/000117	Loss: 0.187619
Epoch - 10, step #000024/000117	Loss: 0.184998
Epoch - 10, step #000025/000117	Loss: 0.235695
Epoch - 10, step #000026/000117	Loss: 0.230100
Epoch - 10, step #000027/000117	Loss: 0.204992
Epoch - 10, step #000028/000117	Loss: 0.211464
Epoch - 10, step #000029/000117	Loss: 0.194117
Epoch - 10, step #000030/000117	Loss: 0.175586
Epoch - 10, step #000031/000117	Loss: 0.227602
Epoch - 10, step #000032/000117	Loss: 0.243461
Epoch - 10, step #000033/000117	Loss: 0.190015
Epoch - 10, step #000034/000117	Loss: 0.217436
Epoch - 10, step #000035/000117	Loss: 0.194313
Epoch - 10, step #000036/000117	Loss: 0.162440
Epoch - 10, step #000037/000117	Loss: 0.206876
Epoch - 10, step #000038/000117	Loss: 0.232135
Epoch - 10, step #000039/000117	Loss: 0.172319
Epoch - 10, step #000040/000117	Loss: 0.207641
Epoch - 10, step #000041/000117	Loss: 0.223326
Epoch - 10, step #000042/000117	Loss: 0.195348
Epoch - 10, step #000043/000117	Loss: 0.181427
Epoch - 10, step #000044/000117	Loss: 0.210926
Epoch - 10, step #000045/000117	Loss: 0.172360
Epoch - 10, step #000046/000117	Loss: 0.190967
Epoch - 10, step #000047/000117	Loss: 0.130104
Epoch - 10, step #000048/000117	Loss: 0.227598
Epoch - 10, step #000049/000117	Loss: 0.163319
Epoch - 10, step #000050/000117	Loss: 0.231303
Epoch - 10, step #000051/000117	Loss: 0.220961
Epoch - 10, step #000052/000117	Loss: 0.157944
Epoch - 10, step #000053/000117	Loss: 0.240502
Epoch - 10, step #000054/000117	Loss: 0.206476
Epoch - 10, step #000055/000117	Loss: 0.213490
Epoch - 10, step #000056/000117	Loss: 0.160664
Epoch - 10, step #000057/000117	Loss: 0.143228
Epoch - 10, step #000058/000117	Loss: 0.202992
Epoch - 10, step #000059/000117	Loss: 0.182487
Epoch - 10, step #000060/000117	Loss: 0.224585
Epoch - 10, step #000061/000117	Loss: 0.184148
Epoch - 10, step #000062/000117	Loss: 0.186968
Epoch - 10, step #000063/000117	Loss: 0.232711
Epoch - 10, step #000064/000117	Loss: 0.164202
Epoch - 10, step #000065/000117	Loss: 0.189773
Epoch - 10, step #000066/000117	Loss: 0.205646
Epoch - 10, step #000067/000117	Loss: 0.215560
Epoch - 10, step #000068/000117	Loss: 0.194217
Epoch - 10, step #000069/000117	Loss: 0.220327
Epoch - 10, step #000070/000117	Loss: 0.182216
Epoch - 10, step #000071/000117	Loss: 0.224948
Epoch - 10, step #000072/000117	Loss: 0.160835
Epoch - 10, step #000073/000117	Loss: 0.161110
Epoch - 10, step #000074/000117	Loss: 0.215156
Epoch - 10, step #000075/000117	Loss: 0.184762
Epoch - 10, step #000076/000117	Loss: 0.184404
Epoch - 10, step #000077/000117	Loss: 0.161433
Epoch - 10, step #000078/000117	Loss: 0.261841
Epoch - 10, step #000079/000117	Loss: 0.173390
Epoch - 10, step #000080/000117	Loss: 0.192231
Epoch - 10, step #000081/000117	Loss: 0.182859
Epoch - 10, step #000082/000117	Loss: 0.225064
Epoch - 10, step #000083/000117	Loss: 0.160139
Epoch - 10, step #000084/000117	Loss: 0.172965
Epoch - 10, step #000085/000117	Loss: 0.183581
Epoch - 10, step #000086/000117	Loss: 0.222216
Epoch - 10, step #000087/000117	Loss: 0.191756
Epoch - 10, step #000088/000117	Loss: 0.245919
Epoch - 10, step #000089/000117	Loss: 0.199970
Epoch - 10, step #000090/000117	Loss: 0.257499
Epoch - 10, step #000091/000117	Loss: 0.178015
Epoch - 10, step #000092/000117	Loss: 0.250833
Epoch - 10, step #000093/000117	Loss: 0.157144
Epoch - 10, step #000094/000117	Loss: 0.138225
Epoch - 10, step #000095/000117	Loss: 0.189167
Epoch - 10, step #000096/000117	Loss: 0.143214
Epoch - 10, step #000097/000117	Loss: 0.163054
Epoch - 10, step #000098/000117	Loss: 0.166911
Epoch - 10, step #000099/000117	Loss: 0.173874
Epoch - 10, step #000100/000117	Loss: 0.184110
Epoch - 10, step #000101/000117	Loss: 0.200309
Epoch - 10, step #000102/000117	Loss: 0.178490
Epoch - 10, step #000103/000117	Loss: 0.202828
Epoch - 10, step #000104/000117	Loss: 0.182971
Epoch - 10, step #000105/000117	Loss: 0.207498
Epoch - 10, step #000106/000117	Loss: 0.192552
Epoch - 10, step #000107/000117	Loss: 0.227486
Epoch - 10, step #000108/000117	Loss: 0.178737
Epoch - 10, step #000109/000117	Loss: 0.233042
Epoch - 10, step #000110/000117	Loss: 0.182506
Epoch - 10, step #000111/000117	Loss: 0.243631
Epoch - 10, step #000112/000117	Loss: 0.202352
Epoch - 10, step #000113/000117	Loss: 0.172304
Epoch - 10, step #000114/000117	Loss: 0.205240
Epoch - 10, step #000115/000117	Loss: 0.149057
Epoch - 10, step #000116/000117	Loss: 0.176041
E[10], train Loss: 0.194178, training Acc: 0.941, val loss: 0.173, val Acc: 0.950	 Time: 10.551 seconds
E[10], train Loss: 0.194178, training Acc: 0.941, val loss: 0.126, val Acc: 0.961	 Time: 10.426 seconds
Epoch - 11, step #000000/000117	Loss: 0.178316
Epoch - 11, step #000001/000117	Loss: 0.175337
Epoch - 11, step #000002/000117	Loss: 0.150066
Epoch - 11, step #000003/000117	Loss: 0.164849
Epoch - 11, step #000004/000117	Loss: 0.148914
Epoch - 11, step #000005/000117	Loss: 0.155412
Epoch - 11, step #000006/000117	Loss: 0.189773
Epoch - 11, step #000007/000117	Loss: 0.154729
Epoch - 11, step #000008/000117	Loss: 0.133772
Epoch - 11, step #000009/000117	Loss: 0.197459
Epoch - 11, step #000010/000117	Loss: 0.165428
Epoch - 11, step #000011/000117	Loss: 0.199202
Epoch - 11, step #000012/000117	Loss: 0.162686
Epoch - 11, step #000013/000117	Loss: 0.217688
Epoch - 11, step #000014/000117	Loss: 0.183941
Epoch - 11, step #000015/000117	Loss: 0.149691
Epoch - 11, step #000016/000117	Loss: 0.131340
Epoch - 11, step #000017/000117	Loss: 0.213267
Epoch - 11, step #000018/000117	Loss: 0.208845
Epoch - 11, step #000019/000117	Loss: 0.193063
Epoch - 11, step #000020/000117	Loss: 0.176989
Epoch - 11, step #000021/000117	Loss: 0.155151
Epoch - 11, step #000022/000117	Loss: 0.204726
Epoch - 11, step #000023/000117	Loss: 0.177546
Epoch - 11, step #000024/000117	Loss: 0.190414
Epoch - 11, step #000025/000117	Loss: 0.181200
Epoch - 11, step #000026/000117	Loss: 0.223964
Epoch - 11, step #000027/000117	Loss: 0.147134
Epoch - 11, step #000028/000117	Loss: 0.203112
Epoch - 11, step #000029/000117	Loss: 0.209360
Epoch - 11, step #000030/000117	Loss: 0.172084
Epoch - 11, step #000031/000117	Loss: 0.140449
Epoch - 11, step #000032/000117	Loss: 0.142919
Epoch - 11, step #000033/000117	Loss: 0.183550
Epoch - 11, step #000034/000117	Loss: 0.137818
Epoch - 11, step #000035/000117	Loss: 0.180791
Epoch - 11, step #000036/000117	Loss: 0.216719
Epoch - 11, step #000037/000117	Loss: 0.191189
Epoch - 11, step #000038/000117	Loss: 0.196111
Epoch - 11, step #000039/000117	Loss: 0.161903
Epoch - 11, step #000040/000117	Loss: 0.175801
Epoch - 11, step #000041/000117	Loss: 0.177701
Epoch - 11, step #000042/000117	Loss: 0.168680
Epoch - 11, step #000043/000117	Loss: 0.200239
Epoch - 11, step #000044/000117	Loss: 0.207283
Epoch - 11, step #000045/000117	Loss: 0.191733
Epoch - 11, step #000046/000117	Loss: 0.193244
Epoch - 11, step #000047/000117	Loss: 0.185213
Epoch - 11, step #000048/000117	Loss: 0.187176
Epoch - 11, step #000049/000117	Loss: 0.193645
Epoch - 11, step #000050/000117	Loss: 0.166116
Epoch - 11, step #000051/000117	Loss: 0.137008
Epoch - 11, step #000052/000117	Loss: 0.190255
Epoch - 11, step #000053/000117	Loss: 0.200620
Epoch - 11, step #000054/000117	Loss: 0.180960
Epoch - 11, step #000055/000117	Loss: 0.160536
Epoch - 11, step #000056/000117	Loss: 0.167335
Epoch - 11, step #000057/000117	Loss: 0.195969
Epoch - 11, step #000058/000117	Loss: 0.176110
Epoch - 11, step #000059/000117	Loss: 0.198262
Epoch - 11, step #000060/000117	Loss: 0.168820
Epoch - 11, step #000061/000117	Loss: 0.193861
Epoch - 11, step #000062/000117	Loss: 0.154333
Epoch - 11, step #000063/000117	Loss: 0.176620
Epoch - 11, step #000064/000117	Loss: 0.160693
Epoch - 11, step #000065/000117	Loss: 0.190463
Epoch - 11, step #000066/000117	Loss: 0.210376
Epoch - 11, step #000067/000117	Loss: 0.226163
Epoch - 11, step #000068/000117	Loss: 0.194264
Epoch - 11, step #000069/000117	Loss: 0.152231
Epoch - 11, step #000070/000117	Loss: 0.222091
Epoch - 11, step #000071/000117	Loss: 0.189085
Epoch - 11, step #000072/000117	Loss: 0.146947
Epoch - 11, step #000073/000117	Loss: 0.177494
Epoch - 11, step #000074/000117	Loss: 0.208197
Epoch - 11, step #000075/000117	Loss: 0.145471
Epoch - 11, step #000076/000117	Loss: 0.183972
Epoch - 11, step #000077/000117	Loss: 0.203065
Epoch - 11, step #000078/000117	Loss: 0.166142
Epoch - 11, step #000079/000117	Loss: 0.159864
Epoch - 11, step #000080/000117	Loss: 0.235357
Epoch - 11, step #000081/000117	Loss: 0.195417
Epoch - 11, step #000082/000117	Loss: 0.126774
Epoch - 11, step #000083/000117	Loss: 0.196321
Epoch - 11, step #000084/000117	Loss: 0.198615
Epoch - 11, step #000085/000117	Loss: 0.214739
Epoch - 11, step #000086/000117	Loss: 0.191380
Epoch - 11, step #000087/000117	Loss: 0.199236
Epoch - 11, step #000088/000117	Loss: 0.204192
Epoch - 11, step #000089/000117	Loss: 0.153195
Epoch - 11, step #000090/000117	Loss: 0.167218
Epoch - 11, step #000091/000117	Loss: 0.210016
Epoch - 11, step #000092/000117	Loss: 0.195601
Epoch - 11, step #000093/000117	Loss: 0.149124
Epoch - 11, step #000094/000117	Loss: 0.148296
Epoch - 11, step #000095/000117	Loss: 0.187245
Epoch - 11, step #000096/000117	Loss: 0.181984
Epoch - 11, step #000097/000117	Loss: 0.172614
Epoch - 11, step #000098/000117	Loss: 0.150290
Epoch - 11, step #000099/000117	Loss: 0.172357
Epoch - 11, step #000100/000117	Loss: 0.203315
Epoch - 11, step #000101/000117	Loss: 0.166427
Epoch - 11, step #000102/000117	Loss: 0.260061
Epoch - 11, step #000103/000117	Loss: 0.137439
Epoch - 11, step #000104/000117	Loss: 0.218609
Epoch - 11, step #000105/000117	Loss: 0.216820
Epoch - 11, step #000106/000117	Loss: 0.178323
Epoch - 11, step #000107/000117	Loss: 0.230478
Epoch - 11, step #000108/000117	Loss: 0.171580
Epoch - 11, step #000109/000117	Loss: 0.165310
Epoch - 11, step #000110/000117	Loss: 0.177352
Epoch - 11, step #000111/000117	Loss: 0.192027
Epoch - 11, step #000112/000117	Loss: 0.150377
Epoch - 11, step #000113/000117	Loss: 0.194362
Epoch - 11, step #000114/000117	Loss: 0.167471
Epoch - 11, step #000115/000117	Loss: 0.132311
Epoch - 11, step #000116/000117	Loss: 0.165007
E[11], train Loss: 0.180583, training Acc: 0.946, val loss: 0.115, val Acc: 0.964	 Time: 6.070 seconds
E[11], train Loss: 0.180583, training Acc: 0.946, val loss: 0.165, val Acc: 0.953	 Time: 10.486 seconds
Epoch - 12, step #000000/000117	Loss: 0.197006
Epoch - 12, step #000001/000117	Loss: 0.165627
Epoch - 12, step #000002/000117	Loss: 0.154677
Epoch - 12, step #000003/000117	Loss: 0.204455
Epoch - 12, step #000004/000117	Loss: 0.162324
Epoch - 12, step #000005/000117	Loss: 0.169840
Epoch - 12, step #000006/000117	Loss: 0.112264
Epoch - 12, step #000007/000117	Loss: 0.173746
Epoch - 12, step #000008/000117	Loss: 0.164714
Epoch - 12, step #000009/000117	Loss: 0.207458
Epoch - 12, step #000010/000117	Loss: 0.193107
Epoch - 12, step #000011/000117	Loss: 0.171004
Epoch - 12, step #000012/000117	Loss: 0.146787
Epoch - 12, step #000013/000117	Loss: 0.141405
Epoch - 12, step #000014/000117	Loss: 0.178582
Epoch - 12, step #000015/000117	Loss: 0.127375
Epoch - 12, step #000016/000117	Loss: 0.129919
Epoch - 12, step #000017/000117	Loss: 0.151938
Epoch - 12, step #000018/000117	Loss: 0.169294
Epoch - 12, step #000019/000117	Loss: 0.207625
Epoch - 12, step #000020/000117	Loss: 0.166398
Epoch - 12, step #000021/000117	Loss: 0.146235
Epoch - 12, step #000022/000117	Loss: 0.205629
Epoch - 12, step #000023/000117	Loss: 0.171696
Epoch - 12, step #000024/000117	Loss: 0.147683
Epoch - 12, step #000025/000117	Loss: 0.139034
Epoch - 12, step #000026/000117	Loss: 0.142907
Epoch - 12, step #000027/000117	Loss: 0.154709
Epoch - 12, step #000028/000117	Loss: 0.156570
Epoch - 12, step #000029/000117	Loss: 0.167233
Epoch - 12, step #000030/000117	Loss: 0.189202
Epoch - 12, step #000031/000117	Loss: 0.148759
Epoch - 12, step #000032/000117	Loss: 0.166405
Epoch - 12, step #000033/000117	Loss: 0.130939
Epoch - 12, step #000034/000117	Loss: 0.187863
Epoch - 12, step #000035/000117	Loss: 0.179704
Epoch - 12, step #000036/000117	Loss: 0.194750
Epoch - 12, step #000037/000117	Loss: 0.186444
Epoch - 12, step #000038/000117	Loss: 0.190760
Epoch - 12, step #000039/000117	Loss: 0.199484
Epoch - 12, step #000040/000117	Loss: 0.160642
Epoch - 12, step #000041/000117	Loss: 0.140981
Epoch - 12, step #000042/000117	Loss: 0.191375
Epoch - 12, step #000043/000117	Loss: 0.129072
Epoch - 12, step #000044/000117	Loss: 0.186808
Epoch - 12, step #000045/000117	Loss: 0.183649
Epoch - 12, step #000046/000117	Loss: 0.202185
Epoch - 12, step #000047/000117	Loss: 0.224174
Epoch - 12, step #000048/000117	Loss: 0.178937
Epoch - 12, step #000049/000117	Loss: 0.142853
Epoch - 12, step #000050/000117	Loss: 0.181647
Epoch - 12, step #000051/000117	Loss: 0.146560
Epoch - 12, step #000052/000117	Loss: 0.192238
Epoch - 12, step #000053/000117	Loss: 0.180178
Epoch - 12, step #000054/000117	Loss: 0.186387
Epoch - 12, step #000055/000117	Loss: 0.185006
Epoch - 12, step #000056/000117	Loss: 0.172888
Epoch - 12, step #000057/000117	Loss: 0.179543
Epoch - 12, step #000058/000117	Loss: 0.145408
Epoch - 12, step #000059/000117	Loss: 0.150223
Epoch - 12, step #000060/000117	Loss: 0.197947
Epoch - 12, step #000061/000117	Loss: 0.178809
Epoch - 12, step #000062/000117	Loss: 0.140888
Epoch - 12, step #000063/000117	Loss: 0.210516
Epoch - 12, step #000064/000117	Loss: 0.217011
Epoch - 12, step #000065/000117	Loss: 0.174896
Epoch - 12, step #000066/000117	Loss: 0.141931
Epoch - 12, step #000067/000117	Loss: 0.186111
Epoch - 12, step #000068/000117	Loss: 0.176889
Epoch - 12, step #000069/000117	Loss: 0.213643
Epoch - 12, step #000070/000117	Loss: 0.176142
Epoch - 12, step #000071/000117	Loss: 0.176554
Epoch - 12, step #000072/000117	Loss: 0.212987
Epoch - 12, step #000073/000117	Loss: 0.166286
Epoch - 12, step #000074/000117	Loss: 0.140309
Epoch - 12, step #000075/000117	Loss: 0.147411
Epoch - 12, step #000076/000117	Loss: 0.151713
Epoch - 12, step #000077/000117	Loss: 0.204971
Epoch - 12, step #000078/000117	Loss: 0.178932
Epoch - 12, step #000079/000117	Loss: 0.195850
Epoch - 12, step #000080/000117	Loss: 0.157570
Epoch - 12, step #000081/000117	Loss: 0.130796
Epoch - 12, step #000082/000117	Loss: 0.191072
Epoch - 12, step #000083/000117	Loss: 0.168750
Epoch - 12, step #000084/000117	Loss: 0.157090
Epoch - 12, step #000085/000117	Loss: 0.200270
Epoch - 12, step #000086/000117	Loss: 0.177531
Epoch - 12, step #000087/000117	Loss: 0.138090
Epoch - 12, step #000088/000117	Loss: 0.215574
Epoch - 12, step #000089/000117	Loss: 0.172937
Epoch - 12, step #000090/000117	Loss: 0.192833
Epoch - 12, step #000091/000117	Loss: 0.143576
Epoch - 12, step #000092/000117	Loss: 0.192194
Epoch - 12, step #000093/000117	Loss: 0.128820
Epoch - 12, step #000094/000117	Loss: 0.158602
Epoch - 12, step #000095/000117	Loss: 0.142404
Epoch - 12, step #000096/000117	Loss: 0.124282
Epoch - 12, step #000097/000117	Loss: 0.238460
Epoch - 12, step #000098/000117	Loss: 0.176564
Epoch - 12, step #000099/000117	Loss: 0.189918
Epoch - 12, step #000100/000117	Loss: 0.190139
Epoch - 12, step #000101/000117	Loss: 0.160337
Epoch - 12, step #000102/000117	Loss: 0.199377
Epoch - 12, step #000103/000117	Loss: 0.112302
Epoch - 12, step #000104/000117	Loss: 0.128634
Epoch - 12, step #000105/000117	Loss: 0.180183
Epoch - 12, step #000106/000117	Loss: 0.133316
Epoch - 12, step #000107/000117	Loss: 0.156527
Epoch - 12, step #000108/000117	Loss: 0.168707
Epoch - 12, step #000109/000117	Loss: 0.173608
Epoch - 12, step #000110/000117	Loss: 0.152876
Epoch - 12, step #000111/000117	Loss: 0.187649
Epoch - 12, step #000112/000117	Loss: 0.172765
Epoch - 12, step #000113/000117	Loss: 0.134750
Epoch - 12, step #000114/000117	Loss: 0.134593
Epoch - 12, step #000115/000117	Loss: 0.211633
Epoch - 12, step #000116/000117	Loss: 0.101631
E[12], train Loss: 0.169645, training Acc: 0.949, val loss: 0.155, val Acc: 0.954	 Time: 6.481 seconds
E[12], train Loss: 0.169645, training Acc: 0.949, val loss: 0.110, val Acc: 0.964	 Time: 6.857 seconds
Epoch - 13, step #000000/000117	Loss: 0.121052
Epoch - 13, step #000001/000117	Loss: 0.160488
Epoch - 13, step #000002/000117	Loss: 0.163052
Epoch - 13, step #000003/000117	Loss: 0.172661
Epoch - 13, step #000004/000117	Loss: 0.141417
Epoch - 13, step #000005/000117	Loss: 0.183681
Epoch - 13, step #000006/000117	Loss: 0.178283
Epoch - 13, step #000007/000117	Loss: 0.196230
Epoch - 13, step #000008/000117	Loss: 0.140584
Epoch - 13, step #000009/000117	Loss: 0.127466
Epoch - 13, step #000010/000117	Loss: 0.194280
Epoch - 13, step #000011/000117	Loss: 0.162841
Epoch - 13, step #000012/000117	Loss: 0.147535
Epoch - 13, step #000013/000117	Loss: 0.147159
Epoch - 13, step #000014/000117	Loss: 0.142691
Epoch - 13, step #000015/000117	Loss: 0.151154
Epoch - 13, step #000016/000117	Loss: 0.158775
Epoch - 13, step #000017/000117	Loss: 0.202936
Epoch - 13, step #000018/000117	Loss: 0.143795
Epoch - 13, step #000019/000117	Loss: 0.139252
Epoch - 13, step #000020/000117	Loss: 0.153585
Epoch - 13, step #000021/000117	Loss: 0.149204
Epoch - 13, step #000022/000117	Loss: 0.146677
Epoch - 13, step #000023/000117	Loss: 0.176592
Epoch - 13, step #000024/000117	Loss: 0.209937
Epoch - 13, step #000025/000117	Loss: 0.160968
Epoch - 13, step #000026/000117	Loss: 0.182013
Epoch - 13, step #000027/000117	Loss: 0.126682
Epoch - 13, step #000028/000117	Loss: 0.142174
Epoch - 13, step #000029/000117	Loss: 0.111358
Epoch - 13, step #000030/000117	Loss: 0.142176
Epoch - 13, step #000031/000117	Loss: 0.149307
Epoch - 13, step #000032/000117	Loss: 0.158638
Epoch - 13, step #000033/000117	Loss: 0.159294
Epoch - 13, step #000034/000117	Loss: 0.132243
Epoch - 13, step #000035/000117	Loss: 0.147724
Epoch - 13, step #000036/000117	Loss: 0.132287
Epoch - 13, step #000037/000117	Loss: 0.157657
Epoch - 13, step #000038/000117	Loss: 0.168147
Epoch - 13, step #000039/000117	Loss: 0.137956
Epoch - 13, step #000040/000117	Loss: 0.197947
Epoch - 13, step #000041/000117	Loss: 0.156720
Epoch - 13, step #000042/000117	Loss: 0.143099
Epoch - 13, step #000043/000117	Loss: 0.182167
Epoch - 13, step #000044/000117	Loss: 0.213920
Epoch - 13, step #000045/000117	Loss: 0.190756
Epoch - 13, step #000046/000117	Loss: 0.175448
Epoch - 13, step #000047/000117	Loss: 0.143273
Epoch - 13, step #000048/000117	Loss: 0.148356
Epoch - 13, step #000049/000117	Loss: 0.183453
Epoch - 13, step #000050/000117	Loss: 0.160979
Epoch - 13, step #000051/000117	Loss: 0.155826
Epoch - 13, step #000052/000117	Loss: 0.153725
Epoch - 13, step #000053/000117	Loss: 0.213305
Epoch - 13, step #000054/000117	Loss: 0.170587
Epoch - 13, step #000055/000117	Loss: 0.180480
Epoch - 13, step #000056/000117	Loss: 0.171446
Epoch - 13, step #000057/000117	Loss: 0.129857
Epoch - 13, step #000058/000117	Loss: 0.176114
Epoch - 13, step #000059/000117	Loss: 0.183939
Epoch - 13, step #000060/000117	Loss: 0.153289
Epoch - 13, step #000061/000117	Loss: 0.174083
Epoch - 13, step #000062/000117	Loss: 0.178953
Epoch - 13, step #000063/000117	Loss: 0.170777
Epoch - 13, step #000064/000117	Loss: 0.214640
Epoch - 13, step #000065/000117	Loss: 0.152875
Epoch - 13, step #000066/000117	Loss: 0.146959
Epoch - 13, step #000067/000117	Loss: 0.142007
Epoch - 13, step #000068/000117	Loss: 0.181649
Epoch - 13, step #000069/000117	Loss: 0.183149
Epoch - 13, step #000070/000117	Loss: 0.185045
Epoch - 13, step #000071/000117	Loss: 0.135942
Epoch - 13, step #000072/000117	Loss: 0.181934
Epoch - 13, step #000073/000117	Loss: 0.200675
Epoch - 13, step #000074/000117	Loss: 0.153243
Epoch - 13, step #000075/000117	Loss: 0.129205
Epoch - 13, step #000076/000117	Loss: 0.144585
Epoch - 13, step #000077/000117	Loss: 0.159396
Epoch - 13, step #000078/000117	Loss: 0.206901
Epoch - 13, step #000079/000117	Loss: 0.179697
Epoch - 13, step #000080/000117	Loss: 0.209430
Epoch - 13, step #000081/000117	Loss: 0.208554
Epoch - 13, step #000082/000117	Loss: 0.197241
Epoch - 13, step #000083/000117	Loss: 0.159640
Epoch - 13, step #000084/000117	Loss: 0.127515
Epoch - 13, step #000085/000117	Loss: 0.167388
Epoch - 13, step #000086/000117	Loss: 0.184657
Epoch - 13, step #000087/000117	Loss: 0.185190
Epoch - 13, step #000088/000117	Loss: 0.131006
Epoch - 13, step #000089/000117	Loss: 0.133104
Epoch - 13, step #000090/000117	Loss: 0.156767
Epoch - 13, step #000091/000117	Loss: 0.102254
Epoch - 13, step #000092/000117	Loss: 0.175491
Epoch - 13, step #000093/000117	Loss: 0.147909
Epoch - 13, step #000094/000117	Loss: 0.140578
Epoch - 13, step #000095/000117	Loss: 0.168348
Epoch - 13, step #000096/000117	Loss: 0.090812
Epoch - 13, step #000097/000117	Loss: 0.128155
Epoch - 13, step #000098/000117	Loss: 0.161166
Epoch - 13, step #000099/000117	Loss: 0.182444
Epoch - 13, step #000100/000117	Loss: 0.114550
Epoch - 13, step #000101/000117	Loss: 0.135431
Epoch - 13, step #000102/000117	Loss: 0.168872
Epoch - 13, step #000103/000117	Loss: 0.197668
Epoch - 13, step #000104/000117	Loss: 0.130141
Epoch - 13, step #000105/000117	Loss: 0.119485
Epoch - 13, step #000106/000117	Loss: 0.181191
Epoch - 13, step #000107/000117	Loss: 0.104351
Epoch - 13, step #000108/000117	Loss: 0.168386
Epoch - 13, step #000109/000117	Loss: 0.142627
Epoch - 13, step #000110/000117	Loss: 0.157516
Epoch - 13, step #000111/000117	Loss: 0.124091
Epoch - 13, step #000112/000117	Loss: 0.156832
Epoch - 13, step #000113/000117	Loss: 0.163077
Epoch - 13, step #000114/000117	Loss: 0.141734
Epoch - 13, step #000115/000117	Loss: 0.213406
Epoch - 13, step #000116/000117	Loss: 0.139577
E[13], train Loss: 0.160196, training Acc: 0.952, val loss: 0.103, val Acc: 0.969	 Time: 6.046 seconds
E[13], train Loss: 0.160196, training Acc: 0.952, val loss: 0.147, val Acc: 0.956	 Time: 10.486 seconds
Epoch - 14, step #000000/000117	Loss: 0.145968
Epoch - 14, step #000001/000117	Loss: 0.166962
Epoch - 14, step #000002/000117	Loss: 0.132344
Epoch - 14, step #000003/000117	Loss: 0.130505
Epoch - 14, step #000004/000117	Loss: 0.182753
Epoch - 14, step #000005/000117	Loss: 0.109080
Epoch - 14, step #000006/000117	Loss: 0.118062
Epoch - 14, step #000007/000117	Loss: 0.130962
Epoch - 14, step #000008/000117	Loss: 0.140089
Epoch - 14, step #000009/000117	Loss: 0.197477
Epoch - 14, step #000010/000117	Loss: 0.149132
Epoch - 14, step #000011/000117	Loss: 0.156358
Epoch - 14, step #000012/000117	Loss: 0.142287
Epoch - 14, step #000013/000117	Loss: 0.157976
Epoch - 14, step #000014/000117	Loss: 0.120569
Epoch - 14, step #000015/000117	Loss: 0.154146
Epoch - 14, step #000016/000117	Loss: 0.126924
Epoch - 14, step #000017/000117	Loss: 0.126427
Epoch - 14, step #000018/000117	Loss: 0.166874
Epoch - 14, step #000019/000117	Loss: 0.195629
Epoch - 14, step #000020/000117	Loss: 0.156462
Epoch - 14, step #000021/000117	Loss: 0.144546
Epoch - 14, step #000022/000117	Loss: 0.152423
Epoch - 14, step #000023/000117	Loss: 0.153758
Epoch - 14, step #000024/000117	Loss: 0.119591
Epoch - 14, step #000025/000117	Loss: 0.117033
Epoch - 14, step #000026/000117	Loss: 0.130854
Epoch - 14, step #000027/000117	Loss: 0.169492
Epoch - 14, step #000028/000117	Loss: 0.146102
Epoch - 14, step #000029/000117	Loss: 0.130404
Epoch - 14, step #000030/000117	Loss: 0.145598
Epoch - 14, step #000031/000117	Loss: 0.130562
Epoch - 14, step #000032/000117	Loss: 0.150551
Epoch - 14, step #000033/000117	Loss: 0.134784
Epoch - 14, step #000034/000117	Loss: 0.250046
Epoch - 14, step #000035/000117	Loss: 0.142574
Epoch - 14, step #000036/000117	Loss: 0.136572
Epoch - 14, step #000037/000117	Loss: 0.162115
Epoch - 14, step #000038/000117	Loss: 0.154053
Epoch - 14, step #000039/000117	Loss: 0.192035
Epoch - 14, step #000040/000117	Loss: 0.156856
Epoch - 14, step #000041/000117	Loss: 0.119484
Epoch - 14, step #000042/000117	Loss: 0.141787
Epoch - 14, step #000043/000117	Loss: 0.128137
Epoch - 14, step #000044/000117	Loss: 0.148274
Epoch - 14, step #000045/000117	Loss: 0.187865
Epoch - 14, step #000046/000117	Loss: 0.150319
Epoch - 14, step #000047/000117	Loss: 0.165642
Epoch - 14, step #000048/000117	Loss: 0.131869
Epoch - 14, step #000049/000117	Loss: 0.174725
Epoch - 14, step #000050/000117	Loss: 0.160188
Epoch - 14, step #000051/000117	Loss: 0.152407
Epoch - 14, step #000052/000117	Loss: 0.123463
Epoch - 14, step #000053/000117	Loss: 0.122013
Epoch - 14, step #000054/000117	Loss: 0.121578
Epoch - 14, step #000055/000117	Loss: 0.146745
Epoch - 14, step #000056/000117	Loss: 0.114555
Epoch - 14, step #000057/000117	Loss: 0.150912
Epoch - 14, step #000058/000117	Loss: 0.199210
Epoch - 14, step #000059/000117	Loss: 0.180183
Epoch - 14, step #000060/000117	Loss: 0.160066
Epoch - 14, step #000061/000117	Loss: 0.225981
Epoch - 14, step #000062/000117	Loss: 0.125224
Epoch - 14, step #000063/000117	Loss: 0.200871
Epoch - 14, step #000064/000117	Loss: 0.181845
Epoch - 14, step #000065/000117	Loss: 0.112564
Epoch - 14, step #000066/000117	Loss: 0.196341
Epoch - 14, step #000067/000117	Loss: 0.149046
Epoch - 14, step #000068/000117	Loss: 0.148272
Epoch - 14, step #000069/000117	Loss: 0.159339
Epoch - 14, step #000070/000117	Loss: 0.182054
Epoch - 14, step #000071/000117	Loss: 0.153712
Epoch - 14, step #000072/000117	Loss: 0.159522
Epoch - 14, step #000073/000117	Loss: 0.144196
Epoch - 14, step #000074/000117	Loss: 0.125999
Epoch - 14, step #000075/000117	Loss: 0.175880
Epoch - 14, step #000076/000117	Loss: 0.147007
Epoch - 14, step #000077/000117	Loss: 0.151036
Epoch - 14, step #000078/000117	Loss: 0.155877
Epoch - 14, step #000079/000117	Loss: 0.218652
Epoch - 14, step #000080/000117	Loss: 0.173421
Epoch - 14, step #000081/000117	Loss: 0.111728
Epoch - 14, step #000082/000117	Loss: 0.148938
Epoch - 14, step #000083/000117	Loss: 0.144325
Epoch - 14, step #000084/000117	Loss: 0.096123
Epoch - 14, step #000085/000117	Loss: 0.118518
Epoch - 14, step #000086/000117	Loss: 0.129578
Epoch - 14, step #000087/000117	Loss: 0.239078
Epoch - 14, step #000088/000117	Loss: 0.103970
Epoch - 14, step #000089/000117	Loss: 0.146369
Epoch - 14, step #000090/000117	Loss: 0.111846
Epoch - 14, step #000091/000117	Loss: 0.095942
Epoch - 14, step #000092/000117	Loss: 0.112489
Epoch - 14, step #000093/000117	Loss: 0.125583
Epoch - 14, step #000094/000117	Loss: 0.129187
Epoch - 14, step #000095/000117	Loss: 0.140476
Epoch - 14, step #000096/000117	Loss: 0.169401
Epoch - 14, step #000097/000117	Loss: 0.147909
Epoch - 14, step #000098/000117	Loss: 0.159889
Epoch - 14, step #000099/000117	Loss: 0.140245
Epoch - 14, step #000100/000117	Loss: 0.137668
Epoch - 14, step #000101/000117	Loss: 0.097745
Epoch - 14, step #000102/000117	Loss: 0.118654
Epoch - 14, step #000103/000117	Loss: 0.175369
Epoch - 14, step #000104/000117	Loss: 0.134849
Epoch - 14, step #000105/000117	Loss: 0.175281
Epoch - 14, step #000106/000117	Loss: 0.118009
Epoch - 14, step #000107/000117	Loss: 0.133489
Epoch - 14, step #000108/000117	Loss: 0.168138
Epoch - 14, step #000109/000117	Loss: 0.137705
Epoch - 14, step #000110/000117	Loss: 0.169009
Epoch - 14, step #000111/000117	Loss: 0.173859
Epoch - 14, step #000112/000117	Loss: 0.153377
Epoch - 14, step #000113/000117	Loss: 0.135482
Epoch - 14, step #000114/000117	Loss: 0.139290
Epoch - 14, step #000115/000117	Loss: 0.136881
Epoch - 14, step #000116/000117	Loss: 0.130909
E[14], train Loss: 0.148722, training Acc: 0.955, val loss: 0.143, val Acc: 0.958	 Time: 6.445 seconds
E[14], train Loss: 0.148722, training Acc: 0.955, val loss: 0.093, val Acc: 0.971	 Time: 20.669 seconds
Epoch - 15, step #000000/000117	Loss: 0.118074
Epoch - 15, step #000001/000117	Loss: 0.192537
Epoch - 15, step #000002/000117	Loss: 0.177677
Epoch - 15, step #000003/000117	Loss: 0.180736
Epoch - 15, step #000004/000117	Loss: 0.103438
Epoch - 15, step #000005/000117	Loss: 0.153900
Epoch - 15, step #000006/000117	Loss: 0.090713
Epoch - 15, step #000007/000117	Loss: 0.133425
Epoch - 15, step #000008/000117	Loss: 0.115846
Epoch - 15, step #000009/000117	Loss: 0.133189
Epoch - 15, step #000010/000117	Loss: 0.129202
Epoch - 15, step #000011/000117	Loss: 0.128358
Epoch - 15, step #000012/000117	Loss: 0.130326
Epoch - 15, step #000013/000117	Loss: 0.138554
Epoch - 15, step #000014/000117	Loss: 0.119695
Epoch - 15, step #000015/000117	Loss: 0.105753
Epoch - 15, step #000016/000117	Loss: 0.164168
Epoch - 15, step #000017/000117	Loss: 0.141618
Epoch - 15, step #000018/000117	Loss: 0.133976
Epoch - 15, step #000019/000117	Loss: 0.107707
Epoch - 15, step #000020/000117	Loss: 0.121375
Epoch - 15, step #000021/000117	Loss: 0.193053
Epoch - 15, step #000022/000117	Loss: 0.137320
Epoch - 15, step #000023/000117	Loss: 0.191325
Epoch - 15, step #000024/000117	Loss: 0.147865
Epoch - 15, step #000025/000117	Loss: 0.170942
Epoch - 15, step #000026/000117	Loss: 0.133455
Epoch - 15, step #000027/000117	Loss: 0.109205
Epoch - 15, step #000028/000117	Loss: 0.171871
Epoch - 15, step #000029/000117	Loss: 0.171217
Epoch - 15, step #000030/000117	Loss: 0.115217
Epoch - 15, step #000031/000117	Loss: 0.135825
Epoch - 15, step #000032/000117	Loss: 0.145647
Epoch - 15, step #000033/000117	Loss: 0.163537
Epoch - 15, step #000034/000117	Loss: 0.134054
Epoch - 15, step #000035/000117	Loss: 0.164552
Epoch - 15, step #000036/000117	Loss: 0.092366
Epoch - 15, step #000037/000117	Loss: 0.126084
Epoch - 15, step #000038/000117	Loss: 0.137261
Epoch - 15, step #000039/000117	Loss: 0.164090
Epoch - 15, step #000040/000117	Loss: 0.088020
Epoch - 15, step #000041/000117	Loss: 0.154303
Epoch - 15, step #000042/000117	Loss: 0.190751
Epoch - 15, step #000043/000117	Loss: 0.198420
Epoch - 15, step #000044/000117	Loss: 0.137092
Epoch - 15, step #000045/000117	Loss: 0.101387
Epoch - 15, step #000046/000117	Loss: 0.127879
Epoch - 15, step #000047/000117	Loss: 0.150930
Epoch - 15, step #000048/000117	Loss: 0.162810
Epoch - 15, step #000049/000117	Loss: 0.148788
Epoch - 15, step #000050/000117	Loss: 0.131773
Epoch - 15, step #000051/000117	Loss: 0.161206
Epoch - 15, step #000052/000117	Loss: 0.147829
Epoch - 15, step #000053/000117	Loss: 0.141266
Epoch - 15, step #000054/000117	Loss: 0.123504
Epoch - 15, step #000055/000117	Loss: 0.156976
Epoch - 15, step #000056/000117	Loss: 0.127790
Epoch - 15, step #000057/000117	Loss: 0.155011
Epoch - 15, step #000058/000117	Loss: 0.133059
Epoch - 15, step #000059/000117	Loss: 0.150614
Epoch - 15, step #000060/000117	Loss: 0.189611
Epoch - 15, step #000061/000117	Loss: 0.138207
Epoch - 15, step #000062/000117	Loss: 0.133361
Epoch - 15, step #000063/000117	Loss: 0.123960
Epoch - 15, step #000064/000117	Loss: 0.118295
Epoch - 15, step #000065/000117	Loss: 0.158993
Epoch - 15, step #000066/000117	Loss: 0.140145
Epoch - 15, step #000067/000117	Loss: 0.134330
Epoch - 15, step #000068/000117	Loss: 0.116872
Epoch - 15, step #000069/000117	Loss: 0.182639
Epoch - 15, step #000070/000117	Loss: 0.166159
Epoch - 15, step #000071/000117	Loss: 0.142442
Epoch - 15, step #000072/000117	Loss: 0.122024
Epoch - 15, step #000073/000117	Loss: 0.139678
Epoch - 15, step #000074/000117	Loss: 0.148134
Epoch - 15, step #000075/000117	Loss: 0.140247
Epoch - 15, step #000076/000117	Loss: 0.091904
Epoch - 15, step #000077/000117	Loss: 0.106599
Epoch - 15, step #000078/000117	Loss: 0.114173
Epoch - 15, step #000079/000117	Loss: 0.145576
Epoch - 15, step #000080/000117	Loss: 0.203821
Epoch - 15, step #000081/000117	Loss: 0.143081
Epoch - 15, step #000082/000117	Loss: 0.122760
Epoch - 15, step #000083/000117	Loss: 0.131528
Epoch - 15, step #000084/000117	Loss: 0.130429
Epoch - 15, step #000085/000117	Loss: 0.114305
Epoch - 15, step #000086/000117	Loss: 0.152016
Epoch - 15, step #000087/000117	Loss: 0.150685
Epoch - 15, step #000088/000117	Loss: 0.126935
Epoch - 15, step #000089/000117	Loss: 0.121278
Epoch - 15, step #000090/000117	Loss: 0.145394
Epoch - 15, step #000091/000117	Loss: 0.132094
Epoch - 15, step #000092/000117	Loss: 0.129530
Epoch - 15, step #000093/000117	Loss: 0.152104
Epoch - 15, step #000094/000117	Loss: 0.133755
Epoch - 15, step #000095/000117	Loss: 0.152353
Epoch - 15, step #000096/000117	Loss: 0.118410
Epoch - 15, step #000097/000117	Loss: 0.145745
Epoch - 15, step #000098/000117	Loss: 0.190478
Epoch - 15, step #000099/000117	Loss: 0.145862
Epoch - 15, step #000100/000117	Loss: 0.141180
Epoch - 15, step #000101/000117	Loss: 0.161611
Epoch - 15, step #000102/000117	Loss: 0.127167
Epoch - 15, step #000103/000117	Loss: 0.120291
Epoch - 15, step #000104/000117	Loss: 0.102092
Epoch - 15, step #000105/000117	Loss: 0.097977
Epoch - 15, step #000106/000117	Loss: 0.142312
Epoch - 15, step #000107/000117	Loss: 0.145613
Epoch - 15, step #000108/000117	Loss: 0.119266
Epoch - 15, step #000109/000117	Loss: 0.134468
Epoch - 15, step #000110/000117	Loss: 0.168666
Epoch - 15, step #000111/000117	Loss: 0.143322
Epoch - 15, step #000112/000117	Loss: 0.149046
Epoch - 15, step #000113/000117	Loss: 0.177948
Epoch - 15, step #000114/000117	Loss: 0.084494
Epoch - 15, step #000115/000117	Loss: 0.143759
Epoch - 15, step #000116/000117	Loss: 0.133939
E[15], train Loss: 0.140202, training Acc: 0.958, val loss: 0.086, val Acc: 0.973	 Time: 6.291 seconds
Total training time: 170.52184319496155 seconds
E[15], train Loss: 0.140202, training Acc: 0.958, val loss: 0.145, val Acc: 0.958	 Time: 20.666 seconds
Total training time: 174.6849446296692 seconds
# GPSs:  3
# GPSs:  3
# GPSs:  3
# GPSs:  3
# I am rank 0 of 4
# I am rank 1 of 4
# I am rank 3 of 4
# I am rank 2 of 4
Epoch - 0, step #000000/000058	Loss: 2.306760
Epoch - 0, step #000001/000058	Loss: 2.301686
Epoch - 0, step #000002/000058	Loss: 2.294018
Epoch - 0, step #000003/000058	Loss: 2.291615
Epoch - 0, step #000004/000058	Loss: 2.283203
Epoch - 0, step #000005/000058	Loss: 2.283218
Epoch - 0, step #000006/000058	Loss: 2.269732
Epoch - 0, step #000007/000058	Loss: 2.273111
Epoch - 0, step #000008/000058	Loss: 2.254145
Epoch - 0, step #000009/000058	Loss: 2.259456
Epoch - 0, step #000010/000058	Loss: 2.246688
Epoch - 0, step #000011/000058	Loss: 2.226705
Epoch - 0, step #000012/000058	Loss: 2.225811
Epoch - 0, step #000013/000058	Loss: 2.205929
Epoch - 0, step #000014/000058	Loss: 2.192065
Epoch - 0, step #000015/000058	Loss: 2.175036
Epoch - 0, step #000016/000058	Loss: 2.150422
Epoch - 0, step #000017/000058	Loss: 2.135193
Epoch - 0, step #000018/000058	Loss: 2.105161
Epoch - 0, step #000019/000058	Loss: 2.052766
Epoch - 0, step #000020/000058	Loss: 2.015378
Epoch - 0, step #000021/000058	Loss: 1.989099
Epoch - 0, step #000022/000058	Loss: 1.917115
Epoch - 0, step #000023/000058	Loss: 1.844293
Epoch - 0, step #000024/000058	Loss: 1.772666
Epoch - 0, step #000025/000058	Loss: 1.692858
Epoch - 0, step #000026/000058	Loss: 1.640386
Epoch - 0, step #000027/000058	Loss: 1.545267
Epoch - 0, step #000028/000058	Loss: 1.500358
Epoch - 0, step #000029/000058	Loss: 1.498672
Epoch - 0, step #000030/000058	Loss: 1.496373
Epoch - 0, step #000031/000058	Loss: 1.405372
Epoch - 0, step #000032/000058	Loss: 1.308922
Epoch - 0, step #000033/000058	Loss: 1.322178
Epoch - 0, step #000034/000058	Loss: 1.300244
Epoch - 0, step #000035/000058	Loss: 1.251081
Epoch - 0, step #000036/000058	Loss: 1.160930
Epoch - 0, step #000037/000058	Loss: 1.131310
Epoch - 0, step #000038/000058	Loss: 1.121794
Epoch - 0, step #000039/000058	Loss: 1.092624
Epoch - 0, step #000040/000058	Loss: 1.102644
Epoch - 0, step #000041/000058	Loss: 1.054149
Epoch - 0, step #000042/000058	Loss: 1.014172
Epoch - 0, step #000043/000058	Loss: 1.000843
Epoch - 0, step #000044/000058	Loss: 0.959172
Epoch - 0, step #000045/000058	Loss: 0.855696
Epoch - 0, step #000046/000058	Loss: 0.893570
Epoch - 0, step #000047/000058	Loss: 0.865446
Epoch - 0, step #000048/000058	Loss: 0.874528
Epoch - 0, step #000049/000058	Loss: 0.963917
Epoch - 0, step #000050/000058	Loss: 1.084327
Epoch - 0, step #000051/000058	Loss: 1.021056
Epoch - 0, step #000052/000058	Loss: 0.994821
Epoch - 0, step #000053/000058	Loss: 0.862054
Epoch - 0, step #000054/000058	Loss: 0.818786
Epoch - 0, step #000055/000058	Loss: 0.819257
Epoch - 0, step #000056/000058	Loss: 0.776736
Epoch - 0, step #000057/000058	Loss: 0.758724
E[0], train Loss: 1.573440, training Acc: 0.471, val loss: 0.591, val Acc: 0.844	 Time: 12.948 seconds
E[0], train Loss: 1.573440, training Acc: 0.471, val loss: 0.561, val Acc: 0.817	 Time: 12.919 seconds
E[0], train Loss: 1.573440, training Acc: 0.471, val loss: 0.579, val Acc: 0.819	 Time: 12.912 seconds
E[0], train Loss: 1.573440, training Acc: 0.471, val loss: 0.564, val Acc: 0.828	 Time: 12.990 seconds
Epoch - 1, step #000000/000058	Loss: 0.762265
Epoch - 1, step #000001/000058	Loss: 0.747653
Epoch - 1, step #000002/000058	Loss: 0.712064
Epoch - 1, step #000003/000058	Loss: 0.824700
Epoch - 1, step #000004/000058	Loss: 0.838687
Epoch - 1, step #000005/000058	Loss: 0.758961
Epoch - 1, step #000006/000058	Loss: 0.677619
Epoch - 1, step #000007/000058	Loss: 0.713641
Epoch - 1, step #000008/000058	Loss: 0.769410
Epoch - 1, step #000009/000058	Loss: 0.699659
Epoch - 1, step #000010/000058	Loss: 0.683480
Epoch - 1, step #000011/000058	Loss: 0.684196
Epoch - 1, step #000012/000058	Loss: 0.677455
Epoch - 1, step #000013/000058	Loss: 0.589688
Epoch - 1, step #000014/000058	Loss: 0.577366
Epoch - 1, step #000015/000058	Loss: 0.650379
Epoch - 1, step #000016/000058	Loss: 0.631707
Epoch - 1, step #000017/000058	Loss: 0.633723
Epoch - 1, step #000018/000058	Loss: 0.562197
Epoch - 1, step #000019/000058	Loss: 0.599535
Epoch - 1, step #000020/000058	Loss: 0.593639
Epoch - 1, step #000021/000058	Loss: 0.651583
Epoch - 1, step #000022/000058	Loss: 0.641578
Epoch - 1, step #000023/000058	Loss: 0.590500
Epoch - 1, step #000024/000058	Loss: 0.666121
Epoch - 1, step #000025/000058	Loss: 0.622862
Epoch - 1, step #000026/000058	Loss: 0.589066
Epoch - 1, step #000027/000058	Loss: 0.589315
Epoch - 1, step #000028/000058	Loss: 0.565528
Epoch - 1, step #000029/000058	Loss: 0.592969
Epoch - 1, step #000030/000058	Loss: 0.569583
Epoch - 1, step #000031/000058	Loss: 0.607295
Epoch - 1, step #000032/000058	Loss: 0.533076
Epoch - 1, step #000033/000058	Loss: 0.550772
Epoch - 1, step #000034/000058	Loss: 0.572019
Epoch - 1, step #000035/000058	Loss: 0.508556
Epoch - 1, step #000036/000058	Loss: 0.500493
Epoch - 1, step #000037/000058	Loss: 0.519633
Epoch - 1, step #000038/000058	Loss: 0.536913
Epoch - 1, step #000039/000058	Loss: 0.569797
Epoch - 1, step #000040/000058	Loss: 0.521805
Epoch - 1, step #000041/000058	Loss: 0.509830
Epoch - 1, step #000042/000058	Loss: 0.525112
Epoch - 1, step #000043/000058	Loss: 0.580127
Epoch - 1, step #000044/000058	Loss: 0.521442
Epoch - 1, step #000045/000058	Loss: 0.504540
Epoch - 1, step #000046/000058	Loss: 0.535545
Epoch - 1, step #000047/000058	Loss: 0.516916
Epoch - 1, step #000048/000058	Loss: 0.479645
Epoch - 1, step #000049/000058	Loss: 0.555204
Epoch - 1, step #000050/000058	Loss: 0.524895
Epoch - 1, step #000051/000058	Loss: 0.493248
Epoch - 1, step #000052/000058	Loss: 0.475814
Epoch - 1, step #000053/000058	Loss: 0.560612
Epoch - 1, step #000054/000058	Loss: 0.502674
Epoch - 1, step #000055/000058	Loss: 0.512300
Epoch - 1, step #000056/000058	Loss: 0.484215
Epoch - 1, step #000057/000058	Loss: 0.495582
E[1], train Loss: 0.597676, training Acc: 0.808, val loss: 0.366, val Acc: 0.890	 Time: 3.334 seconds
E[1], train Loss: 0.597676, training Acc: 0.808, val loss: 0.359, val Acc: 0.891	 Time: 3.336 seconds
E[1], train Loss: 0.597676, training Acc: 0.808, val loss: 0.365, val Acc: 0.893	 Time: 3.344 seconds
E[1], train Loss: 0.597676, training Acc: 0.808, val loss: 0.370, val Acc: 0.889	 Time: 3.334 seconds
Epoch - 2, step #000000/000058	Loss: 0.487028
Epoch - 2, step #000001/000058	Loss: 0.555818
Epoch - 2, step #000002/000058	Loss: 0.460346
Epoch - 2, step #000003/000058	Loss: 0.535382
Epoch - 2, step #000004/000058	Loss: 0.481349
Epoch - 2, step #000005/000058	Loss: 0.450818
Epoch - 2, step #000006/000058	Loss: 0.552927
Epoch - 2, step #000007/000058	Loss: 0.486615
Epoch - 2, step #000008/000058	Loss: 0.455225
Epoch - 2, step #000009/000058	Loss: 0.442050
Epoch - 2, step #000010/000058	Loss: 0.507621
Epoch - 2, step #000011/000058	Loss: 0.502053
Epoch - 2, step #000012/000058	Loss: 0.516828
Epoch - 2, step #000013/000058	Loss: 0.434548
Epoch - 2, step #000014/000058	Loss: 0.432413
Epoch - 2, step #000015/000058	Loss: 0.502604
Epoch - 2, step #000016/000058	Loss: 0.448871
Epoch - 2, step #000017/000058	Loss: 0.467059
Epoch - 2, step #000018/000058	Loss: 0.462476
Epoch - 2, step #000019/000058	Loss: 0.489029
Epoch - 2, step #000020/000058	Loss: 0.524844
Epoch - 2, step #000021/000058	Loss: 0.494888
Epoch - 2, step #000022/000058	Loss: 0.450374
Epoch - 2, step #000023/000058	Loss: 0.475804
Epoch - 2, step #000024/000058	Loss: 0.398667
Epoch - 2, step #000025/000058	Loss: 0.451098
Epoch - 2, step #000026/000058	Loss: 0.439248
Epoch - 2, step #000027/000058	Loss: 0.439513
Epoch - 2, step #000028/000058	Loss: 0.416639
Epoch - 2, step #000029/000058	Loss: 0.436877
Epoch - 2, step #000030/000058	Loss: 0.441730
Epoch - 2, step #000031/000058	Loss: 0.432794
Epoch - 2, step #000032/000058	Loss: 0.443149
Epoch - 2, step #000033/000058	Loss: 0.445610
Epoch - 2, step #000034/000058	Loss: 0.431180
Epoch - 2, step #000035/000058	Loss: 0.431441
Epoch - 2, step #000036/000058	Loss: 0.443616
Epoch - 2, step #000037/000058	Loss: 0.411737
Epoch - 2, step #000038/000058	Loss: 0.385218
Epoch - 2, step #000039/000058	Loss: 0.385258
Epoch - 2, step #000040/000058	Loss: 0.396948
Epoch - 2, step #000041/000058	Loss: 0.484994
Epoch - 2, step #000042/000058	Loss: 0.485062
Epoch - 2, step #000043/000058	Loss: 0.437746
Epoch - 2, step #000044/000058	Loss: 0.427201
Epoch - 2, step #000045/000058	Loss: 0.454259
Epoch - 2, step #000046/000058	Loss: 0.442644
Epoch - 2, step #000047/000058	Loss: 0.414069
Epoch - 2, step #000048/000058	Loss: 0.470598
Epoch - 2, step #000049/000058	Loss: 0.421230
Epoch - 2, step #000050/000058	Loss: 0.384716
Epoch - 2, step #000051/000058	Loss: 0.439262
Epoch - 2, step #000052/000058	Loss: 0.455085
Epoch - 2, step #000053/000058	Loss: 0.415298
Epoch - 2, step #000054/000058	Loss: 0.470285
Epoch - 2, step #000055/000058	Loss: 0.385833
Epoch - 2, step #000056/000058	Loss: 0.459880
Epoch - 2, step #000057/000058	Loss: 0.465267
E[2], train Loss: 0.454502, training Acc: 0.858, val loss: 0.335, val Acc: 0.895	 Time: 3.343 seconds
E[2], train Loss: 0.454502, training Acc: 0.858, val loss: 0.308, val Acc: 0.909	 Time: 3.343 seconds
E[2], train Loss: 0.454502, training Acc: 0.858, val loss: 0.312, val Acc: 0.908	 Time: 3.355 seconds
E[2], train Loss: 0.454502, training Acc: 0.858, val loss: 0.309, val Acc: 0.907	 Time: 3.349 seconds
Epoch - 3, step #000000/000058	Loss: 0.390606
Epoch - 3, step #000001/000058	Loss: 0.426168
Epoch - 3, step #000002/000058	Loss: 0.415852
Epoch - 3, step #000003/000058	Loss: 0.476092
Epoch - 3, step #000004/000058	Loss: 0.421837
Epoch - 3, step #000005/000058	Loss: 0.435578
Epoch - 3, step #000006/000058	Loss: 0.413703
Epoch - 3, step #000007/000058	Loss: 0.391971
Epoch - 3, step #000008/000058	Loss: 0.420336
Epoch - 3, step #000009/000058	Loss: 0.384588
Epoch - 3, step #000010/000058	Loss: 0.418269
Epoch - 3, step #000011/000058	Loss: 0.412025
Epoch - 3, step #000012/000058	Loss: 0.391439
Epoch - 3, step #000013/000058	Loss: 0.459266
Epoch - 3, step #000014/000058	Loss: 0.407266
Epoch - 3, step #000015/000058	Loss: 0.413559
Epoch - 3, step #000016/000058	Loss: 0.396287
Epoch - 3, step #000017/000058	Loss: 0.371305
Epoch - 3, step #000018/000058	Loss: 0.390685
Epoch - 3, step #000019/000058	Loss: 0.384978
Epoch - 3, step #000020/000058	Loss: 0.454894
Epoch - 3, step #000021/000058	Loss: 0.354823
Epoch - 3, step #000022/000058	Loss: 0.412435
Epoch - 3, step #000023/000058	Loss: 0.380322
Epoch - 3, step #000024/000058	Loss: 0.402567
Epoch - 3, step #000025/000058	Loss: 0.397742
Epoch - 3, step #000026/000058	Loss: 0.422544
Epoch - 3, step #000027/000058	Loss: 0.405248
Epoch - 3, step #000028/000058	Loss: 0.382763
Epoch - 3, step #000029/000058	Loss: 0.437942
Epoch - 3, step #000030/000058	Loss: 0.372262
Epoch - 3, step #000031/000058	Loss: 0.356994
Epoch - 3, step #000032/000058	Loss: 0.352494
Epoch - 3, step #000033/000058	Loss: 0.397042
Epoch - 3, step #000034/000058	Loss: 0.432374
Epoch - 3, step #000035/000058	Loss: 0.362404
Epoch - 3, step #000036/000058	Loss: 0.373975
Epoch - 3, step #000037/000058	Loss: 0.385955
Epoch - 3, step #000038/000058	Loss: 0.400908
Epoch - 3, step #000039/000058	Loss: 0.371834
Epoch - 3, step #000040/000058	Loss: 0.377458
Epoch - 3, step #000041/000058	Loss: 0.363927
Epoch - 3, step #000042/000058	Loss: 0.400584
Epoch - 3, step #000043/000058	Loss: 0.400651
Epoch - 3, step #000044/000058	Loss: 0.380695
Epoch - 3, step #000045/000058	Loss: 0.358625
Epoch - 3, step #000046/000058	Loss: 0.366696
Epoch - 3, step #000047/000058	Loss: 0.422999
Epoch - 3, step #000048/000058	Loss: 0.339295
Epoch - 3, step #000049/000058	Loss: 0.345783
Epoch - 3, step #000050/000058	Loss: 0.380535
Epoch - 3, step #000051/000058	Loss: 0.418006
Epoch - 3, step #000052/000058	Loss: 0.389039
Epoch - 3, step #000053/000058	Loss: 0.367709
Epoch - 3, step #000054/000058	Loss: 0.312143
Epoch - 3, step #000055/000058	Loss: 0.364107
Epoch - 3, step #000056/000058	Loss: 0.339290
Epoch - 3, step #000057/000058	Loss: 0.355082
E[3], train Loss: 0.392448, training Acc: 0.877, val loss: 0.282, val Acc: 0.914	 Time: 3.345 seconds
E[3], train Loss: 0.392448, training Acc: 0.877, val loss: 0.284, val Acc: 0.917	 Time: 3.338 seconds
E[3], train Loss: 0.392448, training Acc: 0.877, val loss: 0.258, val Acc: 0.922	 Time: 3.347 seconds
E[3], train Loss: 0.392448, training Acc: 0.877, val loss: 0.283, val Acc: 0.912	 Time: 3.349 seconds
Epoch - 4, step #000000/000058	Loss: 0.394325
Epoch - 4, step #000001/000058	Loss: 0.362290
Epoch - 4, step #000002/000058	Loss: 0.430677
Epoch - 4, step #000003/000058	Loss: 0.332221
Epoch - 4, step #000004/000058	Loss: 0.391546
Epoch - 4, step #000005/000058	Loss: 0.340722
Epoch - 4, step #000006/000058	Loss: 0.389125
Epoch - 4, step #000007/000058	Loss: 0.380249
Epoch - 4, step #000008/000058	Loss: 0.372114
Epoch - 4, step #000009/000058	Loss: 0.346077
Epoch - 4, step #000010/000058	Loss: 0.369000
Epoch - 4, step #000011/000058	Loss: 0.409192
Epoch - 4, step #000012/000058	Loss: 0.400879
Epoch - 4, step #000013/000058	Loss: 0.368033
Epoch - 4, step #000014/000058	Loss: 0.401825
Epoch - 4, step #000015/000058	Loss: 0.373133
Epoch - 4, step #000016/000058	Loss: 0.318447
Epoch - 4, step #000017/000058	Loss: 0.356813
Epoch - 4, step #000018/000058	Loss: 0.393410
Epoch - 4, step #000019/000058	Loss: 0.391524
Epoch - 4, step #000020/000058	Loss: 0.384150
Epoch - 4, step #000021/000058	Loss: 0.337265
Epoch - 4, step #000022/000058	Loss: 0.324985
Epoch - 4, step #000023/000058	Loss: 0.314002
Epoch - 4, step #000024/000058	Loss: 0.322859
Epoch - 4, step #000025/000058	Loss: 0.356040
Epoch - 4, step #000026/000058	Loss: 0.375046
Epoch - 4, step #000027/000058	Loss: 0.310060
Epoch - 4, step #000028/000058	Loss: 0.357183
Epoch - 4, step #000029/000058	Loss: 0.331117
Epoch - 4, step #000030/000058	Loss: 0.354482
Epoch - 4, step #000031/000058	Loss: 0.303293
Epoch - 4, step #000032/000058	Loss: 0.339487
Epoch - 4, step #000033/000058	Loss: 0.360268
Epoch - 4, step #000034/000058	Loss: 0.365528
Epoch - 4, step #000035/000058	Loss: 0.389771
Epoch - 4, step #000036/000058	Loss: 0.354732
Epoch - 4, step #000037/000058	Loss: 0.370988
Epoch - 4, step #000038/000058	Loss: 0.322538
Epoch - 4, step #000039/000058	Loss: 0.362836
Epoch - 4, step #000040/000058	Loss: 0.378506
Epoch - 4, step #000041/000058	Loss: 0.377484
Epoch - 4, step #000042/000058	Loss: 0.378975
Epoch - 4, step #000043/000058	Loss: 0.387742
Epoch - 4, step #000044/000058	Loss: 0.356990
Epoch - 4, step #000045/000058	Loss: 0.349105
Epoch - 4, step #000046/000058	Loss: 0.363348
Epoch - 4, step #000047/000058	Loss: 0.389453
Epoch - 4, step #000048/000058	Loss: 0.311544
Epoch - 4, step #000049/000058	Loss: 0.333838
Epoch - 4, step #000050/000058	Loss: 0.384326
Epoch - 4, step #000051/000058	Loss: 0.357870
Epoch - 4, step #000052/000058	Loss: 0.313874
Epoch - 4, step #000053/000058	Loss: 0.300292
Epoch - 4, step #000054/000058	Loss: 0.349754
Epoch - 4, step #000055/000058	Loss: 0.326995
Epoch - 4, step #000056/000058	Loss: 0.347566
Epoch - 4, step #000057/000058	Loss: 0.388689
E[4], train Loss: 0.359562, training Acc: 0.891, val loss: 0.256, val Acc: 0.924	 Time: 3.358 seconds
E[4], train Loss: 0.359562, training Acc: 0.891, val loss: 0.250, val Acc: 0.923	 Time: 3.359 seconds
E[4], train Loss: 0.359562, training Acc: 0.891, val loss: 0.255, val Acc: 0.925	 Time: 3.361 seconds
E[4], train Loss: 0.359562, training Acc: 0.891, val loss: 0.247, val Acc: 0.925	 Time: 3.355 seconds
Epoch - 5, step #000000/000058	Loss: 0.339554
Epoch - 5, step #000001/000058	Loss: 0.323705
Epoch - 5, step #000002/000058	Loss: 0.347011
Epoch - 5, step #000003/000058	Loss: 0.282848
Epoch - 5, step #000004/000058	Loss: 0.375529
Epoch - 5, step #000005/000058	Loss: 0.346047
Epoch - 5, step #000006/000058	Loss: 0.341856
Epoch - 5, step #000007/000058	Loss: 0.305831
Epoch - 5, step #000008/000058	Loss: 0.333120
Epoch - 5, step #000009/000058	Loss: 0.330892
Epoch - 5, step #000010/000058	Loss: 0.342282
Epoch - 5, step #000011/000058	Loss: 0.343398
Epoch - 5, step #000012/000058	Loss: 0.335920
Epoch - 5, step #000013/000058	Loss: 0.369426
Epoch - 5, step #000014/000058	Loss: 0.358601
Epoch - 5, step #000015/000058	Loss: 0.356536
Epoch - 5, step #000016/000058	Loss: 0.324659
Epoch - 5, step #000017/000058	Loss: 0.281399
Epoch - 5, step #000018/000058	Loss: 0.339942
Epoch - 5, step #000019/000058	Loss: 0.271210
Epoch - 5, step #000020/000058	Loss: 0.314764
Epoch - 5, step #000021/000058	Loss: 0.304752
Epoch - 5, step #000022/000058	Loss: 0.296210
Epoch - 5, step #000023/000058	Loss: 0.354798
Epoch - 5, step #000024/000058	Loss: 0.289777
Epoch - 5, step #000025/000058	Loss: 0.335621
Epoch - 5, step #000026/000058	Loss: 0.305823
Epoch - 5, step #000027/000058	Loss: 0.314579
Epoch - 5, step #000028/000058	Loss: 0.309029
Epoch - 5, step #000029/000058	Loss: 0.287923
Epoch - 5, step #000030/000058	Loss: 0.319930
Epoch - 5, step #000031/000058	Loss: 0.304786
Epoch - 5, step #000032/000058	Loss: 0.304124
Epoch - 5, step #000033/000058	Loss: 0.262910
Epoch - 5, step #000034/000058	Loss: 0.294547
Epoch - 5, step #000035/000058	Loss: 0.303082
Epoch - 5, step #000036/000058	Loss: 0.312986
Epoch - 5, step #000037/000058	Loss: 0.330228
Epoch - 5, step #000038/000058	Loss: 0.342364
Epoch - 5, step #000039/000058	Loss: 0.321413
Epoch - 5, step #000040/000058	Loss: 0.345924
Epoch - 5, step #000041/000058	Loss: 0.328456
Epoch - 5, step #000042/000058	Loss: 0.318416
Epoch - 5, step #000043/000058	Loss: 0.299987
Epoch - 5, step #000044/000058	Loss: 0.301567
Epoch - 5, step #000045/000058	Loss: 0.307229
Epoch - 5, step #000046/000058	Loss: 0.324697
Epoch - 5, step #000047/000058	Loss: 0.324468
Epoch - 5, step #000048/000058	Loss: 0.304745
Epoch - 5, step #000049/000058	Loss: 0.322220
Epoch - 5, step #000050/000058	Loss: 0.292007
Epoch - 5, step #000051/000058	Loss: 0.374112
Epoch - 5, step #000052/000058	Loss: 0.272020
Epoch - 5, step #000053/000058	Loss: 0.309778
Epoch - 5, step #000054/000058	Loss: 0.333075
Epoch - 5, step #000055/000058	Loss: 0.306277
Epoch - 5, step #000056/000058	Loss: 0.331946
Epoch - 5, step #000057/000058	Loss: 0.243823
E[5], train Loss: 0.318968, training Acc: 0.903, val loss: 0.234, val Acc: 0.930	 Time: 3.331 seconds
E[5], train Loss: 0.318968, training Acc: 0.903, val loss: 0.241, val Acc: 0.929	 Time: 3.325 seconds
E[5], train Loss: 0.318968, training Acc: 0.903, val loss: 0.222, val Acc: 0.929	 Time: 3.325 seconds
E[5], train Loss: 0.318968, training Acc: 0.903, val loss: 0.216, val Acc: 0.933	 Time: 3.323 seconds
Epoch - 6, step #000000/000058	Loss: 0.363199
Epoch - 6, step #000001/000058	Loss: 0.273596
Epoch - 6, step #000002/000058	Loss: 0.321311
Epoch - 6, step #000003/000058	Loss: 0.302179
Epoch - 6, step #000004/000058	Loss: 0.292371
Epoch - 6, step #000005/000058	Loss: 0.270039
Epoch - 6, step #000006/000058	Loss: 0.340066
Epoch - 6, step #000007/000058	Loss: 0.273318
Epoch - 6, step #000008/000058	Loss: 0.362498
Epoch - 6, step #000009/000058	Loss: 0.319676
Epoch - 6, step #000010/000058	Loss: 0.310704
Epoch - 6, step #000011/000058	Loss: 0.306483
Epoch - 6, step #000012/000058	Loss: 0.338544
Epoch - 6, step #000013/000058	Loss: 0.304667
Epoch - 6, step #000014/000058	Loss: 0.282152
Epoch - 6, step #000015/000058	Loss: 0.299919
Epoch - 6, step #000016/000058	Loss: 0.291088
Epoch - 6, step #000017/000058	Loss: 0.277391
Epoch - 6, step #000018/000058	Loss: 0.321996
Epoch - 6, step #000019/000058	Loss: 0.339335
Epoch - 6, step #000020/000058	Loss: 0.294424
Epoch - 6, step #000021/000058	Loss: 0.293967
Epoch - 6, step #000022/000058	Loss: 0.293442
Epoch - 6, step #000023/000058	Loss: 0.298071
Epoch - 6, step #000024/000058	Loss: 0.288884
Epoch - 6, step #000025/000058	Loss: 0.308295
Epoch - 6, step #000026/000058	Loss: 0.305163
Epoch - 6, step #000027/000058	Loss: 0.300676
Epoch - 6, step #000028/000058	Loss: 0.313168
Epoch - 6, step #000029/000058	Loss: 0.287029
Epoch - 6, step #000030/000058	Loss: 0.301133
Epoch - 6, step #000031/000058	Loss: 0.308362
Epoch - 6, step #000032/000058	Loss: 0.241804
Epoch - 6, step #000033/000058	Loss: 0.345320
Epoch - 6, step #000034/000058	Loss: 0.295310
Epoch - 6, step #000035/000058	Loss: 0.250041
Epoch - 6, step #000036/000058	Loss: 0.254131
Epoch - 6, step #000037/000058	Loss: 0.275746
Epoch - 6, step #000038/000058	Loss: 0.285614
Epoch - 6, step #000039/000058	Loss: 0.235737
Epoch - 6, step #000040/000058	Loss: 0.253841
Epoch - 6, step #000041/000058	Loss: 0.300608
Epoch - 6, step #000042/000058	Loss: 0.323084
Epoch - 6, step #000043/000058	Loss: 0.291385
Epoch - 6, step #000044/000058	Loss: 0.302676
Epoch - 6, step #000045/000058	Loss: 0.293443
Epoch - 6, step #000046/000058	Loss: 0.281096
Epoch - 6, step #000047/000058	Loss: 0.258237
Epoch - 6, step #000048/000058	Loss: 0.250513
Epoch - 6, step #000049/000058	Loss: 0.259454
Epoch - 6, step #000050/000058	Loss: 0.300777
Epoch - 6, step #000051/000058	Loss: 0.291168
Epoch - 6, step #000052/000058	Loss: 0.289099
Epoch - 6, step #000053/000058	Loss: 0.295595
Epoch - 6, step #000054/000058	Loss: 0.318886
Epoch - 6, step #000055/000058	Loss: 0.287215
Epoch - 6, step #000056/000058	Loss: 0.278168
Epoch - 6, step #000057/000058	Loss: 0.252948
E[6], train Loss: 0.294742, training Acc: 0.911, val loss: 0.224, val Acc: 0.936	 Time: 3.654 seconds
E[6], train Loss: 0.294742, training Acc: 0.911, val loss: 0.204, val Acc: 0.935	 Time: 3.656 seconds
E[6], train Loss: 0.294742, training Acc: 0.911, val loss: 0.229, val Acc: 0.933	 Time: 3.658 seconds
E[6], train Loss: 0.294742, training Acc: 0.911, val loss: 0.198, val Acc: 0.937	 Time: 3.659 seconds
Epoch - 7, step #000000/000058	Loss: 0.294974
Epoch - 7, step #000001/000058	Loss: 0.259461
Epoch - 7, step #000002/000058	Loss: 0.264363
Epoch - 7, step #000003/000058	Loss: 0.298462
Epoch - 7, step #000004/000058	Loss: 0.283724
Epoch - 7, step #000005/000058	Loss: 0.299118
Epoch - 7, step #000006/000058	Loss: 0.276724
Epoch - 7, step #000007/000058	Loss: 0.278690
Epoch - 7, step #000008/000058	Loss: 0.284097
Epoch - 7, step #000009/000058	Loss: 0.224988
Epoch - 7, step #000010/000058	Loss: 0.255599
Epoch - 7, step #000011/000058	Loss: 0.237766
Epoch - 7, step #000012/000058	Loss: 0.293316
Epoch - 7, step #000013/000058	Loss: 0.251696
Epoch - 7, step #000014/000058	Loss: 0.305857
Epoch - 7, step #000015/000058	Loss: 0.345828
Epoch - 7, step #000016/000058	Loss: 0.301144
Epoch - 7, step #000017/000058	Loss: 0.326541
Epoch - 7, step #000018/000058	Loss: 0.282869
Epoch - 7, step #000019/000058	Loss: 0.240672
Epoch - 7, step #000020/000058	Loss: 0.292459
Epoch - 7, step #000021/000058	Loss: 0.268768
Epoch - 7, step #000022/000058	Loss: 0.305194
Epoch - 7, step #000023/000058	Loss: 0.292955
Epoch - 7, step #000024/000058	Loss: 0.295755
Epoch - 7, step #000025/000058	Loss: 0.247578
Epoch - 7, step #000026/000058	Loss: 0.270390
Epoch - 7, step #000027/000058	Loss: 0.231990
Epoch - 7, step #000028/000058	Loss: 0.261010
Epoch - 7, step #000029/000058	Loss: 0.267777
Epoch - 7, step #000030/000058	Loss: 0.224121
Epoch - 7, step #000031/000058	Loss: 0.297866
Epoch - 7, step #000032/000058	Loss: 0.302011
Epoch - 7, step #000033/000058	Loss: 0.270482
Epoch - 7, step #000034/000058	Loss: 0.273883
Epoch - 7, step #000035/000058	Loss: 0.236062
Epoch - 7, step #000036/000058	Loss: 0.274532
Epoch - 7, step #000037/000058	Loss: 0.275237
Epoch - 7, step #000038/000058	Loss: 0.265633
Epoch - 7, step #000039/000058	Loss: 0.273769
Epoch - 7, step #000040/000058	Loss: 0.288951
Epoch - 7, step #000041/000058	Loss: 0.249429
Epoch - 7, step #000042/000058	Loss: 0.324503
Epoch - 7, step #000043/000058	Loss: 0.265219
Epoch - 7, step #000044/000058	Loss: 0.254487
Epoch - 7, step #000045/000058	Loss: 0.236367
Epoch - 7, step #000046/000058	Loss: 0.298279
Epoch - 7, step #000047/000058	Loss: 0.235924
Epoch - 7, step #000048/000058	Loss: 0.265084
Epoch - 7, step #000049/000058	Loss: 0.243080
Epoch - 7, step #000050/000058	Loss: 0.289375
Epoch - 7, step #000051/000058	Loss: 0.252169
Epoch - 7, step #000052/000058	Loss: 0.280241
Epoch - 7, step #000053/000058	Loss: 0.305072
Epoch - 7, step #000054/000058	Loss: 0.226127
Epoch - 7, step #000055/000058	Loss: 0.297561
Epoch - 7, step #000056/000058	Loss: 0.250849
Epoch - 7, step #000057/000058	Loss: 0.297838
E[7], train Loss: 0.274033, training Acc: 0.918, val loss: 0.209, val Acc: 0.939	 Time: 3.347 seconds
E[7], train Loss: 0.274033, training Acc: 0.918, val loss: 0.193, val Acc: 0.940	 Time: 3.346 seconds
E[7], train Loss: 0.274033, training Acc: 0.918, val loss: 0.209, val Acc: 0.937	 Time: 3.349 seconds
E[7], train Loss: 0.274033, training Acc: 0.918, val loss: 0.184, val Acc: 0.943	 Time: 3.348 seconds
Epoch - 8, step #000000/000058	Loss: 0.271142
Epoch - 8, step #000001/000058	Loss: 0.225488
Epoch - 8, step #000002/000058	Loss: 0.298943
Epoch - 8, step #000003/000058	Loss: 0.241791
Epoch - 8, step #000004/000058	Loss: 0.273973
Epoch - 8, step #000005/000058	Loss: 0.309913
Epoch - 8, step #000006/000058	Loss: 0.312225
Epoch - 8, step #000007/000058	Loss: 0.258631
Epoch - 8, step #000008/000058	Loss: 0.235792
Epoch - 8, step #000009/000058	Loss: 0.266511
Epoch - 8, step #000010/000058	Loss: 0.218456
Epoch - 8, step #000011/000058	Loss: 0.225683
Epoch - 8, step #000012/000058	Loss: 0.309652
Epoch - 8, step #000013/000058	Loss: 0.314824
Epoch - 8, step #000014/000058	Loss: 0.233362
Epoch - 8, step #000015/000058	Loss: 0.284248
Epoch - 8, step #000016/000058	Loss: 0.262369
Epoch - 8, step #000017/000058	Loss: 0.240853
Epoch - 8, step #000018/000058	Loss: 0.278966
Epoch - 8, step #000019/000058	Loss: 0.244561
Epoch - 8, step #000020/000058	Loss: 0.187212
Epoch - 8, step #000021/000058	Loss: 0.296977
Epoch - 8, step #000022/000058	Loss: 0.250358
Epoch - 8, step #000023/000058	Loss: 0.270864
Epoch - 8, step #000024/000058	Loss: 0.276078
Epoch - 8, step #000025/000058	Loss: 0.246980
Epoch - 8, step #000026/000058	Loss: 0.239349
Epoch - 8, step #000027/000058	Loss: 0.266849
Epoch - 8, step #000028/000058	Loss: 0.282064
Epoch - 8, step #000029/000058	Loss: 0.261982
Epoch - 8, step #000030/000058	Loss: 0.242847
Epoch - 8, step #000031/000058	Loss: 0.250925
Epoch - 8, step #000032/000058	Loss: 0.243169
Epoch - 8, step #000033/000058	Loss: 0.253200
Epoch - 8, step #000034/000058	Loss: 0.230092
Epoch - 8, step #000035/000058	Loss: 0.257234
Epoch - 8, step #000036/000058	Loss: 0.286742
Epoch - 8, step #000037/000058	Loss: 0.211377
Epoch - 8, step #000038/000058	Loss: 0.213244
Epoch - 8, step #000039/000058	Loss: 0.261263
Epoch - 8, step #000040/000058	Loss: 0.245883
Epoch - 8, step #000041/000058	Loss: 0.248770
Epoch - 8, step #000042/000058	Loss: 0.217003
Epoch - 8, step #000043/000058	Loss: 0.241814
Epoch - 8, step #000044/000058	Loss: 0.237115
Epoch - 8, step #000045/000058	Loss: 0.234251
Epoch - 8, step #000046/000058	Loss: 0.226965
Epoch - 8, step #000047/000058	Loss: 0.298897
Epoch - 8, step #000048/000058	Loss: 0.225619
Epoch - 8, step #000049/000058	Loss: 0.262054
Epoch - 8, step #000050/000058	Loss: 0.229398
Epoch - 8, step #000051/000058	Loss: 0.238449
Epoch - 8, step #000052/000058	Loss: 0.201791
Epoch - 8, step #000053/000058	Loss: 0.286417
Epoch - 8, step #000054/000058	Loss: 0.251668
Epoch - 8, step #000055/000058	Loss: 0.214708
Epoch - 8, step #000056/000058	Loss: 0.248754
Epoch - 8, step #000057/000058	Loss: 0.313299
E[8], train Loss: 0.254466, training Acc: 0.923, val loss: 0.197, val Acc: 0.941	 Time: 3.332 seconds
E[8], train Loss: 0.254466, training Acc: 0.923, val loss: 0.196, val Acc: 0.943	 Time: 3.337 seconds
E[8], train Loss: 0.254466, training Acc: 0.923, val loss: 0.170, val Acc: 0.947	 Time: 3.336 seconds
E[8], train Loss: 0.254466, training Acc: 0.923, val loss: 0.161, val Acc: 0.950	 Time: 3.332 seconds
Epoch - 9, step #000000/000058	Loss: 0.227782
Epoch - 9, step #000001/000058	Loss: 0.258573
Epoch - 9, step #000002/000058	Loss: 0.226412
Epoch - 9, step #000003/000058	Loss: 0.227141
Epoch - 9, step #000004/000058	Loss: 0.212917
Epoch - 9, step #000005/000058	Loss: 0.248594
Epoch - 9, step #000006/000058	Loss: 0.283389
Epoch - 9, step #000007/000058	Loss: 0.223532
Epoch - 9, step #000008/000058	Loss: 0.233845
Epoch - 9, step #000009/000058	Loss: 0.303732
Epoch - 9, step #000010/000058	Loss: 0.300123
Epoch - 9, step #000011/000058	Loss: 0.219009
Epoch - 9, step #000012/000058	Loss: 0.220187
Epoch - 9, step #000013/000058	Loss: 0.242706
Epoch - 9, step #000014/000058	Loss: 0.241164
Epoch - 9, step #000015/000058	Loss: 0.241798
Epoch - 9, step #000016/000058	Loss: 0.254914
Epoch - 9, step #000017/000058	Loss: 0.269517
Epoch - 9, step #000018/000058	Loss: 0.210669
Epoch - 9, step #000019/000058	Loss: 0.232499
Epoch - 9, step #000020/000058	Loss: 0.237489
Epoch - 9, step #000021/000058	Loss: 0.268633
Epoch - 9, step #000022/000058	Loss: 0.264187
Epoch - 9, step #000023/000058	Loss: 0.198653
Epoch - 9, step #000024/000058	Loss: 0.231244
Epoch - 9, step #000025/000058	Loss: 0.240914
Epoch - 9, step #000026/000058	Loss: 0.237560
Epoch - 9, step #000027/000058	Loss: 0.220479
Epoch - 9, step #000028/000058	Loss: 0.252947
Epoch - 9, step #000029/000058	Loss: 0.240632
Epoch - 9, step #000030/000058	Loss: 0.217662
Epoch - 9, step #000031/000058	Loss: 0.218351
Epoch - 9, step #000032/000058	Loss: 0.207599
Epoch - 9, step #000033/000058	Loss: 0.258215
Epoch - 9, step #000034/000058	Loss: 0.246391
Epoch - 9, step #000035/000058	Loss: 0.230632
Epoch - 9, step #000036/000058	Loss: 0.229520
Epoch - 9, step #000037/000058	Loss: 0.264368
Epoch - 9, step #000038/000058	Loss: 0.228464
Epoch - 9, step #000039/000058	Loss: 0.241552
Epoch - 9, step #000040/000058	Loss: 0.262040
Epoch - 9, step #000041/000058	Loss: 0.247263
Epoch - 9, step #000042/000058	Loss: 0.179427
Epoch - 9, step #000043/000058	Loss: 0.248541
Epoch - 9, step #000044/000058	Loss: 0.198631
Epoch - 9, step #000045/000058	Loss: 0.205584
Epoch - 9, step #000046/000058	Loss: 0.214231
Epoch - 9, step #000047/000058	Loss: 0.234464
Epoch - 9, step #000048/000058	Loss: 0.242361
Epoch - 9, step #000049/000058	Loss: 0.230130
Epoch - 9, step #000050/000058	Loss: 0.246398
Epoch - 9, step #000051/000058	Loss: 0.246650
Epoch - 9, step #000052/000058	Loss: 0.210213
Epoch - 9, step #000053/000058	Loss: 0.204480
Epoch - 9, step #000054/000058	Loss: 0.262821
Epoch - 9, step #000055/000058	Loss: 0.207301
Epoch - 9, step #000056/000058	Loss: 0.212693
Epoch - 9, step #000057/000058	Loss: 0.211239
E[9], train Loss: 0.235835, training Acc: 0.928, val loss: 0.186, val Acc: 0.947	 Time: 3.330 seconds
E[9], train Loss: 0.235835, training Acc: 0.928, val loss: 0.188, val Acc: 0.944	 Time: 3.336 seconds
E[9], train Loss: 0.235835, training Acc: 0.928, val loss: 0.149, val Acc: 0.953	 Time: 3.336 seconds
E[9], train Loss: 0.235835, training Acc: 0.928, val loss: 0.151, val Acc: 0.953	 Time: 3.336 seconds
Epoch - 10, step #000000/000058	Loss: 0.178697
Epoch - 10, step #000001/000058	Loss: 0.197011
Epoch - 10, step #000002/000058	Loss: 0.218906
Epoch - 10, step #000003/000058	Loss: 0.223156
Epoch - 10, step #000004/000058	Loss: 0.228539
Epoch - 10, step #000005/000058	Loss: 0.217855
Epoch - 10, step #000006/000058	Loss: 0.203650
Epoch - 10, step #000007/000058	Loss: 0.193943
Epoch - 10, step #000008/000058	Loss: 0.265767
Epoch - 10, step #000009/000058	Loss: 0.242119
Epoch - 10, step #000010/000058	Loss: 0.215393
Epoch - 10, step #000011/000058	Loss: 0.262189
Epoch - 10, step #000012/000058	Loss: 0.199203
Epoch - 10, step #000013/000058	Loss: 0.217812
Epoch - 10, step #000014/000058	Loss: 0.263713
Epoch - 10, step #000015/000058	Loss: 0.231572
Epoch - 10, step #000016/000058	Loss: 0.212711
Epoch - 10, step #000017/000058	Loss: 0.214086
Epoch - 10, step #000018/000058	Loss: 0.244784
Epoch - 10, step #000019/000058	Loss: 0.259134
Epoch - 10, step #000020/000058	Loss: 0.224351
Epoch - 10, step #000021/000058	Loss: 0.244818
Epoch - 10, step #000022/000058	Loss: 0.209407
Epoch - 10, step #000023/000058	Loss: 0.209737
Epoch - 10, step #000024/000058	Loss: 0.282335
Epoch - 10, step #000025/000058	Loss: 0.208476
Epoch - 10, step #000026/000058	Loss: 0.206125
Epoch - 10, step #000027/000058	Loss: 0.200661
Epoch - 10, step #000028/000058	Loss: 0.214391
Epoch - 10, step #000029/000058	Loss: 0.219363
Epoch - 10, step #000030/000058	Loss: 0.219706
Epoch - 10, step #000031/000058	Loss: 0.166049
Epoch - 10, step #000032/000058	Loss: 0.177500
Epoch - 10, step #000033/000058	Loss: 0.202625
Epoch - 10, step #000034/000058	Loss: 0.182150
Epoch - 10, step #000035/000058	Loss: 0.248010
Epoch - 10, step #000036/000058	Loss: 0.206116
Epoch - 10, step #000037/000058	Loss: 0.215977
Epoch - 10, step #000038/000058	Loss: 0.231921
Epoch - 10, step #000039/000058	Loss: 0.225174
Epoch - 10, step #000040/000058	Loss: 0.202815
Epoch - 10, step #000041/000058	Loss: 0.201436
Epoch - 10, step #000042/000058	Loss: 0.194004
Epoch - 10, step #000043/000058	Loss: 0.210279
Epoch - 10, step #000044/000058	Loss: 0.214528
Epoch - 10, step #000045/000058	Loss: 0.231110
Epoch - 10, step #000046/000058	Loss: 0.199340
Epoch - 10, step #000047/000058	Loss: 0.281911
Epoch - 10, step #000048/000058	Loss: 0.181275
Epoch - 10, step #000049/000058	Loss: 0.209335
Epoch - 10, step #000050/000058	Loss: 0.218105
Epoch - 10, step #000051/000058	Loss: 0.213984
Epoch - 10, step #000052/000058	Loss: 0.186034
Epoch - 10, step #000053/000058	Loss: 0.211030
Epoch - 10, step #000054/000058	Loss: 0.187442
Epoch - 10, step #000055/000058	Loss: 0.192490
Epoch - 10, step #000056/000058	Loss: 0.214378
Epoch - 10, step #000057/000058	Loss: 0.200467
E[10], train Loss: 0.216122, training Acc: 0.933, val loss: 0.171, val Acc: 0.950	 Time: 3.336 seconds
E[10], train Loss: 0.216122, training Acc: 0.933, val loss: 0.145, val Acc: 0.954	 Time: 3.335 seconds
E[10], train Loss: 0.216122, training Acc: 0.933, val loss: 0.166, val Acc: 0.950	 Time: 3.337 seconds
E[10], train Loss: 0.216122, training Acc: 0.933, val loss: 0.135, val Acc: 0.957	 Time: 3.341 seconds
Epoch - 11, step #000000/000058	Loss: 0.199214
Epoch - 11, step #000001/000058	Loss: 0.177152
Epoch - 11, step #000002/000058	Loss: 0.209316
Epoch - 11, step #000003/000058	Loss: 0.210844
Epoch - 11, step #000004/000058	Loss: 0.211974
Epoch - 11, step #000005/000058	Loss: 0.231918
Epoch - 11, step #000006/000058	Loss: 0.178332
Epoch - 11, step #000007/000058	Loss: 0.208880
Epoch - 11, step #000008/000058	Loss: 0.208841
Epoch - 11, step #000009/000058	Loss: 0.230013
Epoch - 11, step #000010/000058	Loss: 0.221803
Epoch - 11, step #000011/000058	Loss: 0.217819
Epoch - 11, step #000012/000058	Loss: 0.188040
Epoch - 11, step #000013/000058	Loss: 0.206424
Epoch - 11, step #000014/000058	Loss: 0.178788
Epoch - 11, step #000015/000058	Loss: 0.233062
Epoch - 11, step #000016/000058	Loss: 0.234668
Epoch - 11, step #000017/000058	Loss: 0.193382
Epoch - 11, step #000018/000058	Loss: 0.198741
Epoch - 11, step #000019/000058	Loss: 0.184392
Epoch - 11, step #000020/000058	Loss: 0.221110
Epoch - 11, step #000021/000058	Loss: 0.179323
Epoch - 11, step #000022/000058	Loss: 0.204323
Epoch - 11, step #000023/000058	Loss: 0.244094
Epoch - 11, step #000024/000058	Loss: 0.214515
Epoch - 11, step #000025/000058	Loss: 0.224158
Epoch - 11, step #000026/000058	Loss: 0.148469
Epoch - 11, step #000027/000058	Loss: 0.213037
Epoch - 11, step #000028/000058	Loss: 0.207656
Epoch - 11, step #000029/000058	Loss: 0.185715
Epoch - 11, step #000030/000058	Loss: 0.234727
Epoch - 11, step #000031/000058	Loss: 0.169566
Epoch - 11, step #000032/000058	Loss: 0.237404
Epoch - 11, step #000033/000058	Loss: 0.162715
Epoch - 11, step #000034/000058	Loss: 0.166645
Epoch - 11, step #000035/000058	Loss: 0.175231
Epoch - 11, step #000036/000058	Loss: 0.200996
Epoch - 11, step #000037/000058	Loss: 0.184429
Epoch - 11, step #000038/000058	Loss: 0.196417
Epoch - 11, step #000039/000058	Loss: 0.190817
Epoch - 11, step #000040/000058	Loss: 0.207563
Epoch - 11, step #000041/000058	Loss: 0.180216
Epoch - 11, step #000042/000058	Loss: 0.201554
Epoch - 11, step #000043/000058	Loss: 0.199478
Epoch - 11, step #000044/000058	Loss: 0.190041
Epoch - 11, step #000045/000058	Loss: 0.179408
Epoch - 11, step #000046/000058	Loss: 0.197340
Epoch - 11, step #000047/000058	Loss: 0.186557
Epoch - 11, step #000048/000058	Loss: 0.186127
Epoch - 11, step #000049/000058	Loss: 0.199319
Epoch - 11, step #000050/000058	Loss: 0.230475
Epoch - 11, step #000051/000058	Loss: 0.190730
Epoch - 11, step #000052/000058	Loss: 0.182276
Epoch - 11, step #000053/000058	Loss: 0.214111
Epoch - 11, step #000054/000058	Loss: 0.259639
Epoch - 11, step #000055/000058	Loss: 0.167135
Epoch - 11, step #000056/000058	Loss: 0.221599
Epoch - 11, step #000057/000058	Loss: 0.188821
E[11], train Loss: 0.201161, training Acc: 0.938, val loss: 0.161, val Acc: 0.953	 Time: 3.312 seconds
E[11], train Loss: 0.201161, training Acc: 0.938, val loss: 0.164, val Acc: 0.952	 Time: 3.321 seconds
E[11], train Loss: 0.201161, training Acc: 0.938, val loss: 0.130, val Acc: 0.960	 Time: 3.322 seconds
E[11], train Loss: 0.201161, training Acc: 0.938, val loss: 0.129, val Acc: 0.960	 Time: 3.313 seconds
Epoch - 12, step #000000/000058	Loss: 0.159948
Epoch - 12, step #000001/000058	Loss: 0.201753
Epoch - 12, step #000002/000058	Loss: 0.188576
Epoch - 12, step #000003/000058	Loss: 0.204278
Epoch - 12, step #000004/000058	Loss: 0.224207
Epoch - 12, step #000005/000058	Loss: 0.257468
Epoch - 12, step #000006/000058	Loss: 0.194244
Epoch - 12, step #000007/000058	Loss: 0.199365
Epoch - 12, step #000008/000058	Loss: 0.222024
Epoch - 12, step #000009/000058	Loss: 0.193461
Epoch - 12, step #000010/000058	Loss: 0.222422
Epoch - 12, step #000011/000058	Loss: 0.199222
Epoch - 12, step #000012/000058	Loss: 0.173772
Epoch - 12, step #000013/000058	Loss: 0.223512
Epoch - 12, step #000014/000058	Loss: 0.216577
Epoch - 12, step #000015/000058	Loss: 0.158779
Epoch - 12, step #000016/000058	Loss: 0.157368
Epoch - 12, step #000017/000058	Loss: 0.205712
Epoch - 12, step #000018/000058	Loss: 0.174015
Epoch - 12, step #000019/000058	Loss: 0.231018
Epoch - 12, step #000020/000058	Loss: 0.188130
Epoch - 12, step #000021/000058	Loss: 0.189664
Epoch - 12, step #000022/000058	Loss: 0.164012
Epoch - 12, step #000023/000058	Loss: 0.179913
Epoch - 12, step #000024/000058	Loss: 0.184017
Epoch - 12, step #000025/000058	Loss: 0.216254
Epoch - 12, step #000026/000058	Loss: 0.215904
Epoch - 12, step #000027/000058	Loss: 0.176815
Epoch - 12, step #000028/000058	Loss: 0.167193
Epoch - 12, step #000029/000058	Loss: 0.199616
Epoch - 12, step #000030/000058	Loss: 0.189215
Epoch - 12, step #000031/000058	Loss: 0.207728
Epoch - 12, step #000032/000058	Loss: 0.201114
Epoch - 12, step #000033/000058	Loss: 0.183785
Epoch - 12, step #000034/000058	Loss: 0.177593
Epoch - 12, step #000035/000058	Loss: 0.199151
Epoch - 12, step #000036/000058	Loss: 0.178562
Epoch - 12, step #000037/000058	Loss: 0.165072
Epoch - 12, step #000038/000058	Loss: 0.200034
Epoch - 12, step #000039/000058	Loss: 0.163914
Epoch - 12, step #000040/000058	Loss: 0.181801
Epoch - 12, step #000041/000058	Loss: 0.176468
Epoch - 12, step #000042/000058	Loss: 0.166867
Epoch - 12, step #000043/000058	Loss: 0.130521
Epoch - 12, step #000044/000058	Loss: 0.163960
Epoch - 12, step #000045/000058	Loss: 0.205199
Epoch - 12, step #000046/000058	Loss: 0.183003
Epoch - 12, step #000047/000058	Loss: 0.143670
Epoch - 12, step #000048/000058	Loss: 0.189410
Epoch - 12, step #000049/000058	Loss: 0.153136
Epoch - 12, step #000050/000058	Loss: 0.176907
Epoch - 12, step #000051/000058	Loss: 0.172799
Epoch - 12, step #000052/000058	Loss: 0.177301
Epoch - 12, step #000053/000058	Loss: 0.188243
Epoch - 12, step #000054/000058	Loss: 0.190796
Epoch - 12, step #000055/000058	Loss: 0.188505
Epoch - 12, step #000056/000058	Loss: 0.151037
Epoch - 12, step #000057/000058	Loss: 0.224095
E[12], train Loss: 0.188261, training Acc: 0.943, val loss: 0.154, val Acc: 0.957	 Time: 3.359 seconds
E[12], train Loss: 0.188261, training Acc: 0.943, val loss: 0.153, val Acc: 0.954	 Time: 3.362 seconds
E[12], train Loss: 0.188261, training Acc: 0.943, val loss: 0.118, val Acc: 0.964	 Time: 3.357 seconds
E[12], train Loss: 0.188261, training Acc: 0.943, val loss: 0.115, val Acc: 0.962	 Time: 3.362 seconds
Epoch - 13, step #000000/000058	Loss: 0.171123
Epoch - 13, step #000001/000058	Loss: 0.195962
Epoch - 13, step #000002/000058	Loss: 0.183474
Epoch - 13, step #000003/000058	Loss: 0.194825
Epoch - 13, step #000004/000058	Loss: 0.159293
Epoch - 13, step #000005/000058	Loss: 0.170023
Epoch - 13, step #000006/000058	Loss: 0.185863
Epoch - 13, step #000007/000058	Loss: 0.173402
Epoch - 13, step #000008/000058	Loss: 0.203756
Epoch - 13, step #000009/000058	Loss: 0.178268
Epoch - 13, step #000010/000058	Loss: 0.181089
Epoch - 13, step #000011/000058	Loss: 0.183635
Epoch - 13, step #000012/000058	Loss: 0.173823
Epoch - 13, step #000013/000058	Loss: 0.168029
Epoch - 13, step #000014/000058	Loss: 0.206830
Epoch - 13, step #000015/000058	Loss: 0.171833
Epoch - 13, step #000016/000058	Loss: 0.167072
Epoch - 13, step #000017/000058	Loss: 0.183430
Epoch - 13, step #000018/000058	Loss: 0.201403
Epoch - 13, step #000019/000058	Loss: 0.176061
Epoch - 13, step #000020/000058	Loss: 0.194599
Epoch - 13, step #000021/000058	Loss: 0.177499
Epoch - 13, step #000022/000058	Loss: 0.159222
Epoch - 13, step #000023/000058	Loss: 0.156328
Epoch - 13, step #000024/000058	Loss: 0.236612
Epoch - 13, step #000025/000058	Loss: 0.185639
Epoch - 13, step #000026/000058	Loss: 0.186861
Epoch - 13, step #000027/000058	Loss: 0.156391
Epoch - 13, step #000028/000058	Loss: 0.201660
Epoch - 13, step #000029/000058	Loss: 0.234640
Epoch - 13, step #000030/000058	Loss: 0.179752
Epoch - 13, step #000031/000058	Loss: 0.165321
Epoch - 13, step #000032/000058	Loss: 0.183869
Epoch - 13, step #000033/000058	Loss: 0.169622
Epoch - 13, step #000034/000058	Loss: 0.172807
Epoch - 13, step #000035/000058	Loss: 0.178641
Epoch - 13, step #000036/000058	Loss: 0.170076
Epoch - 13, step #000037/000058	Loss: 0.215243
Epoch - 13, step #000038/000058	Loss: 0.162747
Epoch - 13, step #000039/000058	Loss: 0.162370
Epoch - 13, step #000040/000058	Loss: 0.184872
Epoch - 13, step #000041/000058	Loss: 0.168655
Epoch - 13, step #000042/000058	Loss: 0.171312
Epoch - 13, step #000043/000058	Loss: 0.174623
Epoch - 13, step #000044/000058	Loss: 0.158385
Epoch - 13, step #000045/000058	Loss: 0.218228
Epoch - 13, step #000046/000058	Loss: 0.140998
Epoch - 13, step #000047/000058	Loss: 0.172036
Epoch - 13, step #000048/000058	Loss: 0.126204
Epoch - 13, step #000049/000058	Loss: 0.146001
Epoch - 13, step #000050/000058	Loss: 0.177632
Epoch - 13, step #000051/000058	Loss: 0.197778
Epoch - 13, step #000052/000058	Loss: 0.165274
Epoch - 13, step #000053/000058	Loss: 0.146788
Epoch - 13, step #000054/000058	Loss: 0.206969
Epoch - 13, step #000055/000058	Loss: 0.189868
Epoch - 13, step #000056/000058	Loss: 0.172886
Epoch - 13, step #000057/000058	Loss: 0.203161
E[13], train Loss: 0.179324, training Acc: 0.945, val loss: 0.152, val Acc: 0.955	 Time: 3.388 seconds
E[13], train Loss: 0.179324, training Acc: 0.945, val loss: 0.153, val Acc: 0.954	 Time: 3.388 seconds
E[13], train Loss: 0.179324, training Acc: 0.945, val loss: 0.108, val Acc: 0.966	 Time: 3.390 seconds
E[13], train Loss: 0.179324, training Acc: 0.945, val loss: 0.108, val Acc: 0.966	 Time: 3.391 seconds
Epoch - 14, step #000000/000058	Loss: 0.171076
Epoch - 14, step #000001/000058	Loss: 0.156926
Epoch - 14, step #000002/000058	Loss: 0.196139
Epoch - 14, step #000003/000058	Loss: 0.157551
Epoch - 14, step #000004/000058	Loss: 0.175199
Epoch - 14, step #000005/000058	Loss: 0.176489
Epoch - 14, step #000006/000058	Loss: 0.166491
Epoch - 14, step #000007/000058	Loss: 0.182087
Epoch - 14, step #000008/000058	Loss: 0.164718
Epoch - 14, step #000009/000058	Loss: 0.158257
Epoch - 14, step #000010/000058	Loss: 0.185212
Epoch - 14, step #000011/000058	Loss: 0.189383
Epoch - 14, step #000012/000058	Loss: 0.140748
Epoch - 14, step #000013/000058	Loss: 0.164689
Epoch - 14, step #000014/000058	Loss: 0.161764
Epoch - 14, step #000015/000058	Loss: 0.141788
Epoch - 14, step #000016/000058	Loss: 0.189536
Epoch - 14, step #000017/000058	Loss: 0.182486
Epoch - 14, step #000018/000058	Loss: 0.200857
Epoch - 14, step #000019/000058	Loss: 0.152221
Epoch - 14, step #000020/000058	Loss: 0.176980
Epoch - 14, step #000021/000058	Loss: 0.168424
Epoch - 14, step #000022/000058	Loss: 0.166287
Epoch - 14, step #000023/000058	Loss: 0.168804
Epoch - 14, step #000024/000058	Loss: 0.185754
Epoch - 14, step #000025/000058	Loss: 0.188374
Epoch - 14, step #000026/000058	Loss: 0.186480
Epoch - 14, step #000027/000058	Loss: 0.176819
Epoch - 14, step #000028/000058	Loss: 0.157958
Epoch - 14, step #000029/000058	Loss: 0.168418
Epoch - 14, step #000030/000058	Loss: 0.125015
Epoch - 14, step #000031/000058	Loss: 0.167997
Epoch - 14, step #000032/000058	Loss: 0.173903
Epoch - 14, step #000033/000058	Loss: 0.132725
Epoch - 14, step #000034/000058	Loss: 0.214086
Epoch - 14, step #000035/000058	Loss: 0.128944
Epoch - 14, step #000036/000058	Loss: 0.175490
Epoch - 14, step #000037/000058	Loss: 0.199639
Epoch - 14, step #000038/000058	Loss: 0.166012
Epoch - 14, step #000039/000058	Loss: 0.139956
Epoch - 14, step #000040/000058	Loss: 0.149136
Epoch - 14, step #000041/000058	Loss: 0.181683
Epoch - 14, step #000042/000058	Loss: 0.172548
Epoch - 14, step #000043/000058	Loss: 0.160467
Epoch - 14, step #000044/000058	Loss: 0.169789
Epoch - 14, step #000045/000058	Loss: 0.148455
Epoch - 14, step #000046/000058	Loss: 0.154692
Epoch - 14, step #000047/000058	Loss: 0.193763
Epoch - 14, step #000048/000058	Loss: 0.157721
Epoch - 14, step #000049/000058	Loss: 0.141175
Epoch - 14, step #000050/000058	Loss: 0.113407
Epoch - 14, step #000051/000058	Loss: 0.178310
Epoch - 14, step #000052/000058	Loss: 0.161259
Epoch - 14, step #000053/000058	Loss: 0.168795
Epoch - 14, step #000054/000058	Loss: 0.178393
Epoch - 14, step #000055/000058	Loss: 0.148119
Epoch - 14, step #000056/000058	Loss: 0.181562
Epoch - 14, step #000057/000058	Loss: 0.163375
E[14], train Loss: 0.167316, training Acc: 0.949, val loss: 0.107, val Acc: 0.967	 Time: 3.325 seconds
E[14], train Loss: 0.167316, training Acc: 0.949, val loss: 0.139, val Acc: 0.959	 Time: 3.332 seconds
E[14], train Loss: 0.167316, training Acc: 0.949, val loss: 0.138, val Acc: 0.959	 Time: 3.334 seconds
E[14], train Loss: 0.167316, training Acc: 0.949, val loss: 0.106, val Acc: 0.966	 Time: 3.328 seconds
Epoch - 15, step #000000/000058	Loss: 0.127680
Epoch - 15, step #000001/000058	Loss: 0.157100
Epoch - 15, step #000002/000058	Loss: 0.162739
Epoch - 15, step #000003/000058	Loss: 0.140960
Epoch - 15, step #000004/000058	Loss: 0.173533
Epoch - 15, step #000005/000058	Loss: 0.141414
Epoch - 15, step #000006/000058	Loss: 0.168142
Epoch - 15, step #000007/000058	Loss: 0.137799
Epoch - 15, step #000008/000058	Loss: 0.184535
Epoch - 15, step #000009/000058	Loss: 0.188539
Epoch - 15, step #000010/000058	Loss: 0.150394
Epoch - 15, step #000011/000058	Loss: 0.210671
Epoch - 15, step #000012/000058	Loss: 0.147953
Epoch - 15, step #000013/000058	Loss: 0.173240
Epoch - 15, step #000014/000058	Loss: 0.192541
Epoch - 15, step #000015/000058	Loss: 0.166169
Epoch - 15, step #000016/000058	Loss: 0.148004
Epoch - 15, step #000017/000058	Loss: 0.182117
Epoch - 15, step #000018/000058	Loss: 0.153372
Epoch - 15, step #000019/000058	Loss: 0.217513
Epoch - 15, step #000020/000058	Loss: 0.182036
Epoch - 15, step #000021/000058	Loss: 0.170546
Epoch - 15, step #000022/000058	Loss: 0.139695
Epoch - 15, step #000023/000058	Loss: 0.194562
Epoch - 15, step #000024/000058	Loss: 0.166130
Epoch - 15, step #000025/000058	Loss: 0.174440
Epoch - 15, step #000026/000058	Loss: 0.179955
Epoch - 15, step #000027/000058	Loss: 0.140011
Epoch - 15, step #000028/000058	Loss: 0.157750
Epoch - 15, step #000029/000058	Loss: 0.162507
Epoch - 15, step #000030/000058	Loss: 0.157592
Epoch - 15, step #000031/000058	Loss: 0.161746
Epoch - 15, step #000032/000058	Loss: 0.118807
Epoch - 15, step #000033/000058	Loss: 0.153327
Epoch - 15, step #000034/000058	Loss: 0.111248
Epoch - 15, step #000035/000058	Loss: 0.163295
Epoch - 15, step #000036/000058	Loss: 0.178570
Epoch - 15, step #000037/000058	Loss: 0.140921
Epoch - 15, step #000038/000058	Loss: 0.141384
Epoch - 15, step #000039/000058	Loss: 0.145514
Epoch - 15, step #000040/000058	Loss: 0.141735
Epoch - 15, step #000041/000058	Loss: 0.153051
Epoch - 15, step #000042/000058	Loss: 0.126491
Epoch - 15, step #000043/000058	Loss: 0.165279
Epoch - 15, step #000044/000058	Loss: 0.184343
Epoch - 15, step #000045/000058	Loss: 0.126083
Epoch - 15, step #000046/000058	Loss: 0.168142
Epoch - 15, step #000047/000058	Loss: 0.161200
Epoch - 15, step #000048/000058	Loss: 0.146478
Epoch - 15, step #000049/000058	Loss: 0.177532
Epoch - 15, step #000050/000058	Loss: 0.159427
Epoch - 15, step #000051/000058	Loss: 0.203699
Epoch - 15, step #000052/000058	Loss: 0.182305
Epoch - 15, step #000053/000058	Loss: 0.161278
Epoch - 15, step #000054/000058	Loss: 0.175326
Epoch - 15, step #000055/000058	Loss: 0.165693
Epoch - 15, step #000056/000058	Loss: 0.157778
Epoch - 15, step #000057/000058	Loss: 0.175844
E[15], train Loss: 0.162002, training Acc: 0.951, val loss: 0.096, val Acc: 0.971	 Time: 3.366 seconds
E[15], train Loss: 0.162002, training Acc: 0.951, val loss: 0.135, val Acc: 0.961	 Time: 3.365 seconds
E[15], train Loss: 0.162002, training Acc: 0.951, val loss: 0.134, val Acc: 0.959	 Time: 3.363 seconds
E[15], train Loss: 0.162002, training Acc: 0.951, val loss: 0.100, val Acc: 0.968	 Time: 3.363 seconds
Total training time: 63.50987958908081 seconds
Total training time: 63.523223876953125 seconds
# GPSs:  4
# GPSs:  4
# GPSs:  4
# GPSs:  4
# GPSs:  4
# GPSs:  4
# GPSs:  4
# GPSs:  4
# I am rank 4 of 8
# I am rank 2 of 8
# I am rank 5 of 8
# I am rank 6 of 8
# I am rank 7 of 8
# I am rank 0 of 8
# I am rank 3 of 8
# I am rank 1 of 8
Epoch - 0, step #000000/000029	Loss: 2.311808
Epoch - 0, step #000001/000029	Loss: 2.302041
Epoch - 0, step #000002/000029	Loss: 2.295627
Epoch - 0, step #000003/000029	Loss: 2.290370
Epoch - 0, step #000004/000029	Loss: 2.281686
Epoch - 0, step #000005/000029	Loss: 2.275360
Epoch - 0, step #000006/000029	Loss: 2.265553
Epoch - 0, step #000007/000029	Loss: 2.257131
Epoch - 0, step #000008/000029	Loss: 2.245898
Epoch - 0, step #000009/000029	Loss: 2.231184
Epoch - 0, step #000010/000029	Loss: 2.220725
Epoch - 0, step #000011/000029	Loss: 2.209403
Epoch - 0, step #000012/000029	Loss: 2.192485
Epoch - 0, step #000013/000029	Loss: 2.168379
Epoch - 0, step #000014/000029	Loss: 2.144417
Epoch - 0, step #000015/000029	Loss: 2.097974
Epoch - 0, step #000016/000029	Loss: 2.062734
Epoch - 0, step #000017/000029	Loss: 2.011879
Epoch - 0, step #000018/000029	Loss: 1.944049
Epoch - 0, step #000019/000029	Loss: 1.858256
Epoch - 0, step #000020/000029	Loss: 1.792134
Epoch - 0, step #000021/000029	Loss: 1.736165
Epoch - 0, step #000022/000029	Loss: 1.691465
Epoch - 0, step #000023/000029	Loss: 1.780756
Epoch - 0, step #000024/000029	Loss: 1.750466
Epoch - 0, step #000025/000029	Loss: 1.623587
Epoch - 0, step #000026/000029	Loss: 1.435129
Epoch - 0, step #000027/000029	Loss: 1.383862
Epoch - 0, step #000028/000029	Loss: 1.452026
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.081, val Acc: 0.689	 Time: 17.644 seconds
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.293, val Acc: 0.623	 Time: 17.611 seconds
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.160, val Acc: 0.629	 Time: 17.582 seconds
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.377, val Acc: 0.575	 Time: 17.673 seconds
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.275, val Acc: 0.650	 Time: 17.580 seconds
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.325, val Acc: 0.576	 Time: 17.638 seconds
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.373, val Acc: 0.495	 Time: 17.581 seconds
E[0], train Loss: 2.010778, training Acc: 0.298, val loss: 1.339, val Acc: 0.573	 Time: 17.686 seconds
Epoch - 1, step #000000/000029	Loss: 1.443335
Epoch - 1, step #000001/000029	Loss: 1.332488
Epoch - 1, step #000002/000029	Loss: 1.267120
Epoch - 1, step #000003/000029	Loss: 1.312193
Epoch - 1, step #000004/000029	Loss: 1.408904
Epoch - 1, step #000005/000029	Loss: 1.331587
Epoch - 1, step #000006/000029	Loss: 1.154640
Epoch - 1, step #000007/000029	Loss: 1.071257
Epoch - 1, step #000008/000029	Loss: 1.038588
Epoch - 1, step #000009/000029	Loss: 1.163533
Epoch - 1, step #000010/000029	Loss: 1.181261
Epoch - 1, step #000011/000029	Loss: 1.146970
Epoch - 1, step #000012/000029	Loss: 1.076139
Epoch - 1, step #000013/000029	Loss: 0.956492
Epoch - 1, step #000014/000029	Loss: 0.937423
Epoch - 1, step #000015/000029	Loss: 0.913414
Epoch - 1, step #000016/000029	Loss: 0.974313
Epoch - 1, step #000017/000029	Loss: 0.961809
Epoch - 1, step #000018/000029	Loss: 0.976323
Epoch - 1, step #000019/000029	Loss: 0.920287
Epoch - 1, step #000020/000029	Loss: 0.851301
Epoch - 1, step #000021/000029	Loss: 0.844536
Epoch - 1, step #000022/000029	Loss: 0.765876
Epoch - 1, step #000023/000029	Loss: 0.736160
Epoch - 1, step #000024/000029	Loss: 0.753572
Epoch - 1, step #000025/000029	Loss: 0.704555
Epoch - 1, step #000026/000029	Loss: 0.680940
Epoch - 1, step #000027/000029	Loss: 0.644707
Epoch - 1, step #000028/000029	Loss: 0.685348
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.525, val Acc: 0.841	 Time: 2.377 seconds
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.442, val Acc: 0.872	 Time: 2.364 seconds
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.488, val Acc: 0.853	 Time: 2.381 seconds
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.532, val Acc: 0.845	 Time: 2.374 seconds
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.500, val Acc: 0.860	 Time: 2.371 seconds
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.492, val Acc: 0.862	 Time: 2.383 seconds
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.499, val Acc: 0.847	 Time: 2.384 seconds
E[1], train Loss: 1.008106, training Acc: 0.664, val loss: 0.545, val Acc: 0.831	 Time: 2.370 seconds
Epoch - 2, step #000000/000029	Loss: 0.652760
Epoch - 2, step #000001/000029	Loss: 0.781006
Epoch - 2, step #000002/000029	Loss: 0.722377
Epoch - 2, step #000003/000029	Loss: 0.694002
Epoch - 2, step #000004/000029	Loss: 0.682104
Epoch - 2, step #000005/000029	Loss: 0.677920
Epoch - 2, step #000006/000029	Loss: 0.689635
Epoch - 2, step #000007/000029	Loss: 0.673694
Epoch - 2, step #000008/000029	Loss: 0.640335
Epoch - 2, step #000009/000029	Loss: 0.644814
Epoch - 2, step #000010/000029	Loss: 0.640564
Epoch - 2, step #000011/000029	Loss: 0.689811
Epoch - 2, step #000012/000029	Loss: 0.636950
Epoch - 2, step #000013/000029	Loss: 0.596768
Epoch - 2, step #000014/000029	Loss: 0.556554
Epoch - 2, step #000015/000029	Loss: 0.598467
Epoch - 2, step #000016/000029	Loss: 0.579194
Epoch - 2, step #000017/000029	Loss: 0.540959
Epoch - 2, step #000018/000029	Loss: 0.569049
Epoch - 2, step #000019/000029	Loss: 0.531960
Epoch - 2, step #000020/000029	Loss: 0.569758
Epoch - 2, step #000021/000029	Loss: 0.544328
Epoch - 2, step #000022/000029	Loss: 0.569696
Epoch - 2, step #000023/000029	Loss: 0.585347
Epoch - 2, step #000024/000029	Loss: 0.531373
Epoch - 2, step #000025/000029	Loss: 0.520373
Epoch - 2, step #000026/000029	Loss: 0.526081
Epoch - 2, step #000027/000029	Loss: 0.541472
Epoch - 2, step #000028/000029	Loss: 0.523223
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.385, val Acc: 0.884	 Time: 2.244 seconds
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.392, val Acc: 0.879	 Time: 2.249 seconds
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.382, val Acc: 0.877	 Time: 2.249 seconds
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.401, val Acc: 0.881	 Time: 2.252 seconds
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.398, val Acc: 0.881	 Time: 2.252 seconds
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.403, val Acc: 0.875	 Time: 2.248 seconds
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.393, val Acc: 0.881	 Time: 2.251 seconds
E[2], train Loss: 0.610709, training Acc: 0.802, val loss: 0.406, val Acc: 0.882	 Time: 2.247 seconds
Epoch - 3, step #000000/000029	Loss: 0.517856
Epoch - 3, step #000001/000029	Loss: 0.524155
Epoch - 3, step #000002/000029	Loss: 0.525418
Epoch - 3, step #000003/000029	Loss: 0.523945
Epoch - 3, step #000004/000029	Loss: 0.487111
Epoch - 3, step #000005/000029	Loss: 0.463294
Epoch - 3, step #000006/000029	Loss: 0.559416
Epoch - 3, step #000007/000029	Loss: 0.541419
Epoch - 3, step #000008/000029	Loss: 0.531978
Epoch - 3, step #000009/000029	Loss: 0.567856
Epoch - 3, step #000010/000029	Loss: 0.552589
Epoch - 3, step #000011/000029	Loss: 0.484856
Epoch - 3, step #000012/000029	Loss: 0.496757
Epoch - 3, step #000013/000029	Loss: 0.497166
Epoch - 3, step #000014/000029	Loss: 0.515212
Epoch - 3, step #000015/000029	Loss: 0.491218
Epoch - 3, step #000016/000029	Loss: 0.510613
Epoch - 3, step #000017/000029	Loss: 0.481466
Epoch - 3, step #000018/000029	Loss: 0.494120
Epoch - 3, step #000019/000029	Loss: 0.471954
Epoch - 3, step #000020/000029	Loss: 0.485900
Epoch - 3, step #000021/000029	Loss: 0.462300
Epoch - 3, step #000022/000029	Loss: 0.402479
Epoch - 3, step #000023/000029	Loss: 0.428388
Epoch - 3, step #000024/000029	Loss: 0.463204
Epoch - 3, step #000025/000029	Loss: 0.466752
Epoch - 3, step #000026/000029	Loss: 0.506910
Epoch - 3, step #000027/000029	Loss: 0.506283
Epoch - 3, step #000028/000029	Loss: 0.448224
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.339, val Acc: 0.894	 Time: 2.245 seconds
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.353, val Acc: 0.891	 Time: 2.245 seconds
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.340, val Acc: 0.900	 Time: 2.247 seconds
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.325, val Acc: 0.902	 Time: 2.244 seconds
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.321, val Acc: 0.903	 Time: 2.249 seconds
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.345, val Acc: 0.895	 Time: 2.254 seconds
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.372, val Acc: 0.882	 Time: 2.254 seconds
E[3], train Loss: 0.496857, training Acc: 0.843, val loss: 0.340, val Acc: 0.899	 Time: 2.252 seconds
Epoch - 4, step #000000/000029	Loss: 0.448252
Epoch - 4, step #000001/000029	Loss: 0.467305
Epoch - 4, step #000002/000029	Loss: 0.429219
Epoch - 4, step #000003/000029	Loss: 0.408207
Epoch - 4, step #000004/000029	Loss: 0.459592
Epoch - 4, step #000005/000029	Loss: 0.456095
Epoch - 4, step #000006/000029	Loss: 0.452696
Epoch - 4, step #000007/000029	Loss: 0.404996
Epoch - 4, step #000008/000029	Loss: 0.431824
Epoch - 4, step #000009/000029	Loss: 0.443228
Epoch - 4, step #000010/000029	Loss: 0.435531
Epoch - 4, step #000011/000029	Loss: 0.452117
Epoch - 4, step #000012/000029	Loss: 0.459382
Epoch - 4, step #000013/000029	Loss: 0.421170
Epoch - 4, step #000014/000029	Loss: 0.422469
Epoch - 4, step #000015/000029	Loss: 0.418321
Epoch - 4, step #000016/000029	Loss: 0.399834
Epoch - 4, step #000017/000029	Loss: 0.381379
Epoch - 4, step #000018/000029	Loss: 0.388779
Epoch - 4, step #000019/000029	Loss: 0.377786
Epoch - 4, step #000020/000029	Loss: 0.396542
Epoch - 4, step #000021/000029	Loss: 0.447402
Epoch - 4, step #000022/000029	Loss: 0.407524
Epoch - 4, step #000023/000029	Loss: 0.393418
Epoch - 4, step #000024/000029	Loss: 0.407555
Epoch - 4, step #000025/000029	Loss: 0.403889
Epoch - 4, step #000026/000029	Loss: 0.439149
Epoch - 4, step #000027/000029	Loss: 0.425079
Epoch - 4, step #000028/000029	Loss: 0.409384
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.309, val Acc: 0.908	 Time: 2.430 seconds
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.294, val Acc: 0.909	 Time: 2.434 seconds
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.317, val Acc: 0.902	 Time: 2.426 seconds
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.320, val Acc: 0.904	 Time: 2.432 seconds
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.312, val Acc: 0.903	 Time: 2.432 seconds
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.310, val Acc: 0.906	 Time: 2.433 seconds
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.333, val Acc: 0.897	 Time: 2.441 seconds
E[4], train Loss: 0.423728, training Acc: 0.869, val loss: 0.333, val Acc: 0.899	 Time: 2.430 seconds
Epoch - 5, step #000000/000029	Loss: 0.414136
Epoch - 5, step #000001/000029	Loss: 0.406825
Epoch - 5, step #000002/000029	Loss: 0.391653
Epoch - 5, step #000003/000029	Loss: 0.398647
Epoch - 5, step #000004/000029	Loss: 0.385067
Epoch - 5, step #000005/000029	Loss: 0.383151
Epoch - 5, step #000006/000029	Loss: 0.420219
Epoch - 5, step #000007/000029	Loss: 0.370748
Epoch - 5, step #000008/000029	Loss: 0.410966
Epoch - 5, step #000009/000029	Loss: 0.376099
Epoch - 5, step #000010/000029	Loss: 0.416201
Epoch - 5, step #000011/000029	Loss: 0.389933
Epoch - 5, step #000012/000029	Loss: 0.432758
Epoch - 5, step #000013/000029	Loss: 0.407511
Epoch - 5, step #000014/000029	Loss: 0.373909
Epoch - 5, step #000015/000029	Loss: 0.389641
Epoch - 5, step #000016/000029	Loss: 0.366651
Epoch - 5, step #000017/000029	Loss: 0.371084
Epoch - 5, step #000018/000029	Loss: 0.400656
Epoch - 5, step #000019/000029	Loss: 0.332430
Epoch - 5, step #000020/000029	Loss: 0.396396
Epoch - 5, step #000021/000029	Loss: 0.403910
Epoch - 5, step #000022/000029	Loss: 0.376289
Epoch - 5, step #000023/000029	Loss: 0.373380
Epoch - 5, step #000024/000029	Loss: 0.349181
Epoch - 5, step #000025/000029	Loss: 0.379212
Epoch - 5, step #000026/000029	Loss: 0.374001
Epoch - 5, step #000027/000029	Loss: 0.383868
Epoch - 5, step #000028/000029	Loss: 0.384960
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.265, val Acc: 0.920	 Time: 2.485 seconds
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.263, val Acc: 0.919	 Time: 2.474 seconds
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.282, val Acc: 0.915	 Time: 2.484 seconds
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.270, val Acc: 0.921	 Time: 2.480 seconds
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.278, val Acc: 0.919	 Time: 2.487 seconds
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.273, val Acc: 0.917	 Time: 2.485 seconds
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.259, val Acc: 0.922	 Time: 2.484 seconds
E[5], train Loss: 0.388258, training Acc: 0.880, val loss: 0.275, val Acc: 0.918	 Time: 2.482 seconds
Epoch - 6, step #000000/000029	Loss: 0.327487
Epoch - 6, step #000001/000029	Loss: 0.353094
Epoch - 6, step #000002/000029	Loss: 0.363165
Epoch - 6, step #000003/000029	Loss: 0.386326
Epoch - 6, step #000004/000029	Loss: 0.343869
Epoch - 6, step #000005/000029	Loss: 0.356431
Epoch - 6, step #000006/000029	Loss: 0.373079
Epoch - 6, step #000007/000029	Loss: 0.385810
Epoch - 6, step #000008/000029	Loss: 0.356435
Epoch - 6, step #000009/000029	Loss: 0.353196
Epoch - 6, step #000010/000029	Loss: 0.367932
Epoch - 6, step #000011/000029	Loss: 0.363763
Epoch - 6, step #000012/000029	Loss: 0.362963
Epoch - 6, step #000013/000029	Loss: 0.317853
Epoch - 6, step #000014/000029	Loss: 0.353098
Epoch - 6, step #000015/000029	Loss: 0.365950
Epoch - 6, step #000016/000029	Loss: 0.363546
Epoch - 6, step #000017/000029	Loss: 0.349625
Epoch - 6, step #000018/000029	Loss: 0.322508
Epoch - 6, step #000019/000029	Loss: 0.336828
Epoch - 6, step #000020/000029	Loss: 0.365998
Epoch - 6, step #000021/000029	Loss: 0.321917
Epoch - 6, step #000022/000029	Loss: 0.318334
Epoch - 6, step #000023/000029	Loss: 0.409159
Epoch - 6, step #000024/000029	Loss: 0.351804
Epoch - 6, step #000025/000029	Loss: 0.365998
Epoch - 6, step #000026/000029	Loss: 0.346528
Epoch - 6, step #000027/000029	Loss: 0.382896
Epoch - 6, step #000028/000029	Loss: 0.314621
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.250, val Acc: 0.923	 Time: 2.262 seconds
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.259, val Acc: 0.923	 Time: 2.265 seconds
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.227, val Acc: 0.931	 Time: 2.262 seconds
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.260, val Acc: 0.922	 Time: 2.266 seconds
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.250, val Acc: 0.925	 Time: 2.267 seconds
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.234, val Acc: 0.931	 Time: 2.268 seconds
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.232, val Acc: 0.930	 Time: 2.270 seconds
E[6], train Loss: 0.354490, training Acc: 0.891, val loss: 0.245, val Acc: 0.925	 Time: 2.264 seconds
Epoch - 7, step #000000/000029	Loss: 0.334570
Epoch - 7, step #000001/000029	Loss: 0.314944
Epoch - 7, step #000002/000029	Loss: 0.338086
Epoch - 7, step #000003/000029	Loss: 0.317884
Epoch - 7, step #000004/000029	Loss: 0.322296
Epoch - 7, step #000005/000029	Loss: 0.329488
Epoch - 7, step #000006/000029	Loss: 0.345510
Epoch - 7, step #000007/000029	Loss: 0.327092
Epoch - 7, step #000008/000029	Loss: 0.321996
Epoch - 7, step #000009/000029	Loss: 0.329090
Epoch - 7, step #000010/000029	Loss: 0.350176
Epoch - 7, step #000011/000029	Loss: 0.399682
Epoch - 7, step #000012/000029	Loss: 0.330489
Epoch - 7, step #000013/000029	Loss: 0.323382
Epoch - 7, step #000014/000029	Loss: 0.317143
Epoch - 7, step #000015/000029	Loss: 0.318031
Epoch - 7, step #000016/000029	Loss: 0.326450
Epoch - 7, step #000017/000029	Loss: 0.284969
Epoch - 7, step #000018/000029	Loss: 0.309320
Epoch - 7, step #000019/000029	Loss: 0.326035
Epoch - 7, step #000020/000029	Loss: 0.328224
Epoch - 7, step #000021/000029	Loss: 0.308544
Epoch - 7, step #000022/000029	Loss: 0.327587
Epoch - 7, step #000023/000029	Loss: 0.305631
Epoch - 7, step #000024/000029	Loss: 0.297530
Epoch - 7, step #000025/000029	Loss: 0.293978
Epoch - 7, step #000026/000029	Loss: 0.301415
Epoch - 7, step #000027/000029	Loss: 0.271846
Epoch - 7, step #000028/000029	Loss: 0.346421
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.241, val Acc: 0.927	 Time: 2.277 seconds
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.225, val Acc: 0.932	 Time: 2.276 seconds
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.217, val Acc: 0.933	 Time: 2.278 seconds
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.214, val Acc: 0.936	 Time: 2.283 seconds
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.218, val Acc: 0.935	 Time: 2.287 seconds
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.237, val Acc: 0.927	 Time: 2.283 seconds
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.236, val Acc: 0.929	 Time: 2.293 seconds
E[7], train Loss: 0.322338, training Acc: 0.901, val loss: 0.232, val Acc: 0.927	 Time: 2.280 seconds
Epoch - 8, step #000000/000029	Loss: 0.301208
Epoch - 8, step #000001/000029	Loss: 0.319195
Epoch - 8, step #000002/000029	Loss: 0.313341
Epoch - 8, step #000003/000029	Loss: 0.340659
Epoch - 8, step #000004/000029	Loss: 0.308910
Epoch - 8, step #000005/000029	Loss: 0.336418
Epoch - 8, step #000006/000029	Loss: 0.312406
Epoch - 8, step #000007/000029	Loss: 0.273470
Epoch - 8, step #000008/000029	Loss: 0.315780
Epoch - 8, step #000009/000029	Loss: 0.306587
Epoch - 8, step #000010/000029	Loss: 0.291381
Epoch - 8, step #000011/000029	Loss: 0.290064
Epoch - 8, step #000012/000029	Loss: 0.268598
Epoch - 8, step #000013/000029	Loss: 0.312394
Epoch - 8, step #000014/000029	Loss: 0.286542
Epoch - 8, step #000015/000029	Loss: 0.290991
Epoch - 8, step #000016/000029	Loss: 0.294018
Epoch - 8, step #000017/000029	Loss: 0.283115
Epoch - 8, step #000018/000029	Loss: 0.298101
Epoch - 8, step #000019/000029	Loss: 0.280577
Epoch - 8, step #000020/000029	Loss: 0.279829
Epoch - 8, step #000021/000029	Loss: 0.327956
Epoch - 8, step #000022/000029	Loss: 0.301937
Epoch - 8, step #000023/000029	Loss: 0.267537
Epoch - 8, step #000024/000029	Loss: 0.280139
Epoch - 8, step #000025/000029	Loss: 0.266884
Epoch - 8, step #000026/000029	Loss: 0.265028
Epoch - 8, step #000027/000029	Loss: 0.240293
Epoch - 8, step #000028/000029	Loss: 0.263374
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.196, val Acc: 0.937	 Time: 2.254 seconds
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.213, val Acc: 0.940	 Time: 2.258 seconds
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.213, val Acc: 0.939	 Time: 2.252 seconds
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.183, val Acc: 0.944	 Time: 2.254 seconds
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.201, val Acc: 0.936	 Time: 2.255 seconds
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.209, val Acc: 0.939	 Time: 2.242 seconds
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.202, val Acc: 0.940	 Time: 2.256 seconds
E[8], train Loss: 0.293680, training Acc: 0.908, val loss: 0.206, val Acc: 0.936	 Time: 2.254 seconds
Epoch - 9, step #000000/000029	Loss: 0.292020
Epoch - 9, step #000001/000029	Loss: 0.282852
Epoch - 9, step #000002/000029	Loss: 0.286488
Epoch - 9, step #000003/000029	Loss: 0.275102
Epoch - 9, step #000004/000029	Loss: 0.290006
Epoch - 9, step #000005/000029	Loss: 0.269179
Epoch - 9, step #000006/000029	Loss: 0.262074
Epoch - 9, step #000007/000029	Loss: 0.272118
Epoch - 9, step #000008/000029	Loss: 0.265377
Epoch - 9, step #000009/000029	Loss: 0.257130
Epoch - 9, step #000010/000029	Loss: 0.258964
Epoch - 9, step #000011/000029	Loss: 0.281922
Epoch - 9, step #000012/000029	Loss: 0.259599
Epoch - 9, step #000013/000029	Loss: 0.282280
Epoch - 9, step #000014/000029	Loss: 0.260311
Epoch - 9, step #000015/000029	Loss: 0.292005
Epoch - 9, step #000016/000029	Loss: 0.259695
Epoch - 9, step #000017/000029	Loss: 0.251184
Epoch - 9, step #000018/000029	Loss: 0.257746
Epoch - 9, step #000019/000029	Loss: 0.278630
Epoch - 9, step #000020/000029	Loss: 0.246444
Epoch - 9, step #000021/000029	Loss: 0.256963
Epoch - 9, step #000022/000029	Loss: 0.233089
Epoch - 9, step #000023/000029	Loss: 0.255121
Epoch - 9, step #000024/000029	Loss: 0.261980
Epoch - 9, step #000025/000029	Loss: 0.272943
Epoch - 9, step #000026/000029	Loss: 0.245993
Epoch - 9, step #000027/000029	Loss: 0.238833
Epoch - 9, step #000028/000029	Loss: 0.253184
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.174, val Acc: 0.946	 Time: 2.246 seconds
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.169, val Acc: 0.949	 Time: 2.248 seconds
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.175, val Acc: 0.949	 Time: 2.252 seconds
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.182, val Acc: 0.946	 Time: 2.246 seconds
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.195, val Acc: 0.943	 Time: 2.247 seconds
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.206, val Acc: 0.941	 Time: 2.252 seconds
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.195, val Acc: 0.942	 Time: 2.253 seconds
E[9], train Loss: 0.265491, training Acc: 0.918, val loss: 0.179, val Acc: 0.946	 Time: 2.251 seconds
Epoch - 10, step #000000/000029	Loss: 0.281178
Epoch - 10, step #000001/000029	Loss: 0.262628
Epoch - 10, step #000002/000029	Loss: 0.272245
Epoch - 10, step #000003/000029	Loss: 0.232872
Epoch - 10, step #000004/000029	Loss: 0.246971
Epoch - 10, step #000005/000029	Loss: 0.247536
Epoch - 10, step #000006/000029	Loss: 0.278742
Epoch - 10, step #000007/000029	Loss: 0.290347
Epoch - 10, step #000008/000029	Loss: 0.275153
Epoch - 10, step #000009/000029	Loss: 0.259323
Epoch - 10, step #000010/000029	Loss: 0.239587
Epoch - 10, step #000011/000029	Loss: 0.256194
Epoch - 10, step #000012/000029	Loss: 0.230085
Epoch - 10, step #000013/000029	Loss: 0.233842
Epoch - 10, step #000014/000029	Loss: 0.208104
Epoch - 10, step #000015/000029	Loss: 0.246781
Epoch - 10, step #000016/000029	Loss: 0.262523
Epoch - 10, step #000017/000029	Loss: 0.232434
Epoch - 10, step #000018/000029	Loss: 0.247763
Epoch - 10, step #000019/000029	Loss: 0.245193
Epoch - 10, step #000020/000029	Loss: 0.247991
Epoch - 10, step #000021/000029	Loss: 0.231517
Epoch - 10, step #000022/000029	Loss: 0.231860
Epoch - 10, step #000023/000029	Loss: 0.222762
Epoch - 10, step #000024/000029	Loss: 0.234706
Epoch - 10, step #000025/000029	Loss: 0.275190
Epoch - 10, step #000026/000029	Loss: 0.221162
Epoch - 10, step #000027/000029	Loss: 0.261384
Epoch - 10, step #000028/000029	Loss: 0.252493
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.174, val Acc: 0.949	 Time: 2.259 seconds
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.180, val Acc: 0.948	 Time: 2.256 seconds
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.175, val Acc: 0.949	 Time: 2.260 seconds
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.169, val Acc: 0.949	 Time: 2.262 seconds
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.185, val Acc: 0.947	 Time: 2.263 seconds
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.172, val Acc: 0.946	 Time: 2.265 seconds
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.168, val Acc: 0.950	 Time: 2.268 seconds
E[10], train Loss: 0.249261, training Acc: 0.924, val loss: 0.169, val Acc: 0.949	 Time: 2.262 seconds
Epoch - 11, step #000000/000029	Loss: 0.231675
Epoch - 11, step #000001/000029	Loss: 0.238690
Epoch - 11, step #000002/000029	Loss: 0.219844
Epoch - 11, step #000003/000029	Loss: 0.233581
Epoch - 11, step #000004/000029	Loss: 0.232790
Epoch - 11, step #000005/000029	Loss: 0.253512
Epoch - 11, step #000006/000029	Loss: 0.249117
Epoch - 11, step #000007/000029	Loss: 0.229617
Epoch - 11, step #000008/000029	Loss: 0.214926
Epoch - 11, step #000009/000029	Loss: 0.218137
Epoch - 11, step #000010/000029	Loss: 0.245888
Epoch - 11, step #000011/000029	Loss: 0.214502
Epoch - 11, step #000012/000029	Loss: 0.239088
Epoch - 11, step #000013/000029	Loss: 0.249067
Epoch - 11, step #000014/000029	Loss: 0.252885
Epoch - 11, step #000015/000029	Loss: 0.245780
Epoch - 11, step #000016/000029	Loss: 0.231697
Epoch - 11, step #000017/000029	Loss: 0.209769
Epoch - 11, step #000018/000029	Loss: 0.217424
Epoch - 11, step #000019/000029	Loss: 0.239248
Epoch - 11, step #000020/000029	Loss: 0.211166
Epoch - 11, step #000021/000029	Loss: 0.214897
Epoch - 11, step #000022/000029	Loss: 0.224347
Epoch - 11, step #000023/000029	Loss: 0.202873
Epoch - 11, step #000024/000029	Loss: 0.207254
Epoch - 11, step #000025/000029	Loss: 0.207843
Epoch - 11, step #000026/000029	Loss: 0.206355
Epoch - 11, step #000027/000029	Loss: 0.253346
Epoch - 11, step #000028/000029	Loss: 0.224676
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.161, val Acc: 0.952	 Time: 2.249 seconds
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.174, val Acc: 0.951	 Time: 2.245 seconds
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.147, val Acc: 0.954	 Time: 2.244 seconds
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.154, val Acc: 0.952	 Time: 2.250 seconds
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.169, val Acc: 0.950	 Time: 2.252 seconds
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.171, val Acc: 0.947	 Time: 2.252 seconds
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.146, val Acc: 0.956	 Time: 2.247 seconds
E[11], train Loss: 0.228276, training Acc: 0.931, val loss: 0.149, val Acc: 0.956	 Time: 2.248 seconds
Epoch - 12, step #000000/000029	Loss: 0.214463
Epoch - 12, step #000001/000029	Loss: 0.217114
Epoch - 12, step #000002/000029	Loss: 0.238413
Epoch - 12, step #000003/000029	Loss: 0.210578
Epoch - 12, step #000004/000029	Loss: 0.218945
Epoch - 12, step #000005/000029	Loss: 0.203382
Epoch - 12, step #000006/000029	Loss: 0.222694
Epoch - 12, step #000007/000029	Loss: 0.203962
Epoch - 12, step #000008/000029	Loss: 0.227140
Epoch - 12, step #000009/000029	Loss: 0.213926
Epoch - 12, step #000010/000029	Loss: 0.213210
Epoch - 12, step #000011/000029	Loss: 0.208703
Epoch - 12, step #000012/000029	Loss: 0.215540
Epoch - 12, step #000013/000029	Loss: 0.201769
Epoch - 12, step #000014/000029	Loss: 0.226241
Epoch - 12, step #000015/000029	Loss: 0.225676
Epoch - 12, step #000016/000029	Loss: 0.223449
Epoch - 12, step #000017/000029	Loss: 0.228953
Epoch - 12, step #000018/000029	Loss: 0.232121
Epoch - 12, step #000019/000029	Loss: 0.204265
Epoch - 12, step #000020/000029	Loss: 0.221120
Epoch - 12, step #000021/000029	Loss: 0.227492
Epoch - 12, step #000022/000029	Loss: 0.211337
Epoch - 12, step #000023/000029	Loss: 0.200302
Epoch - 12, step #000024/000029	Loss: 0.219383
Epoch - 12, step #000025/000029	Loss: 0.219674
Epoch - 12, step #000026/000029	Loss: 0.173829
Epoch - 12, step #000027/000029	Loss: 0.214037
Epoch - 12, step #000028/000029	Loss: 0.218880
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.162, val Acc: 0.955	 Time: 2.262 seconds
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.139, val Acc: 0.959	 Time: 2.258 seconds
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.139, val Acc: 0.958	 Time: 2.262 seconds
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.149, val Acc: 0.955	 Time: 2.262 seconds
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.147, val Acc: 0.954	 Time: 2.269 seconds
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.144, val Acc: 0.957	 Time: 2.266 seconds
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.148, val Acc: 0.957	 Time: 2.269 seconds
E[12], train Loss: 0.215745, training Acc: 0.934, val loss: 0.139, val Acc: 0.958	 Time: 2.261 seconds
Epoch - 13, step #000000/000029	Loss: 0.185727
Epoch - 13, step #000001/000029	Loss: 0.216201
Epoch - 13, step #000002/000029	Loss: 0.216566
Epoch - 13, step #000003/000029	Loss: 0.227619
Epoch - 13, step #000004/000029	Loss: 0.220923
Epoch - 13, step #000005/000029	Loss: 0.218452
Epoch - 13, step #000006/000029	Loss: 0.212113
Epoch - 13, step #000007/000029	Loss: 0.211593
Epoch - 13, step #000008/000029	Loss: 0.178502
Epoch - 13, step #000009/000029	Loss: 0.183712
Epoch - 13, step #000010/000029	Loss: 0.182086
Epoch - 13, step #000011/000029	Loss: 0.183063
Epoch - 13, step #000012/000029	Loss: 0.193521
Epoch - 13, step #000013/000029	Loss: 0.218266
Epoch - 13, step #000014/000029	Loss: 0.211142
Epoch - 13, step #000015/000029	Loss: 0.212779
Epoch - 13, step #000016/000029	Loss: 0.211688
Epoch - 13, step #000017/000029	Loss: 0.216488
Epoch - 13, step #000018/000029	Loss: 0.205944
Epoch - 13, step #000019/000029	Loss: 0.214273
Epoch - 13, step #000020/000029	Loss: 0.173177
Epoch - 13, step #000021/000029	Loss: 0.186675
Epoch - 13, step #000022/000029	Loss: 0.213088
Epoch - 13, step #000023/000029	Loss: 0.185176
Epoch - 13, step #000024/000029	Loss: 0.187095
Epoch - 13, step #000025/000029	Loss: 0.206249
Epoch - 13, step #000026/000029	Loss: 0.213300
Epoch - 13, step #000027/000029	Loss: 0.206384
Epoch - 13, step #000028/000029	Loss: 0.190235
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.138, val Acc: 0.959	 Time: 2.222 seconds
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.149, val Acc: 0.956	 Time: 2.229 seconds
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.127, val Acc: 0.960	 Time: 2.232 seconds
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.139, val Acc: 0.957	 Time: 2.230 seconds
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.139, val Acc: 0.958	 Time: 2.229 seconds
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.129, val Acc: 0.959	 Time: 2.229 seconds
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.125, val Acc: 0.959	 Time: 2.235 seconds
E[13], train Loss: 0.202829, training Acc: 0.937, val loss: 0.128, val Acc: 0.961	 Time: 2.231 seconds
Epoch - 14, step #000000/000029	Loss: 0.207228
Epoch - 14, step #000001/000029	Loss: 0.185662
Epoch - 14, step #000002/000029	Loss: 0.181623
Epoch - 14, step #000003/000029	Loss: 0.201953
Epoch - 14, step #000004/000029	Loss: 0.159771
Epoch - 14, step #000005/000029	Loss: 0.182619
Epoch - 14, step #000006/000029	Loss: 0.192318
Epoch - 14, step #000007/000029	Loss: 0.201708
Epoch - 14, step #000008/000029	Loss: 0.177070
Epoch - 14, step #000009/000029	Loss: 0.190241
Epoch - 14, step #000010/000029	Loss: 0.184982
Epoch - 14, step #000011/000029	Loss: 0.183906
Epoch - 14, step #000012/000029	Loss: 0.182260
Epoch - 14, step #000013/000029	Loss: 0.194817
Epoch - 14, step #000014/000029	Loss: 0.151910
Epoch - 14, step #000015/000029	Loss: 0.185634
Epoch - 14, step #000016/000029	Loss: 0.167810
Epoch - 14, step #000017/000029	Loss: 0.213892
Epoch - 14, step #000018/000029	Loss: 0.181473
Epoch - 14, step #000019/000029	Loss: 0.180643
Epoch - 14, step #000020/000029	Loss: 0.183333
Epoch - 14, step #000021/000029	Loss: 0.178654
Epoch - 14, step #000022/000029	Loss: 0.190597
Epoch - 14, step #000023/000029	Loss: 0.200361
Epoch - 14, step #000024/000029	Loss: 0.194775
Epoch - 14, step #000025/000029	Loss: 0.164872
Epoch - 14, step #000026/000029	Loss: 0.174383
Epoch - 14, step #000027/000029	Loss: 0.165491
Epoch - 14, step #000028/000029	Loss: 0.201460
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.137, val Acc: 0.959	 Time: 2.260 seconds
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.135, val Acc: 0.958	 Time: 2.255 seconds
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.119, val Acc: 0.964	 Time: 2.253 seconds
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.126, val Acc: 0.962	 Time: 2.256 seconds
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.116, val Acc: 0.963	 Time: 2.259 seconds
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.147, val Acc: 0.957	 Time: 2.263 seconds
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.118, val Acc: 0.964	 Time: 2.260 seconds
E[14], train Loss: 0.184878, training Acc: 0.944, val loss: 0.115, val Acc: 0.966	 Time: 2.262 seconds
Epoch - 15, step #000000/000029	Loss: 0.198658
Epoch - 15, step #000001/000029	Loss: 0.174184
Epoch - 15, step #000002/000029	Loss: 0.171665
Epoch - 15, step #000003/000029	Loss: 0.177598
Epoch - 15, step #000004/000029	Loss: 0.177906
Epoch - 15, step #000005/000029	Loss: 0.179844
Epoch - 15, step #000006/000029	Loss: 0.167869
Epoch - 15, step #000007/000029	Loss: 0.179069
Epoch - 15, step #000008/000029	Loss: 0.195793
Epoch - 15, step #000009/000029	Loss: 0.186211
Epoch - 15, step #000010/000029	Loss: 0.203188
Epoch - 15, step #000011/000029	Loss: 0.173499
Epoch - 15, step #000012/000029	Loss: 0.192336
Epoch - 15, step #000013/000029	Loss: 0.154516
Epoch - 15, step #000014/000029	Loss: 0.191728
Epoch - 15, step #000015/000029	Loss: 0.169434
Epoch - 15, step #000016/000029	Loss: 0.146721
Epoch - 15, step #000017/000029	Loss: 0.170235
Epoch - 15, step #000018/000029	Loss: 0.176231
Epoch - 15, step #000019/000029	Loss: 0.203476
Epoch - 15, step #000020/000029	Loss: 0.184036
Epoch - 15, step #000021/000029	Loss: 0.181493
Epoch - 15, step #000022/000029	Loss: 0.166509
Epoch - 15, step #000023/000029	Loss: 0.178282
Epoch - 15, step #000024/000029	Loss: 0.166640
Epoch - 15, step #000025/000029	Loss: 0.150964
Epoch - 15, step #000026/000029	Loss: 0.157992
Epoch - 15, step #000027/000029	Loss: 0.177102
Epoch - 15, step #000028/000029	Loss: 0.182191
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.115, val Acc: 0.965	 Time: 2.239 seconds
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.121, val Acc: 0.963	 Time: 2.237 seconds
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.123, val Acc: 0.962	 Time: 2.242 seconds
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.125, val Acc: 0.962	 Time: 2.243 seconds
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.142, val Acc: 0.959	 Time: 2.241 seconds
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.112, val Acc: 0.965	 Time: 2.241 seconds
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.118, val Acc: 0.963	 Time: 2.237 seconds
E[15], train Loss: 0.177082, training Acc: 0.945, val loss: 0.116, val Acc: 0.965	 Time: 2.234 seconds
Total training time: 51.983335733413696 seconds
Total training time: 52.08811020851135 seconds
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# GPSs:  5
# I am rank 0 of 16
# I am rank 8 of 16
# I am rank 12 of 16
# I am rank 9 of 16
# I am rank 3 of 16
# I am rank 1 of 16
# I am rank 5 of 16
# I am rank 13 of 16
# I am rank 6 of 16
# I am rank 14 of 16
# I am rank 2 of 16
# I am rank 11 of 16
# I am rank 10 of 16
# I am rank 4 of 16
# I am rank 7 of 16
# I am rank 15 of 16
